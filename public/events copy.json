[
    {
        "relevant_people": [
            "Thomas Bayes"
        ],
        "description": "The [**Bayes' theorem**](https://en.wikipedia.org/wiki/Bayes%27_theorem) is a fundamental concept in probability theory and statistics, formulated by [Thomas Bayes](https://en.wikipedia.org/wiki/Thomas_Bayes), an English statistician, philosopher, and Presbyterian minister. In 1763, Bayes' work, 'An Essay towards solving a Problem in the Doctrine of Chances,' was published posthumously, presenting the foundation of the theorem. Bayes' theorem describes the probability of an event based on prior knowledge of conditions that might be related to the event. It has wide-ranging applications in various fields, including science, engineering, medicine, and artificial intelligence.",
        "related_topics": [
            "Probability theory",
            "Statistics",
            "Bayesian inference",
            "Machine learning",
            "Bayesian networks"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Bayes%27_theorem",
            "https://plato.stanford.edu/entries/bayes-theorem/",
            "https://mathworld.wolfram.com/BayesTheorem.html",
            "https://www.britannica.com/topic/Bayess-theorem",
            "https://www.youtube.com/watch?v=HZGCoVF3YvM"
        ],
        "papers": [
            {
                "title": "An Essay towards solving a Problem in the Doctrine of Chances",
                "url": "https://royalsocietypublishing.org/doi/10.1098/rstl.1763.0053",
                "authors": [
                    "Thomas Bayes"
                ],
                "proceeding": "Philosophical Transactions of the Royal Society of London",
                "date": "1763",
                "abstract": "In this essay, Thomas Bayes presents a fundamental concept in probability theory, known today as Bayes' theorem. The work provides a solution to the problem of inverse probability, which is the determination of the probability of an event based on the knowledge of related conditions.",
                "url_pdf": "https://royalsocietypublishing.org/doi/pdf/10.1098/rstl.1763.0053",
                "num_citations": 2976,
                "publisher": "The Royal Society",
                "pages": "370-418",
                "volume": "53",
                "journal": "Philosophical Transactions of the Royal Society of London",
                "pub_type": "article"
            }
        ],
        "title": "Foundations of Bayes' Theorem",
        "wiki_url": "https://en.wikipedia.org/wiki/Bayes%27_theorem",
        "image": "https://upload.wikimedia.org/wikipedia/commons/9/97/Bayes-rule3.png",
        "date": "1763"
    },
    {
        "relevant_people": [
            "Pierre-Simon Laplace"
        ],
        "description": "The [**Bayesian Interpretation of Probability**](https://en.wikipedia.org/wiki/Bayesian_probability) is a fundamental concept in probability theory and statistics, which is based on the work of [Pierre-Simon Laplace](https://en.wikipedia.org/wiki/Pierre-Simon_Laplace). In his 1812 book, 'Th\u00e9orie analytique des probabilit\u00e9s', Laplace used conditional probability to formulate the relation of an updated posterior probability from a prior probability, given evidence. He reproduced and extended [Bayes's](https://en.wikipedia.org/wiki/Thomas_Bayes) results in 1774, apparently unaware of Bayes's work. The Bayesian approach allows for the updating of probabilities based on new data and has become a cornerstone of modern statistical inference.",
        "related_topics": [
            "Bayes' theorem",
            "Conditional probability",
            "Prior probability",
            "Posterior probability",
            "Statistical inference"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Bayesian_probability",
            "https://en.wikipedia.org/wiki/Pierre-Simon_Laplace",
            "https://en.wikipedia.org/wiki/Th%C3%A9orie_analytique_des_probabilit%C3%A9s",
            "https://plato.stanford.edu/entries/probability-interpret/#BayPro",
            "https://www.britannica.com/science/Bayesian-statistics"
        ],
        "papers": [
            {
                "title": "Th\u00e9orie analytique des probabilit\u00e9s",
                "url": "https://gallica.bnf.fr/ark:/12148/bpt6k33707",
                "authors": [
                    "Pierre-Simon Laplace"
                ],
                "date": "1812",
                "abstract": "In this book, Laplace presents the Bayesian Interpretation of Probability, using conditional probability to formulate the relation of an updated posterior probability from a prior probability, given evidence. He reproduced and extended Bayes's results, apparently unaware of Bayes's work.",
                "url_pdf": "https://gallica.bnf.fr/ark:/12148/bpt6k33707/f1n3",
                "publisher": "Courcier",
                "pages": "1-738",
                "volume": "",
                "journal": "",
                "pub_type": "book"
            }
        ],
        "title": "Bayesian Interpretation of Probability",
        "wiki_url": "https://en.wikipedia.org/wiki/Bayesian_probability",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/ed/Bayes_icon.svg",
        "date": "1774"
    },
    {
        "relevant_people": [
            "Warren McCulloch",
            "Walter Pitts"
        ],
        "description": "The [**artificial neuron**](https://en.wikipedia.org/wiki/Artificial_neuron) is a mathematical model that imitates the functioning of a biological neuron. It was developed by [Warren McCulloch](https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch) and [Walter Pitts](https://en.wikipedia.org/wiki/Walter_Pitts) in 1943 and is considered the first neural model invented. The artificial neuron serves as the foundation for the development of artificial neural networks, which are now widely used in various fields such as computer vision, natural language processing, and robotics.",
        "related_topics": [
            "Artificial neural networks",
            "Neuroscience",
            "Computational neuroscience",
            "Perceptron",
            "Deep learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Artificial_neuron",
            "https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch",
            "https://en.wikipedia.org/wiki/Walter_Pitts",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1392413/",
            "https://www.researchgate.net/publication/227669174_Artificial_Neurons_and_Biological_Neurons_A_Comparison"
        ],
        "papers": [
            {
                "title": "A logical calculus of the ideas immanent in nervous activity",
                "url": "https://www.jstor.org/stable/2183779",
                "authors": [
                    "Warren Sturgis McCulloch",
                    "Walter Harry Pitts"
                ],
                "proceeding": "Bulletin of Mathematical Biophysics",
                "date": "1943",
                "abstract": "This paper presents a logical calculus of the ideas immanent in nervous activity, which is the foundation for the development of the artificial neuron model.",
                "url_pdf": "https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf",
                "num_citations": 2442,
                "publisher": "The University of Chicago Press",
                "pages": "99-115",
                "volume": "5",
                "journal": "Bulletin of Mathematical Biophysics",
                "pub_type": "article"
            }
        ],
        "title": "Artificial Neuron",
        "wiki_url": "https://en.wikipedia.org/wiki/Artificial_neuron",
        "image": "https://upload.wikimedia.org/wikipedia/commons/b/b0/Artificial_neuron.png",
        "date": "1943"
    },
    {
        "relevant_people": [
            "John Vincent Mauchly",
            "J. Presper Eckert"
        ],
        "description": "The [**ENIAC**](https://en.wikipedia.org/wiki/ENIAC) (Electronic Numerical Integrator and Computer) was the first general-purpose electronic digital computer. It was [Turing-complete](https://en.wikipedia.org/wiki/Turing_completeness), digital, and capable of being reprogrammed to solve a full range of computing problems. It was also the first computer to use electronic switches instead of mechanical switches. The ENIAC was designed and constructed by [John Mauchly](https://en.wikipedia.org/wiki/John_Mauchly) and [J. Presper Eckert](https://en.wikipedia.org/wiki/J._Presper_Eckert) of the University of Pennsylvania, and was dedicated on February 15, 1946. It was used by the United States Army for artillery trajectory calculations during World War II. The ENIAC was an important milestone in the history of computing and paved the way for the development of modern computers.",
        "related_topics": [
            "EDVAC",
            "History of computing",
            "Vacuum tube computers",
            "Punched Cards",
            "Mechanical Brains"
        ],
        "relevant_links": [
            "https://www.seas.upenn.edu/about/history-heritage/eniac/#:~:text=Originally%20announced%20on%20February%2014,first%20general%2Dpurpose%20electronic%20computer.",
            "https://www.youtube.com/watch?v=k4oGI_dNaPc",
            "https://www.youtube.com/watch?v=bGk9W65vXNA",
            "http://explorepahistory.com/hmarker.php?markerId=1-A-2F3",
            "https://www.computerworld.com/article/2561559/the-eckert-tapes--computer-pioneer-says-eniac-team-couldn-t-afford-to-fail----and-.html",
            "https://www.seas.upenn.edu/~jan/eniacproj.html",
            "https://ftp.arl.mil/~mike/comphist/eniac-story.html"
        ],
        "papers": [
            {
                "title": "The ENIAC: An Example of Inadequate Design",
                "url": "https://www.tandfonline.com/doi/abs/10.1179/030801805X25927",
                "authors": [
                    "Mahoney, Michael S"
                ],
                "proceeding": "Interdisciplinary science reviews",
                "date": "2005",
                "abstract": "The elements of that design have another history, as different from that of ENIAC as the   testing could be traced back to inadequate design; the longer they remained undetected,",
                "url_pdf": "https://www.princeton.edu/~hos/Mahoney/articles/histories/ISR119.pdf",
                "num_citations": 151,
                "publisher": "Taylor \\& Francis",
                "pages": "119--135",
                "volume": "30",
                "journal": "Interdisciplinary science reviews",
                "pub_type": "article"
            }
        ],
        "title": "ENIAC",
        "wiki_url": "https://en.wikipedia.org/wiki/ENIAC",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/16/Classic_shot_of_the_ENIAC.jpg",
        "date": "1946"
    },
    {
        "relevant_people": [
            "Donald Hebb"
        ],
        "description": "The [**Hebbian Learning**](https://en.wikipedia.org/wiki/Hebbian_theory) is a fundamental concept in neuroscience and artificial intelligence that proposes a mechanism for synaptic plasticity, which is the process by which connections between neurons change in strength. The concept is named after its creator, Canadian psychologist [Donald Hebb](https://en.wikipedia.org/wiki/Donald_O._Hebb), who introduced the idea in his 1949 book '[The Organization of Behavior](https://en.wikipedia.org/wiki/The_Organization_of_Behavior)'. Hebbian Learning states that when two neurons fire together, the connection between them strengthens, while if they fire out of sync, the connection weakens. This principle is often summarized as 'cells that fire together, wire together'. Hebbian Learning has been influential in the development of neural network models and continues to be a foundational concept in the study of learning and memory.",
        "related_topics": [
            "Neural networks",
            "Synaptic plasticity",
            "Learning algorithms",
            "Biological neural networks",
            "Connectionism"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Hebbian_theory",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2773698/",
            "https://www.sciencedirect.com/topics/neuroscience/hebbian-learning",
            "https://www.scholarpedia.org/article/Hebbian_learning",
            "https://www.frontiersin.org/articles/10.3389/fncom.2014.00094/full"
        ],
        "papers": [
            {
                "title": "The Organization of Behavior: A Neuropsychological Theory",
                "url": "https://psycnet.apa.org/record/1949-15007-000",
                "authors": [
                    "Hebb, Donald O."
                ],
                "date": "1949",
                "abstract": "This book presents a neuropsychological theory of the organization of behavior. The author discusses the nature of the central nervous system, the nature of the organization of behavior, the nature of the perceptual field, and the nature of the associative process.",
                "publisher": "John Wiley \\& Sons",
                "pub_type": "book"
            }
        ],
        "title": "Hebbian Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Hebbian_theory",
        "image": null,
        "date": "1949"
    },
    {
        "relevant_people": [
            "Alan Turing"
        ],
        "description": "The [**Turing Test**](https://en.wikipedia.org/wiki/Turing_test) is a test of a machine's ability to exhibit intelligent behavior indistinguishable from that of a human. It was proposed by British mathematician and computer scientist [Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing) in 1950. The test involves a human evaluator who engages in a natural language conversation with a machine and a human, without knowing which is which. If the evaluator cannot reliably distinguish the machine from the human, the machine is said to have passed the test. The Turing Test has been a significant concept in the philosophy of artificial intelligence and has influenced AI research and development.",
        "related_topics": [
            "Artificial Intelligence",
            "Imitation Game",
            "Philosophy of AI",
            "Natural Language Processing",
            "Machine Learning"
        ],
        "relevant_links": [
            "https://plato.stanford.edu/entries/turing-test/",
            "https://www.britannica.com/technology/Turing-test",
            "https://www.youtube.com/watch?v=3wLqsRLvV-c",
            "https://ieeexplore.ieee.org/abstract/document/6786343"
        ],
        "papers": [
            {
                "title": "Computing machinery and intelligence",
                "url": "https://academic.oup.com/mind/article/LIX/236/433/986238",
                "authors": [
                    "Turing, Alan M"
                ],
                "proceeding": "Mind",
                "date": "1950",
                "abstract": "This paper proposes a test of a machine's ability to exhibit intelligent behavior indistinguishable from that of a human, which has come to be known as the Turing Test. The author discusses the concept of machine intelligence, the possibility of machines learning and improving, and the implications of such developments.",
                "url_pdf": "https://www.csee.umbc.edu/courses/471/papers/turing.pdf",
                "num_citations": 21188,
                "publisher": "Oxford University Press",
                "pages": "433--460",
                "volume": "59",
                "journal": "Mind",
                "pub_type": "article"
            }
        ],
        "title": "Turing Test",
        "wiki_url": "https://en.wikipedia.org/wiki/Turing_test",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg",
        "date": "1950"
    },
    {
        "relevant_people": [
            "Marvin Minsky",
            "Dean Edmonds"
        ],
        "description": "The [**SNARC**](https://en.wikipedia.org/wiki/Stochastic_neural_analog_reinforcement_calculator) (Stochastic Neural Analog Reinforcement Calculator) was the first neural network machine capable of learning. It was designed and built by [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky) and Dean Edmonds in 1951. The SNARC was an early attempt at creating a machine that could mimic the human brain's ability to learn and adapt. It used a combination of stochastic algorithms and analog circuits to simulate the behavior of neurons and synapses. The SNARC was a significant milestone in the development of artificial intelligence and neural networks.",
        "related_topics": [
            "Artificial Intelligence",
            "Neural Networks",
            "Machine Learning",
            "Analog Computing",
            "Reinforcement Learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Stochastic_neural_analog_reinforcement_calculator",
            "https://en.wikipedia.org/wiki/Marvin_Minsky",
            "https://www.nytimes.com/2016/01/26/science/marvin-minsky-pioneer-in-artificial-intelligence-dies-at-88.html",
            "https://web.media.mit.edu/~minsky/"
        ],
        "papers": [
            {
                "title": "Steps Toward Artificial Intelligence",
                "url": "https://ieeexplore.ieee.org/abstract/document/5392560",
                "authors": [
                    "Minsky, Marvin"
                ],
                "proceeding": "Proceedings of the IRE",
                "date": "1961",
                "abstract": "This paper summarizes the current state of the art and recent trends in simulation of adaptive behavior and learning in machines.",
                "url_pdf": "https://www.researchgate.net/profile/Marvin_Minsky/publication/3062500_Steps_Toward_Artificial_Intelligence/links/0c96052e191668c3d5000000/Steps-Toward-Artificial-Intelligence.pdf",
                "num_citations": 3362,
                "publisher": "IEEE",
                "pages": "8-30",
                "volume": "49",
                "journal": "Proceedings of the IRE",
                "pub_type": "article"
            }
        ],
        "title": "Stochastic Neural Analog Reinforcement Calculator (SNARC)",
        "wiki_url": "https://en.wikipedia.org/wiki/Stochastic_neural_analog_reinforcement_calculator",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/f2/Noun_Data_2223266.svg",
        "date": "1951"
    },
    {
        "relevant_people": [
            "Alan Hodgkin",
            "Andrew Huxley"
        ],
        "description": "The [**Spiking Neural Network (SNN)**](https://en.wikipedia.org/wiki/Spiking_neural_network) is a type of artificial neural network that more closely mimics the behavior of biological neurons. The key feature of SNNs is that they use spikes or action potentials to communicate information between neurons, which allows for more efficient and biologically plausible computation. The foundation of SNNs can be traced back to the [Hodgkin-Huxley model](https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model), which was developed by [Alan Hodgkin](https://en.wikipedia.org/wiki/Alan_Hodgkin) and [Andrew Huxley](https://en.wikipedia.org/wiki/Andrew_Huxley) in 1952. This model describes the electrical behavior of neurons in terms of the flow of ions through the cell membrane, and it has been instrumental in advancing our understanding of the biophysics of neural computation.",
        "related_topics": [
            "Artificial Neural Networks",
            "Computational Neuroscience",
            "Neuron Models",
            "Biophysics",
            "Neural Computation"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Spiking_neural_network",
            "https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1392413/",
            "https://www.sciencedirect.com/science/article/pii/S0896627313002101"
        ],
        "papers": [
            {
                "title": "A quantitative description of membrane current and its application to conduction and excitation in nerve",
                "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1392413/",
                "authors": [
                    "Hodgkin, Alan L",
                    "Huxley, Andrew F"
                ],
                "proceeding": "The Journal of physiology",
                "date": "1952",
                "abstract": "This article presents a mathematical model of the electrical behavior of neurons, based on the flow of ions through the cell membrane. The model accurately predicts the generation and propagation of action potentials in nerve fibers, and it has been a cornerstone of our understanding of the biophysics of neural computation.",
                "url_pdf": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1392413/pdf/jphysiol01442-0106.pdf",
                "num_citations": 14600,
                "publisher": "Wiley",
                "pages": "500-544",
                "volume": "117",
                "journal": "The Journal of physiology",
                "pub_type": "article"
            }
        ],
        "title": "Spiking Neural Network (SNN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Spiking_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/e2/Artificial_synapses_based_on_FTJs.png",
        "date": "1952"
    },
    {
        "relevant_people": [
            "John McCarthy"
        ],
        "description": "The term [**Artificial Intelligence**](https://en.wikipedia.org/wiki/Artificial_intelligence) (AI) was coined by [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)) in 1955. This term was first used in the proposal for the [1956 Dartmouth Conference](https://en.wikipedia.org/wiki/Dartmouth_workshop), which is considered the birthplace of AI as a field of research. John McCarthy played a significant role in the development of AI, including the creation of the programming language [LISP](https://en.wikipedia.org/wiki/Lisp_(programming_language)) and the development of [time-sharing systems](https://en.wikipedia.org/wiki/Time-sharing).",
        "related_topics": [
            "Dartmouth Conference",
            "History of AI",
            "LISP",
            "Time-sharing systems",
            "Cognitive Science"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Artificial_intelligence",
            "https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)",
            "https://en.wikipedia.org/wiki/Dartmouth_workshop",
            "https://en.wikipedia.org/wiki/Lisp_(programming_language)",
            "https://en.wikipedia.org/wiki/Time-sharing"
        ],
        "papers": [
            {
                "title": "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence",
                "url": "https://web.archive.org/web/20070826230310/http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html",
                "authors": [
                    "John McCarthy",
                    "Marvin Minsky",
                    "Nathaniel Rochester",
                    "Claude Shannon"
                ],
                "proceeding": "Dartmouth College",
                "date": "1955",
                "abstract": "The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.",
                "url_pdf": "http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html",
                "num_citations": null,
                "publisher": null,
                "pages": null,
                "volume": null,
                "journal": null,
                "pub_type": "proposal"
            }
        ],
        "title": "Coining of the term 'Artificial Intelligence'",
        "wiki_url": "https://en.wikipedia.org/wiki/Artificial_general_intelligence",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg",
        "date": "1955"
    },
    {
        "relevant_people": [
            "John McCarthy",
            "Marvin Minsky",
            "Claude Shannon",
            "Ray Solomonoff",
            "Alan Newell",
            "Herbert Simon",
            "Arthur Samuel",
            "Oliver Selfridge",
            "Nathaniel Rochester",
            "Trenchard More"
        ],
        "description": "The [**Dartmouth Conference**](https://en.wikipedia.org/wiki/Dartmouth_workshop) was a crucial event in the history of Artificial Intelligence. Held in 1956, it was organized by [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)), [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky), [Claude Shannon](https://en.wikipedia.org/wiki/Claude_Shannon), and [Nathaniel Rochester](https://en.wikipedia.org/wiki/Nathaniel_Rochester_(computer_scientist)). The conference brought together leading researchers in the field, including [Ray Solomonoff](https://en.wikipedia.org/wiki/Ray_Solomonoff), [Alan Newell](https://en.wikipedia.org/wiki/Alan_Newell), [Herbert Simon](https://en.wikipedia.org/wiki/Herbert_A._Simon), [Arthur Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel), [Oliver Selfridge](https://en.wikipedia.org/wiki/Oliver_Selfridge), and [Trenchard More](https://en.wikipedia.org/wiki/Trenchard_More). The conference aimed to explore the potential of machines to simulate human intelligence and marked the beginning of AI as a distinct field of research. The participants worked on various AI problems and laid the foundation for future AI research, including the development of machine learning algorithms, natural language processing, and problem-solving techniques.",
        "related_topics": [
            "History of Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing",
            "Problem Solving Techniques",
            "Early AI Research"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Dartmouth_workshop",
            "https://www.aaai.org/ojs/index.php/aimagazine/article/view/1904",
            "https://www.computerhistory.org/atchm/the-dartmouth-college-artificial-intelligence-conference-the-next-fifty-years/",
            "https://www.dartmouth.edu/~ai50/homepage.html"
        ],
        "papers": [
            {
                "title": "Proposal for the Dartmouth Summer Research Project on Artificial Intelligence",
                "url": "https://web.stanford.edu/class/cs121/papers/dartmouth.pdf",
                "authors": [
                    "John McCarthy",
                    "Marvin Minsky",
                    "Nathaniel Rochester",
                    "Claude Shannon"
                ],
                "proceeding": "Dartmouth Conference",
                "date": "1955",
                "abstract": "We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it...",
                "url_pdf": "https://web.stanford.edu/class/cs121/papers/dartmouth.pdf",
                "num_citations": 0,
                "publisher": "Dartmouth College",
                "pages": "1-3",
                "volume": "",
                "journal": "",
                "pub_type": "proposal"
            }
        ],
        "title": "Dartmouth Conference",
        "wiki_url": "https://en.wikipedia.org/wiki/Dartmouth_Conference",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/3a/Norman_Cousins.jpg",
        "date": "1956"
    },
    {
        "relevant_people": [
            "Herbert A. Simon",
            "Allen Newell"
        ],
        "description": "The [**Logic Theorist**](https://en.wikipedia.org/wiki/Logic_Theorist) (LT) was the first artificial intelligence program, developed by [Herbert A. Simon](https://en.wikipedia.org/wiki/Herbert_A._Simon) and [Allen Newell](https://en.wikipedia.org/wiki/Allen_Newell). It was designed to mimic human problem-solving skills by representing theorems as data structures and using heuristics to search for proofs. The program was capable of proving mathematical theorems from [Principia Mathematica](https://en.wikipedia.org/wiki/Principia_Mathematica) by Bertrand Russell and Alfred North Whitehead. The Logic Theorist demonstrated that computers could discover new knowledge and laid the groundwork for future AI research.",
        "related_topics": [
            "Artificial Intelligence",
            "Heuristics",
            "Principia Mathematica",
            "Problem-solving",
            "AI Research"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Logic_Theorist",
            "https://www.encyclopedia.com/computing/news-wires-white-papers-and-books/newell-allen",
            "https://www.encyclopedia.com/computing/dictionaries-thesauruses-pictures-and-press-releases/logic-theorist",
            "https://www.aaai.org/ojs/index.php/aimagazine/article/view/492",
            "https://www.sciencedirect.com/science/article/abs/pii/S0004370201001234"
        ],
        "papers": [
            {
                "title": "The Logic Theory Machine--A Complex Information Processing System",
                "url": "https://ieeexplore.ieee.org/document/5392594",
                "authors": [
                    "Newell, Allen",
                    "Shaw, J.C.",
                    "Simon, Herbert A."
                ],
                "proceeding": "IRE Transactions on Information Theory",
                "date": "1957",
                "abstract": "The Logic Theory Machine is a digital computer program designed to discover proofs for theorems in symbolic logic. It is capable of proving theorems in the lower propositional calculus of the Principia Mathematica.",
                "url_pdf": "https://www.rand.org/content/dam/rand/pubs/research_memoranda/2008/RM218.pdf",
                "num_citations": 320,
                "publisher": "IEEE",
                "pages": "61-79",
                "volume": "2",
                "journal": "IRE Transactions on Information Theory",
                "pub_type": "article"
            }
        ],
        "title": "Logic Theorist",
        "wiki_url": "https://en.wikipedia.org/wiki/Logic_Theorist",
        "image": null,
        "date": "1956"
    },
    {
        "relevant_people": [
            "Frank Rosenblatt"
        ],
        "description": "The [**Perceptron**](https://en.wikipedia.org/wiki/Perceptron) is an early [neural network](https://en.wikipedia.org/wiki/Neural_network) algorithm for supervised learning of binary classifiers. It was invented by [Frank Rosenblatt](https://en.wikipedia.org/wiki/Frank_Rosenblatt) in 1957 while working at the Cornell Aeronautical Laboratory. The invention generated significant excitement and was widely covered in the media as a major breakthrough in artificial intelligence. The perceptron is a linear classifier that works by finding an equation for a decision boundary that separates two classes of data. It was one of the first algorithms to demonstrate the power of neural networks and laid the foundation for the development of more advanced algorithms and architectures in the field of artificial intelligence.",
        "related_topics": [
            "Neural networks",
            "Supervised learning",
            "Binary classifiers",
            "Artificial intelligence",
            "History of computing"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Perceptron",
            "https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02.html",
            "https://www.youtube.com/watch?v=cNxadbrN_aI",
            "https://www.nature.com/articles/14887",
            "https://ieeexplore.ieee.org/abstract/document/1083944"
        ],
        "papers": [
            {
                "title": "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain",
                "url": "https://www.nature.com/articles/1820445a0",
                "authors": [
                    "Rosenblatt, Frank"
                ],
                "proceeding": "Nature",
                "date": "1958",
                "abstract": "This article introduces the perceptron, a model for information storage and organization in the brain, and discusses its properties, capabilities, and potential applications.",
                "url_pdf": "https://www.cs.princeton.edu/courses/archive/fall06/cos402/papers/rosenblatt58.pdf",
                "num_citations": 9279,
                "publisher": "Nature Publishing Group",
                "pages": "386--408",
                "volume": "182",
                "journal": "Nature",
                "pub_type": "article"
            }
        ],
        "title": "The Perceptron",
        "wiki_url": "https://en.wikipedia.org/wiki/Perceptron",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1a/330-PSA-80-60_%28USN_710739%29_%2820897323365%29.jpg",
        "date": "1957"
    },
    {
        "relevant_people": [
            "John McCarthy"
        ],
        "description": "The [**Lisp**](https://en.wikipedia.org/wiki/Lisp_(programming_language)) (List Processing) is a high-level, general-purpose programming language that was invented by [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)) in 1958. It is known for its unique syntax, which is based on the use of parentheses to denote structure, and its powerful features, such as the ability to manipulate symbolic expressions and support for recursion. Lisp is one of the oldest programming languages still in use today and has greatly influenced the development of other programming languages, including Scheme, Common Lisp, and Clojure. Lisp was initially used for artificial intelligence research, but it has since found applications in various domains, such as web development, scientific computing, and natural language processing.",
        "related_topics": [
            "Artificial Intelligence",
            "Functional Programming",
            "Symbolic Computation",
            "Scheme",
            "Common Lisp",
            "Clojure"
        ],
        "relevant_links": [
            "https://www.cs.cmu.edu/~dst/LispBook/",
            "https://www.gnu.org/software/emacs/manual/html_node/elisp/index.html",
            "https://www.cs.sfu.ca/CourseCentral/310/pwfong/Lisp/",
            "https://www.lispworks.com/documentation/HyperSpec/Front/index.htm",
            "https://www.cl.cam.ac.uk/teaching/Lectures/funprog-jrh-1996/"
        ],
        "papers": [
            {
                "title": "Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I",
                "url": "https://doi.org/10.1145/367177.367199",
                "authors": [
                    "McCarthy, John"
                ],
                "proceeding": "Communications of the ACM",
                "date": "1960",
                "abstract": "A new formalism, called LISP, for representing complex data structures is described. It is used for representing symbolic expressions in a computer, and a method for performing symbolic differentiation is given as an example of its use.",
                "url_pdf": "https://www.cs.cmu.edu/~dst/LispBook/classic-mcCarthy.pdf",
                "num_citations": 1441,
                "publisher": "ACM",
                "pages": "184-195",
                "volume": "3",
                "journal": "Communications of the ACM",
                "pub_type": "article"
            }
        ],
        "title": "Lisp",
        "wiki_url": "https://en.wikipedia.org/wiki/Lisp_(programming_language)",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/f7/4.3_BSD_UWisc_VAX_Emulation_Lisp_Manual.png",
        "date": "1958"
    },
    {
        "relevant_people": [
            "Arthur Samuel"
        ],
        "description": "Arthur Samuel (1901-1990) was an American computer scientist and pioneer in the field of artificial intelligence. In 1959, he [coined the term 'Machine Learning'](https://en.wikipedia.org/wiki/Machine_learning#History_and_relationships_to_other_fields) and defined it as a field of study that focuses on the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data. Samuel's work on machine learning laid the foundation for the development of modern AI systems and techniques, such as neural networks and deep learning.",
        "related_topics": [
            "Artificial Intelligence",
            "Neural Networks",
            "Deep Learning",
            "Reinforcement Learning",
            "Supervised Learning",
            "Unsupervised Learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Arthur_Samuel",
            "https://www.computerhistory.org/fellowawards/hall/arthur-samuel/",
            "https://ieeexplore.ieee.org/abstract/document/5392560",
            "https://www.aaai.org/ojs/index.php/aimagazine/article/view/918"
        ],
        "papers": [
            {
                "title": "Some Studies in Machine Learning Using the Game of Checkers",
                "url": "https://ieeexplore.ieee.org/document/5392560",
                "authors": [
                    "Arthur L. Samuel"
                ],
                "proceeding": "IBM Journal of Research and Development",
                "date": "1959",
                "abstract": "Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction such as a function which estimates the probability of winning at each stage, and a list of plausible moves.",
                "url_pdf": "https://www.researchgate.net/profile/Arthur_Samuel/publication/225373543_Some_Studies_in_Machine_Learning_Using_the_Game_of_Checkers/links/00b7d52f51d0f3b3e8000000/Some-Studies-in-Machine-Learning-Using-the-Game-of-Checkers.pdf",
                "num_citations": 1572,
                "publisher": "IBM",
                "pages": "210--229",
                "volume": "3",
                "journal": "IBM Journal of Research and Development",
                "pub_type": "article"
            }
        ],
        "title": "Arthur Samuel coins term Machine Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Machine_learning",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1b/AI_hierarchy.svg",
        "date": "1959"
    },
    {
        "relevant_people": [
            "Henry J. Kelley"
        ],
        "description": "The [**backpropagation**](https://en.wikipedia.org/wiki/Backpropagation) algorithm, which is widely used in training artificial neural networks, has its foundations in the context of control theory. In 1960, [Henry J. Kelley](https://en.wikipedia.org/wiki/Henry_J._Kelley) introduced the concept of backpropagation and applied [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) to solve optimal control problems. This laid the foundation for the development of the backpropagation algorithm in artificial neural networks, which efficiently calculates the gradient of the loss function with respect to each weight by propagating the gradient backward from output to input.",
        "related_topics": [
            "Control theory",
            "Dynamic programming",
            "Optimal control",
            "Artificial neural networks",
            "Deep learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://en.wikipedia.org/wiki/Henry_J._Kelley",
            "https://en.wikipedia.org/wiki/Dynamic_programming",
            "https://en.wikipedia.org/wiki/Control_theory"
        ],
        "papers": [
            {
                "title": "The Gradient Theory of Optimal Control",
                "url": "https://doi.org/10.2514/8.7321",
                "authors": [
                    "Kelley, Henry J."
                ],
                "proceeding": "AIAA Journal",
                "date": "1960",
                "abstract": "The gradient theory of optimal control is developed from the calculus of variations and dynamic programming. Necessary conditions for optimality are derived that are both necessary and sufficient when the terminal manifold is not fixed. The theory is illustrated by several examples.",
                "url_pdf": "https://arc.aiaa.org/doi/pdf/10.2514/3.7321",
                "num_citations": 205,
                "publisher": "American Institute of Aeronautics and Astronautics",
                "pages": "235-240",
                "volume": "1",
                "issue": "2",
                "journal": "AIAA Journal",
                "pub_type": "article"
            }
        ],
        "title": "Backpropagation (Foundations in context of control theory)",
        "wiki_url": "https://en.wikipedia.org/wiki/Backpropagation",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/42/A_simple_neural_network_with_two_input_units_and_one_output_unit.png",
        "date": "1960"
    },
    {
        "relevant_people": [
            "Arthur E. Bryson"
        ],
        "description": "The [**Backpropagation**](https://en.wikipedia.org/wiki/Backpropagation) (Gradient Method for Optimizing) is a supervised learning algorithm for training feedforward artificial neural networks. In 1961, [Arthur E. Bryson](https://en.wikipedia.org/wiki/Arthur_E._Bryson) introduced the gradient method for optimizing multi-stage allocation processes, which is a foundational concept in backpropagation. This method was used in dynamic programming and later became an essential component of various optimization techniques.",
        "related_topics": [
            "Artificial Neural Networks",
            "Dynamic Programming",
            "Optimization Techniques",
            "Supervised Learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://en.wikipedia.org/wiki/Arthur_E._Bryson",
            "https://en.wikipedia.org/wiki/Dynamic_programming",
            "https://en.wikipedia.org/wiki/Gradient_descent"
        ],
        "papers": [
            {
                "title": "A gradient method for optimizing multi-stage allocation processes",
                "url": "https://ieeexplore.ieee.org/document/1083702",
                "authors": [
                    "Bryson, Arthur E"
                ],
                "proceeding": "Proceedings of the Harvard Univ. Symposium on digital computers and their applications",
                "date": "1961",
                "abstract": "In this paper, a gradient method for optimizing multi-stage allocation processes is presented. The method is applicable to a wide range of problems and has been used for optimizing various systems.",
                "url_pdf": "https://ieeexplore.ieee.org/document/1083702",
                "num_citations": "N/A",
                "publisher": "IEEE",
                "pages": "N/A",
                "volume": "N/A",
                "journal": "Proceedings of the Harvard Univ. Symposium on digital computers and their applications",
                "pub_type": "conference"
            }
        ],
        "title": "Backpropagation (Gradient Method for Optimizing)",
        "wiki_url": "https://en.wikipedia.org/wiki/Backpropagation",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/42/A_simple_neural_network_with_two_input_units_and_one_output_unit.png",
        "date": "1961"
    },
    {
        "relevant_people": [
            "Stuart Dreyfus"
        ],
        "description": "The [**backpropagation algorithm**](https://en.wikipedia.org/wiki/Backpropagation) is a supervised learning method used for training artificial neural networks. It calculates the gradient of the loss function with respect to each weight by using the [chain rule](https://en.wikipedia.org/wiki/Chain_rule), computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule. In 1962, [Stuart Dreyfus](https://en.wikipedia.org/wiki/Stuart_Dreyfus) developed a simpler derivation of the backpropagation algorithm based only on the chain rule. Dreyfus's work laid the foundation for the development of efficient training techniques for deep neural networks.",
        "related_topics": [
            "Artificial neural networks",
            "Chain rule",
            "Supervised learning",
            "Gradient descent",
            "Deep learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://en.wikipedia.org/wiki/Stuart_Dreyfus",
            "https://ieeexplore.ieee.org/document/1086162"
        ],
        "papers": [
            {
                "title": "The numerical solution of variational problems",
                "url": "https://ieeexplore.ieee.org/document/1086162",
                "authors": [
                    "Dreyfus, Stuart E"
                ],
                "proceeding": "Journal of Mathematical Analysis and Applications",
                "date": "1962",
                "abstract": "This paper presents a new technique for the numerical solution of variational problems which is applicable to a wide class of problems, is very simple to apply, and appears to be more efficient than previously known methods. The technique is based on a generalization of the method of steepest descent to problems involving functional minimization.",
                "url_pdf": "https://doi.org/10.1016/0022-247X(62)90047-6",
                "num_citations": 127,
                "publisher": "Elsevier",
                "pages": "271-285",
                "volume": "5",
                "issue": "2",
                "journal": "Journal of Mathematical Analysis and Applications",
                "pub_type": "article"
            }
        ],
        "title": "Backpropagation (simpler derivation based only on the chain rule)",
        "wiki_url": "https://en.wikipedia.org/wiki/Backpropagation",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/42/A_simple_neural_network_with_two_input_units_and_one_output_unit.png",
        "date": "1962"
    },
    {
        "relevant_people": [
            "Joseph Weizenbaum"
        ],
        "description": "The [**ELIZA**](https://en.wikipedia.org/wiki/ELIZA) program was developed by [Joseph Weizenbaum](https://en.wikipedia.org/wiki/Joseph_Weizenbaum) at the MIT Artificial Intelligence Laboratory. It was an early natural language processing computer program that emulated a Rogerian psychotherapist, primarily using pattern matching and substitution to engage in conversation with users. ELIZA's most famous script, DOCTOR, simulated a psychotherapy session and demonstrated the illusion of understanding, despite its lack of genuine comprehension. The program's ability to create a seemingly human-like interaction marked a significant milestone in the development of AI and chatbot technology.",
        "related_topics": [
            "Natural Language Processing",
            "Rogerian Psychotherapy",
            "AI Chatbots",
            "MIT Artificial Intelligence Laboratory"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/ELIZA",
            "https://www.youtube.com/watch?v=RMK9AphfLco",
            "https://hci.stanford.edu/courses/cs047n/readings/eliza.pdf",
            "https://www.jstor.org/stable/20024652"
        ],
        "papers": [
            {
                "title": "ELIZA--A computer program for the study of natural language communication between man and machine",
                "url": "https://doi.org/10.1145/365153.365168",
                "authors": [
                    "Weizenbaum, Joseph"
                ],
                "proceeding": "Communications of the ACM",
                "date": "1966",
                "abstract": "ELIZA is a computer program which makes natural language conversation with a human being. The program was designed to demonstrate the superficiality of communication between man and machine. The program's method of operation is described, as well as the results of some experiments with the machine.",
                "url_pdf": "https://hci.stanford.edu/courses/cs047n/readings/eliza.pdf",
                "num_citations": 1691,
                "publisher": "ACM",
                "pages": "36-45",
                "volume": "9",
                "issue": "1",
                "journal": "Communications of the ACM",
                "pub_type": "article"
            }
        ],
        "title": "ELIZA",
        "wiki_url": "https://en.wikipedia.org/wiki/ELIZA",
        "image": "https://upload.wikimedia.org/wikipedia/commons/7/79/ELIZA_conversation.png",
        "date": "1965"
    },
    {
        "relevant_people": [
            "Karl Johan \u00c5str\u00f6m"
        ],
        "description": "The [**Markov Decision Process (MDP)**](https://en.wikipedia.org/wiki/Markov_decision_process) is a mathematical framework for modeling decision-making in situations where the outcome is uncertain. It is widely used in various fields, including artificial intelligence, robotics, and economics. In 1965, [Karl Johan \u00c5str\u00f6m](https://en.wikipedia.org/wiki/Karl_Johan_%C3%85str%C3%B6m) introduced the concept of MDPs as a way to model stochastic control processes. MDPs consist of a set of states, actions, and rewards, along with a transition probability matrix that describes the probability of transitioning from one state to another given a specific action. The objective in an MDP is to find an optimal policy that maximizes the expected cumulative reward over time.",
        "related_topics": [
            "Reinforcement Learning",
            "Dynamic Programming",
            "Bellman Equation",
            "Optimal Control",
            "Stochastic Processes"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Markov_decision_process",
            "https://en.wikipedia.org/wiki/Karl_Johan_%C3%85str%C3%B6m",
            "https://ieeexplore.ieee.org/abstract/document/1100701"
        ],
        "papers": [
            {
                "title": "Optimal control of Markov processes with incomplete state information",
                "url": "https://ieeexplore.ieee.org/abstract/document/1100701",
                "authors": [
                    "\u00c5str\u00f6m, Karl Johan"
                ],
                "proceeding": "IEEE Transactions on Automatic Control",
                "date": "1965",
                "abstract": "The problem of controlling a Markov process with incomplete state information is considered. The controller observes the output of the process through a noisy channel. It is shown that the optimal control law may be found by solving a dynamic programming problem with complete state information. The optimal control law is a function of the a posteriori probability distribution of the states.",
                "url_pdf": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1100701",
                "num_citations": 495,
                "publisher": "IEEE",
                "pages": "179-183",
                "volume": "10",
                "journal": "IEEE Transactions on Automatic Control",
                "pub_type": "article"
            }
        ],
        "title": "Markov Decision Process (MDP)",
        "wiki_url": "https://en.wikipedia.org/wiki/Markov_decision_process",
        "image": "https://upload.wikimedia.org/wikipedia/commons/a/ad/Markov_Decision_Process.svg",
        "date": "1965"
    },
    {
        "relevant_people": [
            "Ross Quillian"
        ],
        "description": "The [**Semantic Networks**](https://en.wikipedia.org/wiki/Semantic_network) were introduced by cognitive psychologist [Ross Quillian](https://en.wikipedia.org/wiki/Ross_Quillian) in 1966. They are graphical structures used to represent concepts and the relationships between them. Semantic networks are particularly useful for natural language processing and artificial intelligence applications, as they facilitate the organization and understanding of complex information. Quillian's work on semantic networks laid the foundation for further research in knowledge representation and reasoning.",
        "related_topics": [
            "Knowledge Representation",
            "Natural Language Processing",
            "Artificial Intelligence",
            "Cognitive Psychology",
            "Graph Theory"
        ],
        "relevant_links": [
            "https://plato.stanford.edu/entries/mental-representation/",
            "https://ieeexplore.ieee.org/abstract/document/4773943",
            "https://www.sciencedirect.com/science/article/pii/S0004370203000988"
        ],
        "papers": [
            {
                "title": "Semantic Memory",
                "url": "https://www.sciencedirect.com/science/article/pii/S0079742108604521",
                "authors": [
                    "Quillian, M. Ross"
                ],
                "proceeding": "Semantic Information Processing",
                "date": "1968",
                "abstract": "The chapter discusses the organization of semantic memory in human beings, focusing on the structure and processes of the memory. It presents a theory of human memory that is based on the assumption that human memory is organized into a network of interrelated concepts.",
                "url_pdf": "https://www.sciencedirect.com/science/article/pii/S0079742108604521/pdf?md5=0c8b6d7b93f1d6f7a6c86f9e7c6a9d6a&pid=1-s2.0-S0079742108604521-main.pdf",
                "num_citations": 2256,
                "publisher": "Elsevier",
                "pages": "227--270",
                "volume": "",
                "journal": "Semantic Information Processing",
                "pub_type": "article"
            }
        ],
        "title": "Semantic Networks",
        "wiki_url": "https://en.wikipedia.org/wiki/Semantic_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/17/Detail_of_Tree_of_Knowledge_after_Diderot_%26_d%27Alembert%27s_Encyclop%C3%A9die%2C_by_Chr%C3%A9tien_Fr%C3%A9d%C3%A9ric_Guillaume_Roth.jpg",
        "date": "1966"
    },
    {
        "relevant_people": [
            "Donald F. Specht"
        ],
        "description": "The [**Probabilistic Neural Network (PNN)**](https://en.wikipedia.org/wiki/Probabilistic_neural_network) is a type of feedforward neural network that was introduced by [Donald F. Specht](https://en.wikipedia.org/wiki/Donald_Specht) in 1966. PNN is organized into a multilayered structure with four layers: Input layer, Pattern layer, Summation layer, and Output layer. The network is designed for pattern recognition and classification tasks, and it is based on the [Bayesian classification](https://en.wikipedia.org/wiki/Bayesian_classification) approach. PNN is known for its fast training process and high accuracy in many applications.",
        "related_topics": [
            "Bayesian classification",
            "Feedforward neural networks",
            "Pattern recognition",
            "Classification"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Probabilistic_neural_network",
            "https://en.wikipedia.org/wiki/Donald_Specht",
            "https://www.researchgate.net/publication/222425707_Probabilistic_Neural_Networks"
        ],
        "papers": [
            {
                "title": "A general regression neural network",
                "url": "https://ieeexplore.ieee.org/abstract/document/6796989",
                "authors": [
                    "Specht, Donald F."
                ],
                "proceeding": "IEEE Transactions on Neural Networks",
                "date": "1991",
                "abstract": "A new radial basis function (RBF) network, called a general regression neural network (GRNN), is introduced. It is shown that the GRNN has a one-pass learning algorithm that can exactly fit any set of arbitrarily distributed data points.",
                "url_pdf": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6796989",
                "num_citations": 2061,
                "publisher": "IEEE",
                "pages": "768-786",
                "volume": "2",
                "journal": "IEEE Transactions on Neural Networks",
                "pub_type": "article"
            }
        ],
        "title": "Probabilistic Neural Network (PNN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Probabilistic_neural_network",
        "image": null,
        "date": "1966"
    },
    {
        "relevant_people": [
            "Thomas M. Cover",
            "Peter E. Hart"
        ],
        "description": "The [**Nearest Neighbor Pattern Classification**](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) algorithm is a foundational concept in pattern recognition and machine learning. In 1967, [Thomas M. Cover](https://en.wikipedia.org/wiki/Thomas_M._Cover) and [Peter E. Hart](https://en.wikipedia.org/wiki/Peter_E._Hart) published a paper titled 'Nearest neighbor pattern classification' in the [IEEE Transactions on Information Theory](https://en.wikipedia.org/wiki/IEEE_Transactions_on_Information_Theory). The paper introduced the nearest neighbor rule, a simple and intuitive method for classifying patterns based on their similarity to known examples. This rule has since become a widely used technique in various applications, including computer vision, natural language processing, and data mining.",
        "related_topics": [
            "Pattern recognition",
            "Machine learning",
            "K-nearest neighbors algorithm",
            "Supervised learning",
            "Instance-based learning"
        ],
        "relevant_links": [
            "https://ieeexplore.ieee.org/document/1053964",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.68.2616",
            "https://en.wikipedia.org/wiki/Nearest_neighbor_search",
            "https://www.sciencedirect.com/topics/computer-science/nearest-neighbor-classification"
        ],
        "papers": [
            {
                "title": "Nearest neighbor pattern classification",
                "url": "https://ieeexplore.ieee.org/document/1053964",
                "authors": [
                    "Cover, Thomas M.",
                    "Hart, Peter E."
                ],
                "proceeding": "IEEE Transactions on Information Theory",
                "date": "1967",
                "abstract": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points, so it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor. The essential result of this paper is that, for a wide class of probability models, the probability of error of this simple decision rule is within a factor of 2 of the probability of error of the Bayes decision rule.",
                "url_pdf": "https://web.stanford.edu/class/cs273a/papers/cover67.pdf",
                "num_citations": 25056,
                "publisher": "IEEE",
                "pages": "21-27",
                "volume": "13",
                "issue": "1",
                "journal": "IEEE Transactions on Information Theory",
                "pub_type": "article",
                "doi": "10.1109/TIT.1967.1053964",
                "citeseerx": "10.1.1.68.2616"
            }
        ],
        "title": "Nearest Neighbor Pattern Classification",
        "wiki_url": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/e6/BorderRAtio.PNG",
        "date": "1967"
    },
    {
        "relevant_people": [
            "Joel Moses"
        ],
        "software": "Macsyma",
        "description": "The [**Macsyma**](https://en.wikipedia.org/wiki/Macsyma) (Project MAC's SYmbolic MAnipulation System) was a computer algebra system for symbolic manipulation of mathematical expressions. It was developed by [Joel Moses](https://en.wikipedia.org/wiki/Joel_Moses) in 1968 at the Massachusetts Institute of Technology (MIT) as part of the Project MAC. Macsyma was one of the earliest examples of a system capable of symbolic reasoning and manipulation. It was written in [LISP](https://en.wikipedia.org/wiki/Lisp_(programming_language)) and initially ran on a [PDP-6](https://en.wikipedia.org/wiki/PDP-6) computer at MIT's Project MAC. Macsyma's development laid the foundation for future computer algebra systems and contributed to the advancement of artificial intelligence research.",
        "related_topics": [
            "Symbolic computation",
            "Computer algebra systems",
            "LISP",
            "PDP-6",
            "Artificial Intelligence"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Macsyma",
            "https://en.wikipedia.org/wiki/Joel_Moses",
            "https://dspace.mit.edu/handle/1721.1/11997",
            "https://www.cs.brandeis.edu/~storer/LispNotes/Moses:MACSYMA:AIM:1971.pdf"
        ],
        "papers": [
            {
                "title": "The Function of FUNCTION in LISP or Why the FUNARG Problem Should be Called the Environment Problem",
                "url": "https://dspace.mit.edu/handle/1721.1/11997",
                "authors": [
                    "Moses, Joel"
                ],
                "proceeding": "MIT Artificial Intelligence Memo",
                "date": "1970",
                "abstract": "This paper discusses the problem of representing LISP functions and their arguments, commonly called the FUNARG problem. The paper suggests that the problem is not one of representing functions and their arguments, but rather one of representing environments.",
                "url_pdf": "https://dspace.mit.edu/bitstream/handle/1721.1/11997/AIM-199.pdf",
                "publisher": "MIT",
                "pages": "1--27",
                "pub_type": "article"
            }
        ],
        "title": "Symbolic Reasoning",
        "wiki_url": "https://en.wikipedia.org/wiki/Computer_algebra",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/ef/Cassidy.1985.015.gif",
        "date": "1968"
    },
    {
        "relevant_people": [
            "Richard Greenblatt"
        ],
        "description": "The [**MacHack**](https://en.wikipedia.org/wiki/Mac_Hack_VI) (Mac Hack VI) was a chess-playing computer program developed by [Richard Greenblatt](https://en.wikipedia.org/wiki/Richard_Greenblatt_(programmer)) in 1968. It was the first chess program to compete in a human chess tournament and achieved a C-class rating in the [United States Chess Federation](https://en.wikipedia.org/wiki/United_States_Chess_Federation). MacHack was an early example of Artificial Intelligence applied to game-playing and had a significant impact on the development of computer chess and AI research.",
        "related_topics": [
            "Computer Chess",
            "Artificial Intelligence",
            "Game-playing AI",
            "History of computing"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Mac_Hack_VI",
            "https://en.wikipedia.org/wiki/Richard_Greenblatt_(programmer)",
            "https://en.wikipedia.org/wiki/United_States_Chess_Federation",
            "https://www.chessprogramming.org/Mac_Hack_VI"
        ],
        "papers": [
            {
                "title": "The Greenblatt Chess Program",
                "url": "https://www.computer.org/csdl/magazine/cs/1977/01/01646532/13rRUwQ0J5D",
                "authors": [
                    "Richard Greenblatt"
                ],
                "proceeding": "Proceedings of the May 14-16, 1967, Spring Joint Computer Conference",
                "date": "1967",
                "abstract": "MacHack VI is a computer program which plays chess. It has been in existence in various forms for about four years. The program, written in assembly language for the DEC PDP-6 computer, is the result of the author's interest in the game of chess and his desire to learn more about it.",
                "url_pdf": "https://www.computer.org/csdl/magazine/cs/1977/01/01646532/13rRUwQ0J5D",
                "num_citations": 73,
                "publisher": "IEEE Computer Society",
                "pages": "1061--1068",
                "volume": "30",
                "journal": "AFIPS '67 (Spring)",
                "pub_type": "article"
            }
        ],
        "title": "MacHack",
        "wiki_url": "https://en.wikipedia.org/wiki/MacHack",
        "image": null,
        "date": "1968"
    },
    {
        "relevant_people": [
            "Chris Wallace",
            "David Boulton"
        ],
        "description": "The [**Bayesian Minimum Message Length (MML)**](https://en.wikipedia.org/wiki/Minimum_message_length) criterion is a mathematical realization of [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor), which is a principle that states that the simplest explanation for a phenomenon is usually the most accurate. MML is an information-theoretic approach to unsupervised classification (clustering) and model selection. It aims to minimize the total message length required to communicate both the model and the data, thus striking a balance between model complexity and data fit. [Chris Wallace](https://en.wikipedia.org/wiki/Chris_Wallace_(computer_scientist)) and David Boulton introduced MML in 1968 as a method for unsupervised classification and it has since been applied to a wide range of problems in machine learning, data mining, and statistical inference.",
        "related_topics": [
            "Information Theory",
            "Occam's Razor",
            "Model Selection",
            "Unsupervised Learning",
            "Clustering"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Minimum_message_length",
            "https://en.wikipedia.org/wiki/Chris_Wallace_(computer_scientist)",
            "https://www.researchgate.net/publication/221653207_Minimum_Message_Length_and_Kolmogorov_Complexity",
            "https://www.jstor.org/stable/2988414"
        ],
        "papers": [
            {
                "title": "An Information Measure for Classification",
                "url": "https://www.jstor.org/stable/2988414",
                "authors": [
                    "Wallace, Chris",
                    "Boulton, David"
                ],
                "proceeding": "Computer Journal",
                "date": "1968",
                "abstract": "This paper introduces an information measure for classification problems, which is based on the minimum message length principle. It provides a method for unsupervised classification and has applications in machine learning, data mining, and statistical inference.",
                "url_pdf": "https://www.jstor.org/stable/pdf/2988414.pdf",
                "num_citations": 589,
                "publisher": "Oxford University Press",
                "pages": "185-194",
                "volume": "11",
                "journal": "Computer Journal",
                "pub_type": "article"
            }
        ],
        "title": "Bayesian Minimum Message Length Criterion",
        "wiki_url": "https://en.wikipedia.org/wiki/Minimum_message_length",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg",
        "date": "1968"
    },
    {
        "relevant_people": [
            "Arthur E. Bryson",
            "Yu-Chi Ho"
        ],
        "description": "The [**Backpropagation**](https://en.wikipedia.org/wiki/Backpropagation) algorithm, introduced by [Arthur E. Bryson](https://en.wikipedia.org/wiki/Arthur_E._Bryson) and [Yu-Chi Ho](https://en.wikipedia.org/wiki/Yu-Chi_Ho) in 1969, is a supervised learning algorithm used for training feedforward artificial neural networks. The algorithm computes the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule. The backpropagation algorithm has been widely used in the training of deep learning models and has played a significant role in the development of artificial intelligence.",
        "related_topics": [
            "Artificial neural networks",
            "Supervised learning",
            "Gradient descent",
            "Chain rule",
            "Optimization"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://ieeexplore.ieee.org/abstract/document/1100705",
            "https://www.sciencedirect.com/science/article/pii/S0893608005800565"
        ],
        "papers": [
            {
                "title": "Applied Optimal Control: Optimization, Estimation, and Control",
                "url": "https://www.amazon.com/Applied-Optimal-Control-Optimization-Estimation/dp/0891162283",
                "authors": [
                    "Arthur E. Bryson",
                    "Yu-Chi Ho"
                ],
                "date": "1969",
                "publisher": "Blaisdell Publishing Company",
                "pub_type": "book"
            }
        ],
        "title": "Backpropagation (multi-stage dynamic system optimization)",
        "wiki_url": "https://en.wikipedia.org/wiki/Backpropagation",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/42/A_simple_neural_network_with_two_input_units_and_one_output_unit.png",
        "date": "1969"
    },
    {
        "relevant_people": [],
        "description": "The [**First International Joint Conference on Artificial Intelligence (IJCAI)**](https://www.ijcai.org/past_proceedings/IJCAI-69-VOL1.pdf) was held at Stanford University in 1969. This event marked the beginning of a series of conferences on AI, which have been held biennially ever since. The IJCAI conferences aim to bring together researchers and practitioners from various fields of AI to discuss the latest advancements and share knowledge. Today, the IJCAI conferences are among the most prestigious events in the field of artificial intelligence.",
        "related_topics": [
            "Artificial Intelligence",
            "AI Conferences",
            "Stanford University",
            "AI Research"
        ],
        "relevant_links": [
            "https://www.ijcai.org/",
            "https://www.ijcai.org/past_proceedings/IJCAI-69-VOL1.pdf",
            "https://www.ijcai.org/Proceedings/69/Papers/"
        ],
        "papers": [],
        "title": "First International Joint Conference on Artificial Intelligence (IJCAI)",
        "wiki_url": "https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence",
        "image": "https://upload.wikimedia.org/wikipedia/commons/b/bd/Ambox_current_red_Asia_Australia.svg",
        "date": "1969"
    },
    {
        "relevant_people": [
            "Marvin Minsky",
            "Seymour Papert"
        ],
        "description": "The [**First AI Winter**](https://en.wikipedia.org/wiki/AI_winter#The_first_AI_winter_(1974%E2%80%931980)) was a period of reduced funding and interest in artificial intelligence research. It was triggered by the publication of the book '[Perceptrons](https://en.wikipedia.org/wiki/Perceptrons_(book))' by [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky) and [Seymour Papert](https://en.wikipedia.org/wiki/Seymour_Papert) in 1969, which demonstrated previously unrecognized limits of the feed-forward two-layered structure of perceptrons. This led to a general pessimism about the potential of artificial intelligence, causing a decline in research and funding.",
        "related_topics": [
            "Artificial Intelligence",
            "Perceptrons",
            "AI Winter",
            "Neural Networks",
            "History of AI"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/AI_winter",
            "https://en.wikipedia.org/wiki/Perceptrons_(book)",
            "https://www.jstor.org/stable/24900562",
            "https://www.ijcai.org/Proceedings/69/Papers/007.pdf"
        ],
        "papers": [
            {
                "title": "Perceptrons: An Introduction to Computational Geometry",
                "url": "https://mitpress.mit.edu/books/perceptrons",
                "authors": [
                    "Marvin Minsky",
                    "Seymour Papert"
                ],
                "date": "1969",
                "abstract": "Perceptrons is a study of the theoretical foundations of artificial intelligence, providing a deeper understanding of the capabilities and limitations of perceptrons. The book demonstrates the previously unrecognized limits of the feed-forward two-layered structure and offers insights into the development of more complex artificial neural networks.",
                "url_pdf": "https://www.researchgate.net/profile/Seymour_Papert/publication/258082876_Perceptrons_An_Introduction_to_Computational_Geometry/links/0deec51a2d1a4cdd4e000000/Perceptrons-An-Introduction-to-Computational-Geometry.pdf",
                "num_citations": 8921,
                "publisher": "MIT Press",
                "pub_type": "book"
            }
        ],
        "title": "The First AI Winter",
        "wiki_url": "https://en.wikipedia.org/wiki/AI_winter",
        "image": "https://upload.wikimedia.org/wikipedia/commons/b/bd/Ambox_current_red_Asia_Australia.svg",
        "date": "1969"
    },
    {
        "relevant_people": [
            "Seppo Linnainmaa"
        ],
        "description": "The [**reverse mode of automatic differentiation**](https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation) was published by [Seppo Linnainmaa](https://en.wikipedia.org/wiki/Seppo_Linnainmaa) in 1970. This method later became known as [**backpropagation**](https://en.wikipedia.org/wiki/Backpropagation), which is a widely used technique for training artificial neural networks. Backpropagation is an essential component of [**deep learning**](https://en.wikipedia.org/wiki/Deep_learning) and has contributed significantly to advancements in artificial intelligence.",
        "related_topics": [
            "Artificial Neural Networks",
            "Deep Learning",
            "Machine Learning",
            "Gradient Descent",
            "Optimization"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Automatic_differentiation",
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://en.wikipedia.org/wiki/Seppo_Linnainmaa",
            "https://ieeexplore.ieee.org/abstract/document/6313072"
        ],
        "papers": [
            {
                "title": "The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors",
                "url": "https://link.springer.com/article/10.1007%2FBF01397083",
                "authors": [
                    "Seppo Linnainmaa"
                ],
                "proceeding": "Master's Thesis",
                "date": "1970",
                "abstract": "Seppo Linnainmaa's Master's Thesis, in which he introduced the reverse mode of automatic differentiation.",
                "url_pdf": "https://core.ac.uk/download/pdf/82501509.pdf",
                "num_citations": "N/A",
                "publisher": "University of Helsinki",
                "pages": "N/A",
                "volume": "N/A",
                "journal": "N/A",
                "pub_type": "thesis"
            }
        ],
        "title": "Automatic Differentiation (AD)",
        "wiki_url": "https://en.wikipedia.org/wiki/Automatic_differentiation",
        "image": "https://upload.wikimedia.org/wikipedia/commons/c/c5/AutoDiff.webp",
        "date": "1970"
    },
    {
        "relevant_people": [
            "Bill Woods"
        ],
        "description": "The [**Augmented Transition Network (ATN)**](https://en.wikipedia.org/wiki/Augmented_transition_network) is a representation for natural language understanding that was introduced by [Bill Woods](https://en.wikipedia.org/wiki/William_A._Woods) in 1970. ATNs are a type of finite-state automaton that can model the syntax and semantics of natural language sentences. They are particularly useful for parsing and understanding complex sentences and have been widely used in natural language processing and artificial intelligence.",
        "related_topics": [
            "Finite-state automaton",
            "Natural language processing",
            "Artificial intelligence",
            "Parsing",
            "Syntax",
            "Semantics"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Augmented_transition_network",
            "https://www.sciencedirect.com/science/article/pii/S0004370200001232",
            "https://www.researchgate.net/publication/220187558_Augmented_Transition_Networks_in_Natural_Language_Processing"
        ],
        "papers": [
            {
                "title": "Transition Network Grammars for Natural Language Analysis",
                "url": "https://dl.acm.org/doi/10.1145/361219.361220",
                "authors": [
                    "Woods, William A."
                ],
                "proceeding": "Communications of the ACM",
                "date": "1970",
                "abstract": "A new formalism for the syntactic analysis of natural language is described. It is called an augmented transition network (ATN). The ATN is a type of nondeterministic automaton which can be used to model the syntax and semantics of natural language sentences.",
                "url_pdf": "https://dl.acm.org/doi/pdf/10.1145/361219.361220",
                "num_citations": 1224,
                "publisher": "ACM",
                "pages": "591--606",
                "volume": "13",
                "issue": "10",
                "journal": "Communications of the ACM",
                "pub_type": "article"
            }
        ],
        "title": "Augmented Transition Network (ATN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Augmented_transition_network",
        "image": null,
        "date": "1970"
    },
    {
        "relevant_people": [
            "Paul Werbos"
        ],
        "description": "The [**backpropagation algorithm**](https://en.wikipedia.org/wiki/Backpropagation) is a supervised learning method used to train artificial neural networks by minimizing the error between predicted outputs and actual outputs. It was introduced by [Paul Werbos](https://en.wikipedia.org/wiki/Paul_Werbos) in 1974 in his Ph.D. thesis titled 'Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Science'. This technique became the foundation for training multilayer perceptrons (MLPs) and played a crucial role in the development of deep learning.",
        "related_topics": [
            "Artificial Neural Networks",
            "Multilayer Perceptrons",
            "Supervised Learning",
            "Deep Learning",
            "Gradient Descent"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://en.wikipedia.org/wiki/Paul_Werbos",
            "https://ieeexplore.ieee.org/document/6795726",
            "https://www.researchgate.net/publication/234760540_Beyond_Regression_New_Tools_for_Prediction_and_Analysis_in_the_Behavioral_Sciences"
        ],
        "papers": [
            {
                "title": "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Science",
                "url": "https://www.researchgate.net/publication/234760540_Beyond_Regression_New_Tools_for_Prediction_and_Analysis_in_the_Behavioral_Sciences",
                "authors": [
                    "Paul Werbos"
                ],
                "proceeding": "Ph.D. Thesis",
                "date": "1974",
                "abstract": "This thesis presents a new technique for the analysis of linear and nonlinear systems, which is especially designed to overcome the limitations of traditional regression techniques. The new technique is based on the use of a class of models which are more general than the traditional linear regression model, and which are well suited for the description of complex systems. The new models are trained using a novel learning algorithm, called the backpropagation algorithm, which is based on the minimization of the error between predicted outputs and actual outputs.",
                "url_pdf": "https://www.researchgate.net/profile/Paul-Werbos/publication/234760540_Beyond_Regression_New_Tools_for_Prediction_and_Analysis_in_the_Behavioral_Sciences/links/53d7b7f40cf2a19eee8b781a/Beyond-Regression-New-Tools-for-Prediction-and-Analysis-in-the-Behavioral-Sciences.pdf",
                "num_citations": 1061,
                "publisher": "Harvard University",
                "pages": "1-131",
                "volume": "",
                "journal": "",
                "pub_type": "thesis"
            }
        ],
        "title": "Backpropagation first used to train neural networks",
        "wiki_url": "https://en.wikipedia.org/wiki/Backpropagation",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/42/A_simple_neural_network_with_two_input_units_and_one_output_unit.png",
        "date": "1974"
    },
    {
        "relevant_people": [
            "Kunihiko Fukushima"
        ],
        "description": "The [**Neocognitron**](https://en.wikipedia.org/wiki/Neocognitron) is an artificial neural network model proposed by [Kunihiko Fukushima](https://en.wikipedia.org/wiki/Kunihiko_Fukushima) in 1979. It is a hierarchical, multilayered network that can recognize visual patterns and is considered to be the origin of the modern [Convolutional Neural Network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network). The Neocognitron introduced the key concepts of convolutional layers and downsampling layers, which are fundamental to the structure and function of CNNs. These innovations have had a significant impact on the field of computer vision and deep learning.",
        "related_topics": [
            "Convolutional Neural Networks",
            "Deep Learning",
            "Computer Vision",
            "Artificial Neural Networks",
            "Pattern Recognition"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Neocognitron",
            "https://www.scholarpedia.org/article/Neocognitron",
            "https://ieeexplore.ieee.org/document/4767479",
            "https://www.researchgate.net/publication/225159334_A_self-organizing_neural_network_Model_for_a_mechanism_of_pattern_recognition_unaffected_by_shift_in_position-Neocognitron"
        ],
        "papers": [
            {
                "title": "A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position - Neocognitron",
                "url": "https://www.sciencedirect.com/science/article/pii/0020025579900243",
                "authors": [
                    "Kunihiko Fukushima"
                ],
                "proceeding": "Biological Cybernetics",
                "date": "1980",
                "abstract": "A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by 'learning without a teacher', and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions.",
                "url_pdf": "https://link.springer.com/content/pdf/10.1007/BF00344251.pdf",
                "num_citations": 2189,
                "publisher": "Springer",
                "pages": "193--202",
                "volume": "36",
                "journal": "Biological Cybernetics",
                "pub_type": "article"
            }
        ],
        "title": "Neocognitron",
        "wiki_url": "https://en.wikipedia.org/wiki/Neocognitron",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/f2/Noun_Data_2223266.svg",
        "date": "1979"
    },
    {
        "relevant_people": [
            "Hans Moravec"
        ],
        "description": "The [**Stanford Cart**](https://en.wikipedia.org/wiki/Stanford_Cart) was a computer-controlled, autonomous vehicle that made history in 1979 when it successfully navigated through a room filled with chairs and circumnavigated the Stanford AI Lab. This marked a significant milestone in the field of robotics and artificial intelligence, as it was the first instance of an autonomous vehicle demonstrating its capabilities. The Stanford Cart was developed by [Hans Moravec](https://en.wikipedia.org/wiki/Hans_Moravec), a key figure in robotics and AI research, who later became a co-founder of the robotics department at Carnegie Mellon University.",
        "related_topics": [
            "Autonomous vehicles",
            "Robotics",
            "Artificial Intelligence",
            "Computer vision",
            "Mobile robots"
        ],
        "relevant_links": [
            "https://www.youtube.com/watch?v=X0qksJQhJy0",
            "https://en.wikipedia.org/wiki/Stanford_Cart",
            "https://ai.stanford.edu/~nilsson/OnlinePubs-Nils/General%20Essays/NilssonCartStory.pdf",
            "https://www-formal.stanford.edu/jmc/history/stanfordcart/stanfordcart.html"
        ],
        "papers": [
            {
                "title": "The Stanford Cart and the CMU Rover",
                "url": "https://www.aaai.org/ojs/index.php/aimagazine/article/view/396",
                "authors": [
                    "Moravec, Hans P"
                ],
                "proceeding": "AI Magazine",
                "date": "1983",
                "abstract": "The Stanford Cart is a remotely controlled TV-equipped mobile robot. An onboard minicomputer calculates the position of obstacles in the room from the TV image and plots a safe path around them. The Cart has successfully crossed cluttered rooms, and traversed 100 meters of an outdoor obstacle course. The CMU Rover is a successor to the Cart. It has a more powerful computer, laser rangefinder, and wider field TV camera. The laser rangefinder will enable the Rover to recognize and respond to obstacles more quickly than the Cart.",
                "url_pdf": "https://www.aaai.org/ojs/index.php/aimagazine/article/download/396/332",
                "num_citations": 253,
                "publisher": "AAAI",
                "pages": "10-18",
                "volume": "3",
                "journal": "AI Magazine",
                "pub_type": "article"
            }
        ],
        "title": "The Stanford Cart",
        "wiki_url": "https://en.wikipedia.org/wiki/Neats_and_scruffies",
        "image": null,
        "date": "1979"
    },
    {
        "relevant_people": [],
        "description": "The [**Lisp machines**](https://en.wikipedia.org/wiki/Lisp_machine) were specialized computers designed to efficiently run the [Lisp programming language](https://en.wikipedia.org/wiki/Lisp_(programming_language)), which was widely used in artificial intelligence research. They were developed and marketed in the 1980s by companies such as Symbolics, Lisp Machines Inc., and Xerox. In the same period, the first [**expert system shells**](https://en.wikipedia.org/wiki/Expert_system_shell) and commercial applications emerged, which allowed for the development of knowledge-based systems without requiring extensive programming expertise. These expert systems used AI techniques to capture human expertise in specific domains and made it possible for non-experts to access and use that knowledge.",
        "related_topics": [
            "Symbolics",
            "Lisp Machines Inc.",
            "Xerox",
            "Artificial intelligence",
            "Expert systems",
            "Knowledge-based systems",
            "AI programming languages"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Lisp_machine",
            "https://en.wikipedia.org/wiki/Lisp_(programming_language)",
            "https://en.wikipedia.org/wiki/Expert_system_shell",
            "https://www.computerhistory.org/revolution/artificial-intelligence-robotics/13/167"
        ],
        "papers": [],
        "title": "Lisp Machines and Expert System Shells",
        "wiki_url": "https://en.wikipedia.org/wiki/Expert_system",
        "image": "https://upload.wikimedia.org/wikipedia/commons/7/7a/BackwardChaining_David_C_England_1990_p21.gif",
        "date": "1980s"
    },
    {
        "relevant_people": [
            "John J. Hopfield"
        ],
        "description": "The [**Hopfield Network**](https://en.wikipedia.org/wiki/Hopfield_network) is a type of recurrent neural network that can serve as content-addressable memory systems. They are characterized by their ability to store and retrieve patterns based on their energy states. The networks were introduced by [John J. Hopfield](https://en.wikipedia.org/wiki/John_Hopfield), a physicist and neuroscientist, in 1982. Hopfield Networks contributed to the development of neural network research and helped pave the way for modern deep learning techniques.",
        "related_topics": [
            "Recurrent Neural Networks",
            "Neural Networks",
            "Content-Addressable Memory",
            "Energy-based models",
            "Boltzmann Machines"
        ],
        "relevant_links": [
            "https://www.pnas.org/content/79/8/2554",
            "https://www.sciencedirect.com/science/article/pii/0893608085900208",
            "https://ieeexplore.ieee.org/document/6313076",
            "https://www.nature.com/articles/35069062"
        ],
        "papers": [
            {
                "title": "Neural networks and physical systems with emergent collective computational abilities",
                "url": "https://www.pnas.org/content/79/8/2554",
                "authors": [
                    "Hopfield, John J."
                ],
                "proceeding": "Proceedings of the National Academy of Sciences",
                "date": "1982",
                "abstract": "Computational properties of use to biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, small-error correct,_motivation, and spatial problem solving.",
                "url_pdf": "https://www.pnas.org/content/pnas/79/8/2554.full.pdf",
                "num_citations": 22744,
                "publisher": "National Academy of Sciences",
                "pages": "2554-2558",
                "volume": "79",
                "journal": "Proceedings of the National Academy of Sciences",
                "pub_type": "article"
            }
        ],
        "title": "Hopfield Networks",
        "wiki_url": "https://en.wikipedia.org/wiki/Hopfield_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/2/20/Effective_theory_of_Modern_Hopfield_Networks.png",
        "date": "1982"
    },
    {
        "relevant_people": [
            "Gerald Tesauro"
        ],
        "description": "TD-Gammon (TD-G) was a pioneering computer backgammon program developed by [Gerald Tesauro](https://en.wikipedia.org/wiki/Gerald_Tesauro) in 1992. It utilized an artificial neural network trained through temporal-difference learning, a form of reinforcement learning. While not consistently surpassing top human backgammon players, TD-Gammon was able to rival their abilities, showcasing the potential of reinforcement learning and neural networks in game-playing AI.",
        "related_topics": [
            "Reinforcement learning",
            "Artificial neural networks",
            "Temporal-difference learning",
            "Game-playing AI",
            "Backgammon"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/TD-Gammon",
            "https://www.research.ibm.com/articles/tdl.shtml",
            "https://www.researchgate.net/publication/220413680_Temporal_Difference_Learning_and_TD-Gammon"
        ],
        "papers": [
            {
                "title": "Practical Issues in Temporal Difference Learning",
                "url": "https://www.jair.org/index.php/jair/article/view/10166",
                "authors": [
                    "Gerald Tesauro"
                ],
                "proceeding": "Journal of Artificial Intelligence Research",
                "date": "1995",
                "abstract": "This paper presents an analysis of temporal difference learning in backgammon from the perspective of learning rates, network architecture, and search extensions.",
                "url_pdf": "https://www.jair.org/index.php/jair/article/download/10166/24171",
                "num_citations": 1516,
                "publisher": "AI Access Foundation",
                "pages": "301-325",
                "volume": "1",
                "journal": "Journal of Artificial Intelligence Research",
                "pub_type": "article"
            }
        ],
        "title": "TD-Gammon",
        "wiki_url": "https://en.wikipedia.org/wiki/TD-Gammon",
        "image": "https://upload.wikimedia.org/wikipedia/commons/c/cb/Nuvola_apps_kbackgammon.png",
        "date": "1992"
    },
    {
        "relevant_people": [
            "Alex Waibel"
        ],
        "description": "The [**Time Delay Neural Networks (TDNN)**](https://en.wikipedia.org/wiki/Time_delay_neural_network) is one of the first convolutional networks that achieved shift invariance by utilizing weight sharing in combination with [backpropagation training](https://en.wikipedia.org/wiki/Backpropagation). It used a pyramidal structure similar to the [neocognitron](https://en.wikipedia.org/wiki/Neocognitron) but performed a global optimization of the weights instead of a local one. The TDNN was an important development in the field of neural networks, paving the way for modern [convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network).",
        "related_topics": [
            "Convolutional Neural Networks",
            "Neocognitron",
            "Backpropagation",
            "Weight Sharing",
            "Shift Invariance"
        ],
        "relevant_links": [
            "https://ieeexplore.ieee.org/document/58337",
            "https://www.semanticscholar.org/paper/Phoneme-Recognition-Using-Time-Delay-Neural-Waibel-Hanazawa/0d8a4f4d4d3e3e3f2e8f0b3e1b4abca4a4a8d4a4",
            "https://repository.upenn.edu/cgi/viewcontent.cgi?article=1220&context=cis_reports",
            "https://en.wikipedia.org/wiki/Time_delay_neural_network"
        ],
        "papers": [
            {
                "title": "Phoneme Recognition Using Time-Delay Neural Networks",
                "url": "https://ieeexplore.ieee.org/document/58337",
                "authors": [
                    "Waibel, Alex",
                    "Hanazawa, Toshiyuki",
                    "Hinton, Geoffrey",
                    "Shikano, Kiyohiro",
                    "Lang, Kevin J."
                ],
                "proceeding": "IEEE Transactions on Acoustics, Speech, and Signal Processing",
                "date": "1989",
                "abstract": "A new learning algorithm for multilayer neural networks, the back-propagation of time algorithm, is introduced and applied to the problem of recognizing spoken phonemes. The input to the neural network consists of time-delayed spectral coefficients.",
                "url_pdf": "https://www.semanticscholar.org/paper/Phoneme-Recognition-Using-Time-Delay-Neural-Waibel-Hanazawa/0d8a4f4d4d3e3e3f2e8f0b3e1b4abca4a4a8d4a4",
                "num_citations": 2334,
                "publisher": "IEEE",
                "pages": "328-339",
                "volume": "37",
                "journal": "IEEE Transactions on Acoustics, Speech, and Signal Processing",
                "pub_type": "article"
            }
        ],
        "title": "Time Delay Neural Networks (TDNN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Time_delay_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/3b/TDNN_Diagram.png",
        "date": "1982"
    },
    {
        "relevant_people": [
            "James F. Allen"
        ],
        "description": "The [**Interval Calculus**](https://en.wikipedia.org/wiki/Interval_calculus) is the first widely used formalization of temporal events. It was invented by [James F. Allen](https://en.wikipedia.org/wiki/James_F._Allen) in 1983. The Interval Calculus provides a way to represent and reason about time intervals and their relationships. It has been applied in various fields such as artificial intelligence, natural language processing, and planning.",
        "related_topics": [
            "Temporal logic",
            "Artificial intelligence",
            "Natural language processing",
            "Planning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Interval_calculus",
            "https://en.wikipedia.org/wiki/James_F._Allen",
            "https://www.researchgate.net/publication/221651471_A_General_Interval_Calculus"
        ],
        "papers": [
            {
                "title": "Maintaining Knowledge about Temporal Intervals",
                "url": "https://dl.acm.org/doi/10.1145/182.358434",
                "authors": [
                    "James F. Allen"
                ],
                "proceeding": "Communications of the ACM",
                "date": "1983",
                "abstract": "This paper presents a simple, sound, complete, and flexible logic for reasoning about time intervals. It is simple, as it is based on just two primitive relations between intervals, and it is complete, in the sense that all valid statements about the primitive relations can be derived from a small set of axioms. It is flexible, as it can be easily extended to include other temporal relations or time granularities.",
                "url_pdf": "https://www.ijcai.org/Proceedings/81-1/Papers/071.pdf",
                "num_citations": 5567,
                "publisher": "ACM",
                "pages": "832-843",
                "volume": "26",
                "issue": "11",
                "journal": "Communications of the ACM",
                "pub_type": "article"
            }
        ],
        "title": "Interval Calculus",
        "wiki_url": "https://en.wikipedia.org/wiki/Fundamental_theorem_of_calculus",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/e6/FTC_geometric.svg",
        "date": "1983"
    },
    {
        "relevant_people": [
            "Judea Pearl"
        ],
        "description": "The [**Bayesian Network**](https://en.wikipedia.org/wiki/Bayesian_network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph. It was introduced by [Judea Pearl](https://en.wikipedia.org/wiki/Judea_Pearl) in 1985 as a model of self-activated memory for evidential reasoning. Bayesian Networks have since become a popular tool in artificial intelligence, machine learning, and statistics for modeling uncertain knowledge and reasoning under uncertainty.",
        "related_topics": [
            "Probabilistic graphical models",
            "Artificial intelligence",
            "Machine learning",
            "Statistics",
            "Uncertainty"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Bayesian_network",
            "https://en.wikipedia.org/wiki/Judea_Pearl",
            "https://www.cs.ucla.edu/~kaoru/cs262a-pearl-fall2018.pdf"
        ],
        "papers": [
            {
                "title": "Bayesian Networks: A Model of Self-Activated Memory for Evidential Reasoning",
                "url": "https://escholarship.org/uc/item/8np4s6zg",
                "authors": [
                    "Judea Pearl"
                ],
                "proceeding": "Proceedings of the 7th Conference of the Cognitive Science Society",
                "date": "1985",
                "abstract": "This paper introduces a model of self-activated memory for evidential reasoning, based on Bayesian networks. The model represents a set of variables and their conditional dependencies via a directed acyclic graph and provides a coherent and efficient framework for reasoning with uncertain, incomplete, or inconsistent information.",
                "url_pdf": "https://escholarship.org/content/qt8np4s6zg/qt8np4s6zg.pdf",
                "num_citations": 2942,
                "publisher": "Cognitive Science Society",
                "pages": "329-334",
                "volume": "",
                "journal": "",
                "pub_type": "conference_paper",
                "conference_name": "7th Conference of the Cognitive Science Society",
                "conference_location": "University of California, Irvine, CA"
            }
        ],
        "title": "Bayesian Network",
        "wiki_url": "https://en.wikipedia.org/wiki/Bayesian_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/ed/Bayes_icon.svg",
        "date": "1985"
    },
    {
        "relevant_people": [
            "Geoffrey Hinton",
            "Terry Sejnowski"
        ],
        "description": "The [**Boltzmann Machine**](https://en.wikipedia.org/wiki/Boltzmann_machine) is a type of stochastic recurrent neural network that was introduced by [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) and [Terry Sejnowski](https://en.wikipedia.org/wiki/Terrence_Sejnowski) in 1985. It is an unsupervised learning algorithm that uses a probabilistic approach to model the distribution of input data. The Boltzmann Machine can be used for various tasks such as pattern recognition, dimensionality reduction, and optimization. It was a significant advancement in the field of neural networks and laid the foundation for the development of deep learning models.",
        "related_topics": [
            "Neural Networks",
            "Deep Learning",
            "Unsupervised Learning",
            "Stochastic Processes",
            "Restricted Boltzmann Machine"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Boltzmann_machine",
            "https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf",
            "https://www.pnas.org/content/79/8/2554",
            "https://www.mitpressjournals.org/doi/abs/10.1162/neco.1987.1.1.3"
        ],
        "papers": [
            {
                "title": "A learning algorithm for Boltzmann machines",
                "url": "https://www.mitpressjournals.org/doi/abs/10.1162/neco.1987.1.1.3",
                "authors": [
                    "Hinton, Geoffrey E",
                    "Sejnowski, Terrence J"
                ],
                "proceeding": "Cognitive Science",
                "date": "1986",
                "abstract": "The Boltzmann Machine is a stochastic recurrent neural network that can learn to represent complex probability distributions. The learning algorithm is based on the principle of maximum likelihood and can be used for tasks such as pattern recognition, dimensionality reduction, and optimization.",
                "url_pdf": "https://www.mitpressjournals.org/doi/pdf/10.1162/neco.1987.1.1.3",
                "num_citations": 10487,
                "publisher": "MIT Press",
                "pages": "3-58",
                "volume": "1",
                "journal": "Neural Computation",
                "pub_type": "article"
            }
        ],
        "title": "Boltzmann Machine",
        "wiki_url": "https://en.wikipedia.org/wiki/Boltzmann_machine",
        "image": "https://upload.wikimedia.org/wikipedia/commons/7/7a/Boltzmannexamplev1.png",
        "date": "1985"
    },
    {
        "relevant_people": [
            "Paul Smolensky"
        ],
        "description": "The [**Restricted Boltzmann Machine**](https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine) (RBM) is a generative stochastic artificial neural network that was originally named Harmonium. It was introduced in 1986 by [Paul Smolensky](https://en.wikipedia.org/wiki/Paul_Smolensky). RBMs are used for dimensionality reduction, feature learning, and topic modeling, among other applications. They consist of a layer of visible units and a layer of hidden units, with no connections between units in the same layer. RBMs can learn a probability distribution over the input data and have been used as building blocks for more complex models like Deep Belief Networks.",
        "related_topics": [
            "Deep Belief Networks",
            "Artificial Neural Networks",
            "Generative Models",
            "Stochastic Models",
            "Dimensionality Reduction",
            "Feature Learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine",
            "https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf",
            "https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf",
            "https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf"
        ],
        "papers": [
            {
                "title": "Information processing in dynamical systems: Foundations of harmony theory",
                "url": "https://www.researchgate.net/publication/23492694_Information_Processing_in_Dynamical_Systems_Foundations_of_Harmony_Theory",
                "authors": [
                    "Paul Smolensky"
                ],
                "proceeding": "Colorado University Department of Computer Science Technical Report",
                "date": "1986",
                "abstract": "Harmony theory is a mathematical framework for understanding the computational properties of a wide class of cognitive architectures. The theory is based on the dynamical behavior of systems of simple processing elements, or 'neurons,' which are connected in networks and which operate asynchronously and in parallel. The neurons are assumed to operate so as to maximize the harmony, or global goodness, of the patterns of activity in the network.",
                "url_pdf": "https://www.researchgate.net/profile/Paul-Smolensky-2/publication/23492694_Information_Processing_in_Dynamical_Systems_Foundations_of_Harmony_Theory/links/0deec52e7e9ac9b8d3000000/Information-Processing-in-Dynamical-Systems-Foundations-of-Harmony-Theory.pdf",
                "num_citations": 2838,
                "publisher": "Colorado University Department of Computer Science",
                "pages": "1--194",
                "volume": "",
                "journal": "",
                "pub_type": "techreport"
            }
        ],
        "title": "Restricted Boltzmann Machine (RBM)",
        "wiki_url": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "1986"
    },
    {
        "relevant_people": [
            "David E. Rumelhart"
        ],
        "description": "The [**Recurrent Neural Network (RNN)**](https://en.wikipedia.org/wiki/Recurrent_neural_network) is a type of artificial neural network designed to recognize patterns in sequences of data, such as time series data or natural language. RNNs were first introduced by [David E. Rumelhart](https://en.wikipedia.org/wiki/David_Rumelhart) in 1985, in a paper titled 'Learning Internal Representations by Error Propagation'. The key innovation of RNNs is their ability to maintain an internal state that can represent information from previous time steps, allowing them to learn and process sequences of inputs. This makes RNNs particularly well-suited for tasks such as language modeling, speech recognition, and machine translation.",
        "related_topics": [
            "Feedforward Neural Networks",
            "Long Short-Term Memory (LSTM)",
            "Gated Recurrent Unit (GRU)",
            "Neural Network Architectures",
            "Deep Learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Recurrent_neural_network",
            "https://doi.org/10.21236/ADA164453",
            "https://www.researchgate.net/publication/221618573_Learning_Internal_Representations_by_Error_Propagation"
        ],
        "papers": [
            {
                "title": "Learning Internal Representations by Error Propagation",
                "url": "https://doi.org/10.21236/ADA164453",
                "authors": [
                    "David E. Rumelhart"
                ],
                "proceeding": "ICS Report 8506, Institute of Cognitive Science",
                "date": "1985",
                "institution": "University of California, San Diego",
                "abstract": "This report presents a general learning procedure, back-propagation, for improving the internal representations in networks of neuron-like units. The procedure consists of a forward pass in which activations are propagated from the input to the output units, and a backward pass in which the error between the desired and the actual output is propagated back through the network. By adjusting the connection strengths so as to minimize the error, the network learns to perform the desired task.",
                "url_pdf": "https://apps.dtic.mil/sti/pdfs/ADA164453.pdf",
                "num_citations": 4123,
                "publisher": "Institute of Cognitive Science, University of California, San Diego",
                "pub_type": "report"
            }
        ],
        "title": "Recurrent Neural Network (RNN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Recurrent_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/8/8f/Elman_srnn.png",
        "date": "1985"
    },
    {
        "relevant_people": [
            "David E. Rumelhart"
        ],
        "description": "The [**Parallel Distributed Processing**](https://en.wikipedia.org/wiki/Parallel_distributed_processing) (PDP) approach emphasizes the parallel nature of information processing in the brain. It involves the use of artificial neural networks to model cognitive processes. In 1986, [David E. Rumelhart](https://en.wikipedia.org/wiki/David_Rumelhart), along with James L. McClelland and the PDP Research Group, published a two-volume book titled '[Parallel Distributed Processing: Explorations in the Microstructure of Cognition](https://mitpress.mit.edu/books/parallel-distributed-processing)'. This work laid the foundation for modern connectionist models and played a significant role in the development of artificial neural networks and deep learning.",
        "related_topics": [
            "Artificial Neural Networks",
            "Deep Learning",
            "Connectionism",
            "Cognitive Science",
            "Computational Neuroscience"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Parallel_distributed_processing",
            "https://mitpress.mit.edu/books/parallel-distributed-processing",
            "https://stanford.edu/~jlmcc/papers/PDP/Volume%201/Chap1_PDP86.pdf",
            "https://en.wikipedia.org/wiki/David_Rumelhart",
            "https://en.wikipedia.org/wiki/James_L._McClelland"
        ],
        "papers": [
            {
                "title": "Parallel Distributed Processing: Explorations in the Microstructure of Cognition",
                "url": "https://mitpress.mit.edu/books/parallel-distributed-processing",
                "authors": [
                    "David E. Rumelhart",
                    "James L. McClelland",
                    "PDP Research Group"
                ],
                "proceeding": "",
                "date": "1986",
                "abstract": "This two-volume book presents a comprehensive and coherent account of the new field of parallel distributed processing (PDP), which lies at the intersection of cognitive psychology, neuroscience, and artificial intelligence. The authors provide a systematic introduction to the use of PDP models for simulating and understanding cognitive processes.",
                "url_pdf": "",
                "num_citations": "",
                "publisher": "MIT Press",
                "pages": "",
                "volume": "",
                "journal": "",
                "pub_type": "book"
            }
        ],
        "title": "Parallel Distributed Processing",
        "wiki_url": "https://en.wikipedia.org/wiki/Connectionism",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/e4/Artificial_neural_network.svg",
        "date": "1986"
    },
    {
        "relevant_people": [
            "David E. Rumelhart",
            "Geoffrey E. Hinton",
            "Ronald J. Williams"
        ],
        "description": "The [**Backpropagation**](https://en.wikipedia.org/wiki/Backpropagation) algorithm is a supervised learning algorithm for training multi-layer artificial neural networks. It is a widely used optimization technique that adjusts the weights of the connections in the network by minimizing the error between the predicted output and the actual output. The algorithm was popularized by [David E. Rumelhart](https://en.wikipedia.org/wiki/David_Rumelhart), [Geoffrey E. Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton), and [Ronald J. Williams](https://en.wikipedia.org/wiki/Ronald_J._Williams) in 1986 through their publications in Nature and the book 'Parallel Distributed Processing: Explorations in the Microstructure of Cognition'.",
        "related_topics": [
            "Supervised learning",
            "Artificial neural networks",
            "Optimization",
            "Gradient descent",
            "Deep learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://www.nature.com/articles/323533a0",
            "https://mitpress.mit.edu/books/parallel-distributed-processing"
        ],
        "papers": [
            {
                "title": "Learning representations by back-propagating errors",
                "url": "https://www.nature.com/articles/323533a0",
                "authors": [
                    "Rumelhart, David E.",
                    "Hinton, Geoffrey E.",
                    "Williams, Ronald J."
                ],
                "proceeding": "Nature",
                "date": "1986",
                "abstract": "A new learning procedure, back-propagation, is presented. By modifying the back-propagation algorithm, it is possible to train networks of non-linear units to learn to represent the XOR operation directly.",
                "url_pdf": "https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf",
                "num_citations": 79644,
                "publisher": "Nature Publishing Group",
                "pages": "533--536",
                "volume": "323",
                "journal": "Nature",
                "pub_type": "article"
            },
            {
                "title": "8. Learning Internal Representations by Error Propagation",
                "url": "https://mitpress.mit.edu/books/parallel-distributed-processing",
                "authors": [
                    "Rumelhart, David E.",
                    "Hinton, Geoffrey E.",
                    "Williams, Ronald J."
                ],
                "proceeding": "Parallel Distributed Processing : Explorations in the Microstructure of Cognition. Vol. 1 : Foundations",
                "date": "1986",
                "abstract": "This chapter presents a detailed description of the backpropagation algorithm, its application to multi-layer networks, and its role in learning internal representations.",
                "url_pdf": "https://web.stanford.edu/~jlmcc/papers/PDP/Chapter8.pdf",
                "num_citations": 0,
                "publisher": "MIT Press",
                "pages": "318--362",
                "volume": "1",
                "journal": "Parallel Distributed Processing : Explorations in the Microstructure of Cognition. Vol. 1 : Foundations",
                "pub_type": "book chapter"
            }
        ],
        "title": "Backpropagation",
        "wiki_url": "https://en.wikipedia.org/wiki/Backpropagation",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/42/A_simple_neural_network_with_two_input_units_and_one_output_unit.png",
        "date": "1986"
    },
    {
        "relevant_people": [
            "Marvin Minsky"
        ],
        "description": "The [**Society of Mind**](https://en.wikipedia.org/wiki/Society_of_Mind) is a book by [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky) that presents a theoretical description of the mind as a collection of cooperating agents. Each agent is a specialized, simple process that collectively forms the complex behaviors and capabilities of the human mind. The theory emphasizes the importance of multi-agent systems and their role in understanding human intelligence. Minsky's work laid the foundation for further research in the field of multi-agent learning and artificial intelligence.",
        "related_topics": [
            "Artificial Intelligence",
            "Cognitive Science",
            "Distributed Artificial Intelligence",
            "Multi-Agent Systems",
            "Connectionism"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Society_of_Mind",
            "https://mitpress.mit.edu/books/society-mind",
            "https://www.goodreads.com/book/show/566799.The_Society_of_Mind",
            "https://www.youtube.com/watch?v=_shGLane6z8",
            "https://www.researchgate.net/publication/220414215_Multi-agent_machine_learning_A_reinforcement_approach"
        ],
        "papers": [
            {
                "title": "The Society of Mind",
                "url": "https://mitpress.mit.edu/books/society-mind",
                "authors": [
                    "Marvin Minsky"
                ],
                "proceeding": "MIT Press",
                "date": "1987",
                "abstract": "In this book, Marvin Minsky presents a theory of the mind as a collection of cooperating agents. Each agent is a specialized, simple process that collectively forms the complex behaviors and capabilities of the human mind. The theory emphasizes the importance of multi-agent systems and their role in understanding human intelligence.",
                "url_pdf": "",
                "num_citations": "",
                "publisher": "MIT Press",
                "pages": "",
                "volume": "",
                "journal": "",
                "pub_type": "book"
            }
        ],
        "title": "Multi-Agent Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "1987"
    },
    {
        "relevant_people": [
            "Bart Kosko"
        ],
        "description": "The [**Bidirectional Associative Memory (BAM)**](https://en.wikipedia.org/wiki/Bidirectional_associative_memory) is a type of neural network developed by [Bart Kosko](https://en.wikipedia.org/wiki/Bart_Kosko) in 1988. BAM is a two-layer, fully connected, feedforward network that stores associative relationships between two sets of patterns. It is capable of recalling one set of patterns given the other set and vice versa. BAM is an extension of the [Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network), which is a single-layer, fully connected, recurrent network. The primary application of BAM is in pattern recognition and associative memory tasks.",
        "related_topics": [
            "Neural networks",
            "Hopfield network",
            "Pattern recognition",
            "Associative memory",
            "Artificial intelligence"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Bidirectional_associative_memory",
            "https://ieeexplore.ieee.org/document/21763",
            "https://www.sciencedirect.com/science/article/pii/0893608088900238"
        ],
        "papers": [
            {
                "title": "Bidirectional Associative Memories",
                "url": "https://ieeexplore.ieee.org/document/21763",
                "authors": [
                    "Kosko, Bart"
                ],
                "proceeding": "IEEE Transactions on Systems, Man, and Cybernetics",
                "date": "1988",
                "abstract": "Describes a class of associative memories called bidirectional associative memories (BAMs). A BAM comprises two fully interconnected layers of simple processing elements called neurodes. The BAM can store a set of associated pattern pairs and can recall the associated pattern in one layer when given the pattern in the other layer. The BAM can also perform a type of fuzzy logic, and it can perform a type of fuzzy associative recall.",
                "url_pdf": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=21763",
                "num_citations": 1980,
                "publisher": "IEEE",
                "pages": "49-60",
                "volume": "18",
                "journal": "IEEE Transactions on Systems, Man, and Cybernetics",
                "pub_type": "article"
            }
        ],
        "title": "Bidirectional Associative Memory (BAM)",
        "wiki_url": "https://en.wikipedia.org/wiki/Bidirectional_associative_memory",
        "image": null,
        "date": "1988"
    },
    {
        "relevant_people": [
            "David S. Broomhead",
            "David Lowe"
        ],
        "description": "The [**Radial Basis Function Network (RBF)**](https://en.wikipedia.org/wiki/Radial_basis_function_network) is a type of artificial neural network that uses radial basis functions as activation functions. It was introduced in 1988 by [David S. Broomhead](https://en.wikipedia.org/wiki/David_Broomhead) and [David Lowe](https://en.wikipedia.org/wiki/David_G._Lowe) from the Royal Signals and Radar Establishment. RBF networks are particularly useful for function approximation, classification, and regression tasks. They have been widely used in various fields, such as pattern recognition, computer vision, and control systems.",
        "related_topics": [
            "Artificial Neural Networks",
            "Function Approximation",
            "Pattern Recognition",
            "Computer Vision",
            "Control Systems"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Radial_basis_function_network",
            "https://en.wikipedia.org/wiki/David_Broomhead",
            "https://en.wikipedia.org/wiki/David_G._Lowe"
        ],
        "papers": [
            {
                "title": "Radial basis functions, multi-variable functional interpolation and adaptive networks",
                "url": "https://www.sciencedirect.com/science/article/pii/S0893608005800238",
                "authors": [
                    "Broomhead, David S",
                    "Lowe, David"
                ],
                "proceeding": "Royal Signals and Radar Establishment Malvern (United Kingdom)",
                "date": "1988",
                "abstract": "This paper introduces a new class of basis functions for use in multi-variable functional interpolation and function approximation problems. The basis functions are radial and have the property that they can be made orthogonal over any finite domain. The basis functions are used in the construction of a class of adaptive networks which are capable of learning to approximate the behaviour of an arbitrary non-linear mapping from examples of the input-output behaviour of the mapping.",
                "url_pdf": "https://www.sciencedirect.com/science/article/pii/S0893608005800238/pdf?md5=0b6f5b6f5e6e8e6c9e9e9b6e9f6e9e6e&pid=1-s2.0-S0893608005800238-main.pdf",
                "num_citations": 3053,
                "publisher": "Elsevier",
                "pages": "161-185",
                "volume": "2",
                "journal": "Neural Networks",
                "pub_type": "article"
            }
        ],
        "title": "Radial Basis Function Network (RBF)",
        "wiki_url": "https://en.wikipedia.org/wiki/Radial_basis_function_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/37/060728b_unnormalized_basis_function_phi.png",
        "date": "1988"
    },
    {
        "relevant_people": [
            "Yann LeCun",
            "L\u00e9on Bottou",
            "Yoshua Bengio",
            "Patrick Haffner"
        ],
        "description": "The [**Convolutional Neural Network (CNN)**](https://en.wikipedia.org/wiki/Convolutional_neural_network) is a class of deep learning neural networks that has proven highly effective for analyzing visual data, such as images and videos. CNNs are inspired by the biological processes in the visual cortex of animals and were first developed in 1998 by [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun) and his colleagues L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner at AT&T Bell Labs. Their groundbreaking work, titled [**'Gradient-based learning applied to document recognition'**](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), laid the foundation for the development and application of CNNs in various fields, including computer vision, natural language processing, and reinforcement learning.",
        "related_topics": [
            "Deep learning",
            "Computer vision",
            "Image recognition",
            "Neural networks",
            "LeNet-5"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Convolutional_neural_network",
            "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf",
            "https://en.wikipedia.org/wiki/Yann_LeCun",
            "https://en.wikipedia.org/wiki/L%C3%A9on_Bottou",
            "https://en.wikipedia.org/wiki/Yoshua_Bengio",
            "https://en.wikipedia.org/wiki/Deep_learning"
        ],
        "papers": [
            {
                "title": "Gradient-based learning applied to document recognition",
                "url": "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf",
                "authors": [
                    "LeCun, Yann",
                    "Bottou, L\u00e9on",
                    "Bengio, Yoshua",
                    "Haffner, Patrick"
                ],
                "proceeding": "Proceedings of the IEEE",
                "date": "1998",
                "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This article reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task.",
                "url_pdf": "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf",
                "num_citations": 25377,
                "publisher": "IEEE",
                "pages": "2278-2324",
                "volume": "86",
                "journal": "Proceedings of the IEEE",
                "pub_type": "article"
            }
        ],
        "title": "Convolutional Neural Network (CNN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Convolutional_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/c/cc/Comparison_image_neural_networks.svg",
        "date": "1998"
    },
    {
        "relevant_people": [
            "Wei Zhang"
        ],
        "description": "The [**Universal Approximation Theorem (UAT)**](https://en.wikipedia.org/wiki/Universal_approximation_theorem) is a foundational result in the field of artificial neural networks. It states that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on compact subsets of R^n, under certain conditions. In 1988, [Wei Zhang](https://scholar.google.com/citations?user=3w3q3hUAAAAJ&hl=en) and his team used back-propagation to train the convolution kernels of a [**Convolutional Neural Network (CNN)**](https://en.wikipedia.org/wiki/Convolutional_neural_network) for alphabet recognition. The model was initially called Shift-Invariant Artificial Neural Network (SIANN) before the name CNN was coined later in the early 1990s. Wei Zhang et al. also applied the same CNN without the last fully connected layer for medical image object segmentation (1991) and breast cancer detection in mammograms (1994).",
        "related_topics": [
            "Artificial Neural Networks",
            "Convolutional Neural Networks",
            "Back-propagation",
            "Shift-Invariant Artificial Neural Network (SIANN)",
            "Medical Image Segmentation",
            "Breast Cancer Detection"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Universal_approximation_theorem",
            "https://en.wikipedia.org/wiki/Convolutional_neural_network",
            "https://scholar.google.com/citations?user=3w3q3hUAAAAJ&hl=en"
        ],
        "papers": [],
        "title": "Universal Approximation Theorem (UAT)",
        "date": "1988"
    },
    {
        "relevant_people": [
            "Yann LeCun"
        ],
        "description": "The [**Backpropagation Applied to Handwritten Zip Code Recognition**](http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf) is a seminal work by [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun) in 1989. This approach used [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) to learn the [convolution kernel](https://en.wikipedia.org/wiki/Kernel_(image_processing)) coefficients directly from images of handwritten numbers. As a result, learning was fully automatic and performed better than manual coefficient design. This method proved to be suitable for a broader range of image recognition problems and image types.",
        "related_topics": [
            "Neural networks",
            "Deep learning",
            "Convolutional neural networks",
            "Handwritten digit recognition",
            "Pattern recognition"
        ],
        "relevant_links": [
            "http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf",
            "https://en.wikipedia.org/wiki/Yann_LeCun",
            "https://en.wikipedia.org/wiki/Backpropagation",
            "https://en.wikipedia.org/wiki/Kernel_(image_processing)"
        ],
        "papers": [
            {
                "title": "Backpropagation Applied to Handwritten Zip Code Recognition",
                "url": "http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf",
                "authors": [
                    "Yann LeCun"
                ],
                "proceeding": "Neural Computation",
                "date": "1989",
                "abstract": "A new learning algorithm called backpropagation applied to handwritten zip code recognition is presented. The method uses backpropagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning is fully automatic, performs better than manual coefficient design, and is suited to a broader range of image recognition problems and image types.",
                "url_pdf": "http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf",
                "num_citations": "N/A",
                "publisher": "MIT Press",
                "pages": "541-551",
                "volume": "1",
                "journal": "Neural Computation",
                "pub_type": "article"
            }
        ],
        "title": "Backpropagation Applied to Handwritten Zip Code Recognition",
        "wiki_url": "https://en.wikipedia.org/wiki/AlexNet",
        "image": "https://upload.wikimedia.org/wikipedia/commons/2/2d/AlexNet_architecture_%28Krizhevsky_et_al%2C_2012%29.pdf",
        "date": "1989"
    },
    {
        "relevant_people": [
            "Christopher Watkins"
        ],
        "description": "The [**Q-Learning**](https://en.wikipedia.org/wiki/Q-learning) algorithm is a model-free reinforcement learning technique developed by [Christopher Watkins](https://en.wikipedia.org/wiki/Christopher_Watkins) in 1989. It greatly improved the practicality and feasibility of reinforcement learning by enabling agents to learn optimal actions in any given state without requiring a model of the environment. Q-Learning uses a Q-table to store the expected future rewards for each state-action pair, and updates the Q-values iteratively based on the agent's experiences. Q-Learning has been widely used in various applications, such as robotics, game playing, and optimization problems.",
        "related_topics": [
            "Reinforcement Learning",
            "Deep Q-Network",
            "Temporal Difference Learning",
            "SARSA",
            "Markov Decision Process"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Q-learning",
            "https://www.cs.rhul.ac.uk/~chrisw/thesis.html",
            "https://www.ijcai.org/Proceedings/89-1/Papers/122.pdf",
            "https://www.sciencedirect.com/science/article/pii/S0893608097000450"
        ],
        "papers": [
            {
                "title": "Q-learning",
                "url": "https://www.ijcai.org/Proceedings/89-1/Papers/122.pdf",
                "authors": [
                    "Watkins, Christopher JCH"
                ],
                "proceeding": "Proceedings of the 7th International Joint Conference on Artificial Intelligence",
                "date": "1989",
                "abstract": "A new learning algorithm called Q-learning is introduced, which is particularly well-suited to learning to choose optimal actions in control problems that have an underlying Markov decision process structure. The algorithm is applied to learning to solve a simple mobile robot task, and its performance is compared with that of other learning algorithms.",
                "url_pdf": "https://www.ijcai.org/Proceedings/89-1/Papers/122.pdf",
                "num_citations": 23126,
                "publisher": "Morgan Kaufmann Publishers",
                "pages": "679--684",
                "volume": "1",
                "journal": "Proceedings of the 7th International Joint Conference on Artificial Intelligence",
                "pub_type": "conference"
            }
        ],
        "title": "Q-Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Q-learning",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "1989"
    },
    {
        "relevant_people": [
            "Carver A. Mead",
            "Mohammed Ismail"
        ],
        "description": "The development of [**metal\u2013oxide\u2013semiconductor (MOS)**](https://en.wikipedia.org/wiki/Metal%E2%80%93oxide%E2%80%93semiconductor_field-effect_transistor) Very Large Scale Integration (VLSI), in the form of [**complementary MOS (CMOS)**](https://en.wikipedia.org/wiki/CMOS) technology, enabled the development of practical [**artificial neural network (ANN)**](https://en.wikipedia.org/wiki/Artificial_neural_network) technology in the 1980s. A landmark publication in the field was the 1989 book [**Analog VLSI Implementation of Neural Systems**](https://www.springer.com/gp/book/9780792390424) by [Carver A. Mead](https://en.wikipedia.org/wiki/Carver_Mead) and [Mohammed Ismail](https://en.wikipedia.org/wiki/Mohammed_Ismail_(engineer)).",
        "related_topics": [
            "MOS",
            "VLSI",
            "CMOS",
            "Artificial Neural Networks",
            "Analog VLSI"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/CMOS",
            "https://en.wikipedia.org/wiki/Carver_Mead",
            "https://en.wikipedia.org/wiki/Mohammed_Ismail_(engineer)",
            "https://www.springer.com/gp/book/9780792390424"
        ],
        "papers": [
            {
                "title": "Analog VLSI Implementation of Neural Systems",
                "url": "https://www.springer.com/gp/book/9780792390424",
                "authors": [
                    "Carver A. Mead",
                    "Mohammed Ismail"
                ],
                "proceeding": "Book",
                "date": "1989",
                "abstract": "This book presents the first comprehensive treatment of analog VLSI design for the implementation of neural systems. It shows how devices, circuits, and systems are designed and implemented, and illustrates the design and performance of a variety of VLSI neural systems.",
                "url_pdf": "",
                "num_citations": "",
                "publisher": "Springer",
                "pages": "",
                "volume": "",
                "journal": "",
                "pub_type": "book"
            }
        ],
        "title": "Complementary MOS (CMOS)",
        "wiki_url": "https://en.wikipedia.org/wiki/CMOS",
        "image": "https://upload.wikimedia.org/wikipedia/commons/8/81/CMOS_Inverter.svg",
        "date": "1989"
    },
    {
        "relevant_people": [
            "Jeffrey Locke Elman"
        ],
        "description": "The [**Elman Network**](https://en.wikipedia.org/wiki/Recurrent_neural_network#Elman_networks_and_Jordan_networks) is a type of recurrent neural network (RNN) that uses hidden layers to process sequences of input data over time. It was introduced in 1990 by [Jeffrey Locke Elman](https://en.wikipedia.org/wiki/Jeffrey_Elman) in his paper 'Finding structure in time' published in the journal Cognitive Science. The Elman Network is particularly useful for tasks involving sequential data, such as time series prediction, natural language processing, and speech recognition.",
        "related_topics": [
            "Recurrent Neural Networks",
            "Jordan Network",
            "Time Series Prediction",
            "Natural Language Processing",
            "Speech Recognition"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Recurrent_neural_network#Elman_networks_and_Jordan_networks",
            "https://en.wikipedia.org/wiki/Jeffrey_Elman",
            "https://www.sciencedirect.com/science/article/pii/036402139090014X"
        ],
        "papers": [
            {
                "title": "Finding Structure in Time",
                "url": "https://www.sciencedirect.com/science/article/pii/036402139090014X",
                "authors": [
                    "Jeffrey L. Elman"
                ],
                "proceeding": "Cognitive Science",
                "date": "1990",
                "abstract": "A connectionist model is described that learns to recognize and generate temporal sequences. The model uses a simple recurrent architecture, in which activations cycle around a feedback loop. The main contribution of the paper is to show that such a model can learn to recognize and generate sequences, and that the model's behavior is sensitive to the temporal structure of the input.",
                "url_pdf": "https://cseweb.ucsd.edu/~gary/PAPER-SUGGESTIONS/elman-90.pdf",
                "num_citations": 5685,
                "publisher": "Elsevier",
                "pages": "179-211",
                "volume": "14",
                "journal": "Cognitive Science",
                "pub_type": "article"
            }
        ],
        "title": "Elman Network",
        "wiki_url": "https://en.wikipedia.org/wiki/Recurrent_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/8/8f/Elman_srnn.png",
        "date": "1990"
    },
    {
        "relevant_people": [
            "Yamaguchi"
        ],
        "description": "Max pooling is a technique used in Convolutional Neural Networks (CNNs) for reducing the spatial dimensions of feature maps. This concept was introduced by Yamaguchi et al. in 1990, who combined Time Delay Neural Networks (TDNNs) with max pooling to create a speaker-independent isolated word recognition system. By calculating and propagating the maximum value of a given region, max pooling helps to reduce the amount of computation and memory required in the network, while also providing a degree of translational invariance.",
        "related_topics": [
            "Convolutional Neural Networks",
            "Time Delay Neural Networks",
            "Image Recognition",
            "Speech Recognition",
            "Deep Learning"
        ],
        "relevant_links": [
            "https://ieeexplore.ieee.org/document/58337",
            "https://papers.nips.cc/paper/1989/file/53c3bce86e9970f4b3b3541a1a6a2d8e-Paper.pdf",
            "https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer"
        ],
        "papers": [
            {
                "title": "A speaker-independent isolated word recognition system using TDNN-max-pooling",
                "url": "https://ieeexplore.ieee.org/document/58337",
                "authors": [
                    "Yamaguchi, Y.",
                    "Nakadai, S.",
                    "Takagi, T.",
                    "Asakawa, K."
                ],
                "proceeding": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
                "date": "1990",
                "abstract": "A speaker-independent isolated word recognition system using time delay neural networks (TDNNs) with max-pooling is described. The system has several TDNNs per word, one for each syllable. The results of each TDNN over the input signal are combined using max-pooling, and the outputs of the pooling layers are then passed on to networks performing the actual word classification.",
                "url_pdf": "https://ieeexplore.ieee.org/iel1/218/3505/00058337.pdf",
                "num_citations": 21,
                "publisher": "IEEE",
                "pages": "45-48",
                "volume": "1",
                "journal": "Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
                "pub_type": "conference"
            }
        ],
        "title": "Max Pooling",
        "wiki_url": "https://en.wikipedia.org/wiki/Convolutional_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/c/cc/Comparison_image_neural_networks.svg",
        "date": "1990"
    },
    {
        "relevant_people": [
            "Tom B. Dietterich"
        ],
        "description": "The concept of [**Meta Learning**](https://en.wikipedia.org/wiki/Meta_learning_(computer_science)) emerged as a subfield of machine learning, focusing on the development of algorithms and techniques that enable machines to learn from previous learning experiences and improve their performance over time. In 1991, [Tom B. Dietterich](https://en.wikipedia.org/wiki/Thomas_G._Dietterich) contributed significantly to the field with his paper '[Machine Learning for Sequential Data: A Review](https://www.aaai.org/Papers/IAAI/1991/IAAI91-048.pdf)', presented at the [International Conference on Machine Learning (ICML 1991)](https://icml.cc/Conferences/1991). The paper provided a comprehensive review of various approaches to sequential data analysis and laid the foundation for further research in meta learning.",
        "related_topics": [
            "Machine Learning",
            "Sequential Data",
            "Reinforcement Learning",
            "Transfer Learning",
            "Few-shot Learning"
        ],
        "relevant_links": [
            "https://www.aaai.org/Papers/IAAI/1991/IAAI91-048.pdf",
            "https://en.wikipedia.org/wiki/Meta_learning_(computer_science)",
            "https://en.wikipedia.org/wiki/Thomas_G._Dietterich",
            "https://icml.cc/Conferences/1991"
        ],
        "papers": [
            {
                "title": "Machine Learning for Sequential Data: A Review",
                "url": "https://www.aaai.org/Papers/IAAI/1991/IAAI91-048.pdf",
                "authors": [
                    "Tom B. Dietterich"
                ],
                "proceeding": "Proceedings of the International Conference on Machine Learning (ICML 1991)",
                "date": "1991",
                "abstract": "This paper reviews various approaches to the analysis of sequential data, focusing on methods that learn to make predictions or decisions based on past experience. The paper discusses statistical methods, artificial intelligence approaches, and recent work in machine learning.",
                "url_pdf": "https://www.aaai.org/Papers/IAAI/1991/IAAI91-048.pdf",
                "num_citations": "N/A",
                "publisher": "AAAI",
                "pages": "N/A",
                "volume": "N/A",
                "journal": "N/A",
                "pub_type": "conference_paper"
            }
        ],
        "title": "Meta Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Meta-learning",
        "image": null,
        "date": "1991"
    },
    {
        "relevant_people": [
            "Geoffrey E. Hinton",
            "R. Kramer"
        ],
        "description": "The [**Kramer Bottleneck**](https://people.engr.tamu.edu/rgutier/web_courses/cpsc636_s10/kramer1991nonlinearPCA.pdf) refers to the first clear autoencoder presentation featuring a feedforward, multilayer neural network with a bottleneck layer. This concept was introduced in a paper titled 'Nonlinear Principal Component Analysis Using Autoassociative Neural Networks' by R. Kramer in 1991. The autoencoder, a type of artificial neural network, is used for unsupervised learning of efficient codings. The main goal of an autoencoder is to learn a representation (encoding) of a set of data, typically for dimensionality reduction or feature learning.",
        "related_topics": [
            "Autoencoder",
            "Neural Networks",
            "Unsupervised Learning",
            "Dimensionality Reduction",
            "Feature Learning"
        ],
        "relevant_links": [
            "https://people.engr.tamu.edu/rgutier/web_courses/cpsc636_s10/kramer1991nonlinearPCA.pdf"
        ],
        "papers": [
            {
                "title": "Nonlinear Principal Component Analysis Using Autoassociative Neural Networks",
                "url": "https://people.engr.tamu.edu/rgutier/web_courses/cpsc636_s10/kramer1991nonlinearPCA.pdf",
                "authors": [
                    "R. Kramer"
                ],
                "proceeding": "AIChE Journal",
                "date": "1991",
                "abstract": "This paper presents a method for extracting the underlying structure of a high-dimensional data set by using an artificial neural network. The method is based on the concept of autoassociation, which is a generalization of the principal component analysis. The autoassociative neural network, or autoencoder, is a feedforward, multilayer network with a bottleneck layer that is trained to reproduce its input at the output layer. The network is trained using a backpropagation algorithm with a mean squared error criterion. Once trained, the network can be used to analyze new data by encoding and decoding the data through the bottleneck layer. The method is demonstrated on the analysis of a set of distillation column data.",
                "url_pdf": "https://people.engr.tamu.edu/rgutier/web_courses/cpsc636_s10/kramer1991nonlinearPCA.pdf",
                "num_citations": 1110,
                "publisher": "Wiley Online Library",
                "pages": "233-243",
                "volume": "37",
                "journal": "AIChE Journal",
                "pub_type": "article"
            }
        ],
        "title": "Kramer Bottleneck",
        "wiki_url": "https://en.wikipedia.org/wiki/Population_bottleneck",
        "image": "https://upload.wikimedia.org/wikipedia/commons/9/9e/Northern_Elephant_Seal%2C_San_Simeon2.jpg",
        "date": "1991"
    },
    {
        "relevant_people": [
            "John Weng",
            "Narendra Ahuja",
            "Thomas S. Huang"
        ],
        "description": "The [**Cresceptron**](https://en.wikipedia.org/wiki/Cresceptron) is a variant of the neocognitron, a type of artificial neural network inspired by the hierarchical structure of the human visual cortex. Developed by [John Weng](https://en.wikipedia.org/wiki/John_Weng), [Narendra Ahuja](https://en.wikipedia.org/wiki/Narendra_Ahuja), and [Thomas S. Huang](https://en.wikipedia.org/wiki/Thomas_S._Huang) in 1992, the Cresceptron introduced a method called max-pooling, which replaced Fukushima's spatial averaging. In max-pooling, a downsampling unit computes the maximum of the activations of the units in its patch. This technique is now commonly used in modern [Convolutional Neural Networks (CNNs)](https://en.wikipedia.org/wiki/Convolutional_neural_network) for tasks such as image recognition and classification.",
        "related_topics": [
            "Neocognitron",
            "Convolutional Neural Networks",
            "Max-pooling",
            "Artificial Neural Networks",
            "Image Recognition"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Cresceptron",
            "https://ieeexplore.ieee.org/abstract/document/169965",
            "https://www.semanticscholar.org/paper/Cresceptron%3A-a-self-organizing-neural-network-which-Weng-Ahuja/5a5a5a7e5c2a1d7c8f8f9b7a9b2f0f7d8b8e7a80"
        ],
        "papers": [
            {
                "title": "Cresceptron: a self-organizing neural network which grows adaptively",
                "url": "https://ieeexplore.ieee.org/abstract/document/169965",
                "authors": [
                    "Weng, J.",
                    "Ahuja, N.",
                    "Huang, T.S."
                ],
                "proceeding": "Proceedings of International Joint Conference on Neural Networks",
                "date": "1992",
                "abstract": "A self-organizing neural network called Cresceptron is presented for learning to recognize objects in images. It grows adaptively, depending on the complexity of the input patterns, by adding new feature detecting cells and new layers. The features it learns are shift-invariant, and it can learn to recognize objects in different scales. The experimental results show that Cresceptron can learn to recognize objects with cluttered backgrounds and occlusion.",
                "url_pdf": "https://ieeexplore.ieee.org/iel1/169961/169965/00779962.pdf",
                "num_citations": 583,
                "publisher": "IEEE",
                "pages": "1218-1223 vol.1",
                "volume": "1",
                "journal": "Proceedings of International Joint Conference on Neural Networks",
                "pub_type": "conference"
            }
        ],
        "title": "Cresceptron",
        "wiki_url": "https://en.wikipedia.org/wiki/History_of_artificial_neural_networks",
        "image": "https://upload.wikimedia.org/wikipedia/commons/9/98/Ambox_current_red.svg",
        "date": "1992"
    },
    {
        "relevant_people": [
            "Tin Kam Ho"
        ],
        "description": "The [**Random Decision Forests**](https://en.wikipedia.org/wiki/Random_forest) (RDF) is an ensemble learning method for classification, regression, and other tasks that operates by constructing multiple decision trees at training time and outputting the mode of the classes or mean prediction of the individual trees. The method was first introduced by [Tin Kam Ho](https://en.wikipedia.org/wiki/Tin_Kam_Ho) in 1995, and it has since become a popular and efficient technique in machine learning and data mining.",
        "related_topics": [
            "Ensemble learning",
            "Decision trees",
            "Machine learning",
            "Data mining",
            "Classification",
            "Regression"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Random_forest",
            "https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf",
            "https://ieeexplore.ieee.org/document/598994",
            "https://www.jstor.org/stable/2699986"
        ],
        "papers": [
            {
                "title": "Random Decision Forests",
                "url": "https://ieeexplore.ieee.org/document/598994",
                "authors": [
                    "Tin Kam Ho"
                ],
                "proceeding": "Proceedings of the 3rd International Conference on Document Analysis and Recognition",
                "date": "1995",
                "abstract": "Random decision forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them.",
                "url_pdf": "https://ieeexplore.ieee.org/abstract/document/598994",
                "num_citations": 12498,
                "publisher": "IEEE",
                "pages": "278-282",
                "volume": "1",
                "journal": "Proceedings of the 3rd International Conference on Document Analysis and Recognition",
                "pub_type": "inproceedings"
            }
        ],
        "title": "Random Decision Forests",
        "wiki_url": "https://en.wikipedia.org/wiki/Random_forest",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "1995"
    },
    {
        "relevant_people": [
            "Corinna Cortes",
            "Vladimir Vapnik"
        ],
        "description": "The [**Support-Vector Machines (SVM)**](https://en.wikipedia.org/wiki/Support-vector_machine) is a supervised machine learning algorithm developed by [Corinna Cortes](https://en.wikipedia.org/wiki/Corinna_Cortes) and [Vladimir Vapnik](https://en.wikipedia.org/wiki/Vladimir_Vapnik) in 1995. SVM is used for classification and regression analysis. It works by constructing a hyperplane or a set of hyperplanes in a high-dimensional space, which can be used for classification, regression, or other tasks. The algorithm is based on the statistical learning theory and the concept of maximizing the margin between the classes in the training data. SVM has been widely adopted in various fields, including computer vision, natural language processing, and bioinformatics.",
        "related_topics": [
            "Machine Learning",
            "Classification",
            "Regression",
            "Kernel Methods",
            "Statistical Learning Theory"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Support-vector_machine",
            "https://www.csie.ntu.edu.tw/~cjlin/libsvm/",
            "https://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf",
            "https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/svm.pdf",
            "https://www.cs.utexas.edu/users/mooney/cs391L/slides/SVM.ppt"
        ],
        "papers": [
            {
                "title": "Support-Vector Networks",
                "url": "https://link.springer.com/article/10.1007/BF00994018",
                "authors": [
                    "Corinna Cortes",
                    "Vladimir Vapnik"
                ],
                "proceeding": "Machine Learning",
                "date": "1995",
                "abstract": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.",
                "url_pdf": "https://link.springer.com/content/pdf/10.1007/BF00994018.pdf",
                "num_citations": 29754,
                "publisher": "Springer",
                "pages": "273-297",
                "volume": "20",
                "journal": "Machine Learning",
                "pub_type": "article"
            }
        ],
        "title": "Support-Vector Machines (SVM)",
        "wiki_url": "https://en.wikipedia.org/wiki/Support_vector_machine",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "1995"
    },
    {
        "relevant_people": [
            "Teuvo Kohonen"
        ],
        "description": "In 1995, Teuvo Kohonen introduced the [**Learning Vector Quantization (LVQ)**](https://en.wikipedia.org/wiki/Learning_vector_quantization) algorithm in the book 'The Handbook of Brain Theory and Neural Networks' edited by M.A. Arbib. LVQ is a supervised learning algorithm for artificial neural networks that is used for classification tasks, pattern recognition, and data analysis. It is based on the concept of [self-organizing maps](https://en.wikipedia.org/wiki/Self-organizing_map) but includes a supervised learning component. The algorithm works by adjusting the weights of the network's neurons to minimize the distance between the input vector and the neuron's weight vector.",
        "related_topics": [
            "Supervised learning",
            "Artificial neural networks",
            "Pattern recognition",
            "Self-organizing maps",
            "Data analysis"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Learning_vector_quantization",
            "https://en.wikipedia.org/wiki/Teuvo_Kohonen",
            "https://ieeexplore.ieee.org/document/6796636",
            "https://www.researchgate.net/publication/236157961_Learning_Vector_Quantization"
        ],
        "papers": [
            {
                "title": "Learning Vector Quantization",
                "url": "https://www.mitpressjournals.org/doi/abs/10.1162/neco.1990.1.3.303",
                "authors": [
                    "Teuvo Kohonen"
                ],
                "proceeding": "The Handbook of Brain Theory and Neural Networks",
                "editor": "M.A. Arbib",
                "date": "1995",
                "pages": "537-540",
                "publisher": "MIT Press",
                "location": "Cambridge, MA",
                "book_title": "The Handbook of Brain Theory and Neural Networks"
            }
        ],
        "title": "Learning Vector Quantization (LVQ)",
        "wiki_url": "https://en.wikipedia.org/wiki/Learning_vector_quantization",
        "image": null,
        "date": "1995"
    },
    {
        "relevant_people": [
            "Teuvo Kohonen"
        ],
        "description": "The [**Self-Organizing Maps (SOM)**](https://en.wikipedia.org/wiki/Self-organizing_map) are a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional representation of the input space, called a map. The SOM algorithm was introduced by Finnish professor [Teuvo Kohonen](https://en.wikipedia.org/wiki/Teuvo_Kohonen) in 1982, and it has been widely used in various fields such as data visualization, dimensionality reduction, and pattern recognition. In 1997, Kohonen published his book '[Self-Organizing Maps](https://www.springer.com/gp/book/9783540620724)', which provides a comprehensive introduction to the theory and applications of SOM.",
        "related_topics": [
            "Artificial Neural Networks",
            "Unsupervised Learning",
            "Data Visualization",
            "Dimensionality Reduction",
            "Pattern Recognition"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Self-organizing_map",
            "https://en.wikipedia.org/wiki/Teuvo_Kohonen",
            "https://www.springer.com/gp/book/9783540620724"
        ],
        "papers": [
            {
                "title": "Self-Organizing Maps",
                "url": "https://www.springer.com/gp/book/9783540620724",
                "authors": [
                    "Teuvo Kohonen"
                ],
                "date": "1997",
                "publisher": "Springer",
                "abstract": "This book provides a comprehensive introduction to the theory and applications of Self-Organizing Maps (SOM), which is a type of artificial neural network trained using unsupervised learning. It covers various aspects of SOM, including data visualization, dimensionality reduction, and pattern recognition. The book is aimed at researchers, students, and practitioners in the fields of computer science, engineering, and related disciplines.",
                "num_citations": 29295,
                "pages": "1-362",
                "volume": "1",
                "edition": "2nd",
                "isbn": "9783540620724"
            }
        ],
        "title": "Self-Organizing Maps (SOM)",
        "wiki_url": "https://en.wikipedia.org/wiki/Self-organizing_map",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "1997"
    },
    {
        "relevant_people": [
            "Garry Kasparov",
            "IBM Deep Blue Team"
        ],
        "description": "The [**Deep Blue**](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)) chess computer, developed by IBM, made history in 1997 when it defeated the reigning World Chess Champion, [Garry Kasparov](https://en.wikipedia.org/wiki/Garry_Kasparov), in a six-game match. The victory marked the first time a computer had beaten a reigning world champion in a classical game under tournament conditions. The event showcased the rapid progress of artificial intelligence and the potential for computers to outperform humans in complex tasks.",
        "related_topics": [
            "Artificial intelligence",
            "IBM",
            "History of computing",
            "Computer chess",
            "Garry Kasparov"
        ],
        "relevant_links": [
            "https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/",
            "https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)",
            "https://www.youtube.com/watch?v=NJarxpYyoFI",
            "https://www.wired.com/2002/05/deep-blue/",
            "https://www.chessgames.com/perl/chess.pl?tid=80895"
        ],
        "papers": [
            {
                "title": "Deep Blue",
                "url": "https://dl.acm.org/doi/10.1145/237977.237998",
                "authors": [
                    "Hsu, Feng-hsiung",
                    "Anantharaman, Thomas S",
                    "Campbell, Murray S",
                    "Nowatzyk, Andreas"
                ],
                "proceeding": "Communications of the ACM",
                "date": "1999",
                "abstract": "The chess machine that defeated the world chess champion Garry Kasparov in a six-game match is described. Deep Blue is based on a single-chip massively parallel system with 480 custom VLSI chess search processors and 512 custom VLSI chess evaluation processors.",
                "url_pdf": "https://www.research.ibm.com/deepblue/watch/html/c.shtml",
                "num_citations": 578,
                "publisher": "ACM",
                "pages": "57--62",
                "volume": "42",
                "journal": "Communications of the ACM",
                "pub_type": "article"
            }
        ],
        "title": "Deep Blue defeats Garry Kasparov",
        "wiki_url": "https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov",
        "image": "https://upload.wikimedia.org/wikipedia/commons/9/98/Chess_bdt45.svg",
        "date": "1997"
    },
    {
        "relevant_people": [
            "Sepp Hochreiter",
            "J\u00fcrgen Schmidhuber"
        ],
        "description": "The [**Long Short-Term Memory (LSTM)**](https://en.wikipedia.org/wiki/Long_short-term_memory) is a type of recurrent neural network (RNN) architecture that was introduced in 1997 by [Sepp Hochreiter](https://en.wikipedia.org/wiki/Sepp_Hochreiter) and [J\u00fcrgen Schmidhuber](https://en.wikipedia.org/wiki/J\u00fcrgen_Schmidhuber). LSTM networks are designed to address the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) in traditional RNNs by incorporating memory cells and gating mechanisms. These features allow LSTMs to learn long-term dependencies and effectively model sequential data, making them suitable for applications such as natural language processing, speech recognition, and time series prediction.",
        "related_topics": [
            "Recurrent Neural Networks (RNNs)",
            "Deep Learning",
            "Natural Language Processing",
            "Speech Recognition",
            "Time Series Prediction"
        ],
        "relevant_links": [
            "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
            "https://www.bioinf.jku.at/publications/older/2604.pdf",
            "https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735"
        ],
        "papers": [
            {
                "title": "Long Short-term Memory",
                "url": "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory",
                "authors": [
                    "Hochreiter, Sepp",
                    "Schmidhuber, J\u00fcrgen"
                ],
                "proceeding": "Neural Computation",
                "date": "1997",
                "abstract": "We introduce a new learning algorithm for recurrent neural networks (RNNs) that is able to learn long-term dependencies. The algorithm is based on a new RNN architecture called Long Short-Term Memory (LSTM). LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow.",
                "url_pdf": "https://www.bioinf.jku.at/publications/older/2604.pdf",
                "num_citations": 40411,
                "publisher": "MIT Press",
                "pages": "1735-1780",
                "volume": "9",
                "issue": "8",
                "journal": "Neural Computation",
                "pub_type": "article"
            }
        ],
        "title": "Long Short-Term Memory (LSTM)",
        "wiki_url": "https://en.wikipedia.org/wiki/Long_short-term_memory",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "1997"
    },
    {
        "month": "December",
        "relevant_people": [
            "Mike Schuster",
            "Kuldip K. Paliwal"
        ],
        "description": "The [**Bidirectional Recurrent Neural Networks**](https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks) (BRNN) were introduced by [Mike Schuster](https://www.semanticscholar.org/author/Mike-Schuster/2535126) and [Kuldip K. Paliwal](https://www.semanticscholar.org/author/Kuldip-K.-Paliwal/2407850) in December 1997. BRNNs are a type of [recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network) that can capture information from both past and future time steps, making them particularly effective in sequence-to-sequence learning tasks and natural language processing applications. The main innovation of BRNNs is the use of two separate hidden layers, one for the forward states and one for the backward states, allowing the network to process data in both directions.",
        "related_topics": [
            "Recurrent Neural Networks",
            "Deep Learning",
            "Natural Language Processing",
            "Sequence-to-Sequence Learning",
            "Long Short-Term Memory (LSTM)"
        ],
        "relevant_links": [
            "https://www.researchgate.net/publication/3316656_Bidirectional_recurrent_neural_networks"
        ],
        "papers": [
            {
                "title": "Bidirectional recurrent neural networks",
                "url": "https://www.researchgate.net/publication/3316656_Bidirectional_recurrent_neural_networks",
                "authors": [
                    "Schuster, Mike",
                    "Paliwal, Kuldip K."
                ],
                "date": "1997",
                "abstract": "Bidirectional recurrent neural networks (BRNN) connect two hidden layers of opposite directions to the same output. With this form of generative deep learning, the output layer can get information from past (backwards) and future (forward) states simultaneously. In BRNN, the information of the future is provided from the backward hidden layer, which is opposite to the conventional forward hidden layer. This paper introduces a new, efficient and almost deterministic training algorithm for BRNN.",
                "url_pdf": "https://www.researchgate.net/profile/Kuldip-Paliwal/publication/3316656_Bidirectional_recurrent_neural_networks/links/0046351ad2b4f74a6a000000/Bidirectional-recurrent-neural-networks.pdf",
                "num_citations": 1738,
                "publisher": "IEEE",
                "pages": "267-270",
                "volume": "",
                "journal": "IEEE Transactions on Signal Processing",
                "pub_type": "article"
            }
        ],
        "title": "Bidirectional Recurrent Neural Networks (BRNN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/35/Structural_diagrams_of_unidirectional_and_bidirectional_recurrent_neural_networks.png",
        "date": "1997"
    },
    {
        "relevant_people": [
            "Leslie P. Kaelbling",
            "Michael Littman",
            "Anthony Cassandra"
        ],
        "description": "The [**Partially Observable Markov Decision Process (POMDP)**](https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process) is an extension of the [Markov Decision Process (MDP)](https://en.wikipedia.org/wiki/Markov_decision_process) that deals with uncertain and incomplete information about the environment. In 1998, [Leslie P. Kaelbling](https://en.wikipedia.org/wiki/Leslie_P._Kaelbling), [Michael Littman](https://en.wikipedia.org/wiki/Michael_L._Littman), and [Anthony Cassandra](https://www.cs.brown.edu/~cassandra/) introduced POMDPs and a scalable method for solving them to the AI community. This development jumpstarted the widespread use of POMDPs in various applications, such as robotics, automated planning, and scheduling.",
        "related_topics": [
            "Markov Decision Process",
            "Reinforcement Learning",
            "Robotics",
            "Automated Planning",
            "Scheduling"
        ],
        "relevant_links": [
            "https://www.aaai.org/Papers/AAAI/1998/AAAI98-108.pdf",
            "https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process",
            "https://en.wikipedia.org/wiki/Markov_decision_process",
            "https://en.wikipedia.org/wiki/Leslie_P._Kaelbling",
            "https://en.wikipedia.org/wiki/Michael_L._Littman",
            "https://www.cs.brown.edu/~cassandra/"
        ],
        "papers": [
            {
                "title": "Planning and Acting in Partially Observable Stochastic Domains",
                "url": "https://www.aaai.org/Papers/AAAI/1998/AAAI98-108.pdf",
                "authors": [
                    "Leslie P. Kaelbling",
                    "Michael L. Littman",
                    "Anthony R. Cassandra"
                ],
                "proceeding": "Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98)",
                "date": "1998",
                "abstract": "We address the problem of planning under uncertainty in large Markov Decision Processes (MDPs). The use of MDPs in AI has been hindered by the lack of algorithms that can find optimal policies in a tractable amount of time. We present a new algorithm, called RTDP, which is able to find optimal policies in an order of magnitude less time than current algorithms. We also present a method for solving POMDPs by transforming them into a series of MDPs.",
                "url_pdf": "https://www.aaai.org/Papers/AAAI/1998/AAAI98-108.pdf",
                "num_citations": 1592,
                "publisher": "AAAI Press",
                "pages": "108-115",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "Partially Observable Markov Decision Process (POMPDP)",
        "date": "1998"
    },
    {
        "relevant_people": [
            "Yann LeCun"
        ],
        "type": "Dataset",
        "description": "The [**MNIST**](https://en.wikipedia.org/wiki/MNIST_database) (Modified National Institute of Standards and Technology) database is a dataset of handwritten digits, released in 1998 by a team led by [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun). It consists of a mix of handwritten digits from American Census Bureau employees and American high school students. The MNIST database has since become a benchmark for evaluating handwriting recognition algorithms and has played a significant role in the development of machine learning and deep learning techniques.",
        "related_topics": [
            "Handwriting recognition",
            "Machine learning",
            "Deep learning",
            "Benchmark datasets",
            "Convolutional neural networks"
        ],
        "relevant_links": [
            "http://yann.lecun.com/exdb/mnist/",
            "https://en.wikipedia.org/wiki/MNIST_database",
            "https://www.nist.gov/itl/products-and-services/emnist-dataset",
            "https://www.kaggle.com/c/digit-recognizer",
            "https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d"
        ],
        "papers": [
            {
                "title": "Gradient-based learning applied to document recognition",
                "url": "https://ieeexplore.ieee.org/abstract/document/726791",
                "authors": [
                    "LeCun, Yann",
                    "Bottou, L\u00e9on",
                    "Bengio, Yoshua",
                    "Haffner, Patrick"
                ],
                "proceeding": "Proceedings of the IEEE",
                "date": "1998",
                "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task.",
                "url_pdf": "http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf",
                "num_citations": 12379,
                "publisher": "IEEE",
                "pages": "2278-2324",
                "volume": "86",
                "journal": "Proceedings of the IEEE",
                "pub_type": "article"
            }
        ],
        "title": "MNIST",
        "wiki_url": "https://en.wikipedia.org/wiki/MNIST_database",
        "image": "https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png",
        "date": "1998"
    },
    {
        "relevant_people": [
            "Yann LeCun"
        ],
        "description": "The [**LeNet-5**](https://en.wikipedia.org/wiki/LeNet) is a 7-level convolutional network developed by [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun) and his team in 1998. It was designed to classify handwritten digits and was adopted by several banks to recognize handwritten numbers on checks, which were digitized into 32x32 pixel images. The processing of higher-resolution images necessitates larger and more layers of convolutional neural networks, making this technique limited by the availability of computing resources.",
        "related_topics": [
            "Convolutional Neural Networks",
            "Handwritten Digit Recognition",
            "Deep Learning",
            "Image Classification",
            "Optical Character Recognition"
        ],
        "relevant_links": [
            "http://yann.lecun.com/exdb/lenet/",
            "https://ieeexplore.ieee.org/document/726791",
            "https://en.wikipedia.org/wiki/Convolutional_neural_network",
            "https://en.wikipedia.org/wiki/Yann_LeCun"
        ],
        "papers": [
            {
                "title": "Gradient-Based Learning Applied to Document Recognition",
                "url": "https://ieeexplore.ieee.org/document/726791",
                "authors": [
                    "LeCun, Yann",
                    "Bottou, L\u00e9on",
                    "Bengio, Yoshua",
                    "Haffner, Patrick"
                ],
                "proceeding": "Proceedings of the IEEE",
                "date": "1998",
                "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task.",
                "url_pdf": "http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf",
                "num_citations": 25381,
                "publisher": "IEEE",
                "pages": "2278-2324",
                "volume": "86",
                "journal": "Proceedings of the IEEE",
                "pub_type": "article"
            }
        ],
        "title": "LeNet-5",
        "wiki_url": "https://en.wikipedia.org/wiki/LeNet",
        "image": "https://upload.wikimedia.org/wikipedia/commons/c/cc/Comparison_image_neural_networks.svg",
        "date": "1998"
    },
    {
        "relevant_people": [
            "Sebastian Mika",
            "Gunnar R\u00e4tsch",
            "Jason Weston",
            "Bernhard Scholkopf",
            "Klaus-Robert M\u00fcller"
        ],
        "description": "The [**Kernel Fisher Discriminant Analysis (KFD)**](https://en.wikipedia.org/wiki/Kernel_Fisher_discriminant_analysis) is an extension of [Fisher's linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis) method that uses [kernel functions](https://en.wikipedia.org/wiki/Kernel_method) to map input data into a high-dimensional feature space. This allows for better separation of classes in complex, non-linearly separable problems. The KFD was introduced in a paper titled 'Fisher discriminant analysis with kernels' in 1999 by [Sebastian Mika](https://scholar.google.com/citations?user=Op1bHgIAAAAJ), [Gunnar R\u00e4tsch](https://scholar.google.com/citations?user=KjH7bOAAAAAJ), [Jason Weston](https://scholar.google.com/citations?user=DuzR0iUAAAAJ), [Bernhard Scholkopf](https://scholar.google.com/citations?user=DZ-fHPgAAAAJ), and [Klaus-Robert M\u00fcller](https://scholar.google.com/citations?user=8vxFz7YAAAAJ).",
        "related_topics": [
            "Fisher's linear discriminant analysis",
            "Kernel methods",
            "Machine learning",
            "Pattern recognition",
            "Support vector machines"
        ],
        "relevant_links": [
            "https://ieeexplore.ieee.org/document/788184",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639",
            "https://en.wikipedia.org/wiki/Kernel_Fisher_discriminant_analysis"
        ],
        "papers": [
            {
                "title": "Fisher discriminant analysis with kernels",
                "url": "https://ieeexplore.ieee.org/document/788184",
                "authors": [
                    "Mika, Sebastian",
                    "R\u00e4tsch, Gunnar",
                    "Weston, Jason",
                    "Scholkopf, Bernhard",
                    "M\u00fcller, Klaus-Robert"
                ],
                "proceeding": "Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop",
                "date": "1999",
                "abstract": "In this article, we present a new method for performing Fisher discriminant analysis (FDA) using kernel functions. The original FDA is a classical pattern recognition method that tries to find a linear combination of the features such that the class separability is maximized. In contrast, the kernel Fisher discriminant (KFD) analysis is based on a nonlinear mapping of the input data into a high dimensional feature space.",
                "url_pdf": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.1639&rep=rep1&type=pdf",
                "num_citations": 1507,
                "publisher": "IEEE",
                "pages": "41-48",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "Kernel Fisher Discriminant Analysis (KFD)",
        "wiki_url": "https://en.wikipedia.org/wiki/Kernel_Fisher_discriminant_analysis",
        "image": null,
        "date": "1999"
    },
    {
        "relevant_people": [],
        "description": "The [**Torch**](https://en.wikipedia.org/wiki/Torch_(machine_learning)) library is an open-source machine learning library, a scientific computing framework, and a script language based on the [Lua programming language](https://en.wikipedia.org/wiki/Lua_(programming_language)). It provides a wide range of algorithms for deep learning and uses the scripting language LuaJIT, and an underlying C implementation. First released in 2002, Torch has been used by numerous research organizations, including [Facebook's AI Research lab](https://ai.facebook.com/), [IBM](https://www.ibm.com/), and [Yandex](https://yandex.com/), for various machine learning tasks.",
        "related_topics": [
            "Deep learning",
            "Machine learning",
            "Lua programming language",
            "Scientific computing",
            "Neural networks"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Torch_(machine_learning)",
            "https://torch.ch/",
            "https://github.com/torch/torch7",
            "https://developer.nvidia.com/torch"
        ],
        "papers": [],
        "title": "Torch",
        "wiki_url": "https://en.wikipedia.org/wiki/Torch",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/eb/18th_November_Torchlight_procession_2013.jpg",
        "date": "2002"
    },
    {
        "relevant_people": [
            "Li Fei-Fei",
            "Rob Fergus",
            "Pietro Perona"
        ],
        "description": "The [**One-Shot Learning of Object Categories**](https://papers.nips.cc/paper/2005/file/69b72a0b5f8de14e0e5a0b0a1f5e9b9a-Paper.pdf) paper introduced a new approach to object recognition in computer vision, where a machine learning model can learn to recognize new objects with very little data. The authors, [Li Fei-Fei](https://en.wikipedia.org/wiki/Fei-Fei_Li), [Rob Fergus](https://cs.nyu.edu/~fergus/), and [Pietro Perona](https://en.wikipedia.org/wiki/Pietro_Perona), presented their work at the 27th Annual Conference on Neural Information Processing Systems (NIPS 2005). Their research has had a significant impact on the development of deep learning and computer vision, particularly in the area of few-shot learning.",
        "related_topics": [
            "Computer Vision",
            "Machine Learning",
            "Deep Learning",
            "Few-Shot Learning",
            "Neural Networks"
        ],
        "relevant_links": [
            "https://papers.nips.cc/paper/2005/file/69b72a0b5f8de14e0e5a0b0a1f5e9b9a-Paper.pdf",
            "https://en.wikipedia.org/wiki/Fei-Fei_Li",
            "https://cs.nyu.edu/~fergus/",
            "https://en.wikipedia.org/wiki/Pietro_Perona"
        ],
        "papers": [
            {
                "title": "One-Shot Learning of Object Categories",
                "url": "https://papers.nips.cc/paper/2005/file/69b72a0b5f8de14e0e5a0b0a1f5e9b9a-Paper.pdf",
                "authors": [
                    "Li Fei-Fei",
                    "Rob Fergus",
                    "Pietro Perona"
                ],
                "proceeding": "Proceedings of the 27th Annual Conference on Neural Information Processing Systems (NIPS 2005)",
                "date": "2005",
                "abstract": "We present a method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We achieve this by building on recent developments in the theory of Bayesian inference. We demonstrate our method on several real-world object categories and show that it can learn models from as few as 1-5 training examples.",
                "url_pdf": "https://papers.nips.cc/paper/2005/file/69b72a0b5f8de14e0e5a0b0a1f5e9b9a-Paper.pdf",
                "num_citations": 2031,
                "publisher": "NIPS",
                "pages": "1-8",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "One-Shot Learning of Object Categories",
        "wiki_url": "https://en.wikipedia.org/wiki/One-shot_learning_(computer_vision)",
        "image": null,
        "date": "2005"
    },
    {
        "relevant_people": [
            "Geoffrey Hinton"
        ],
        "description": "The [**Deep Belief Network**](https://en.wikipedia.org/wiki/Deep_belief_network) (DBN) is a generative graphical model composed of multiple layers of [Restricted Boltzmann Machines](https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine) (RBMs). It was introduced by [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) in 2006, and it marked a significant breakthrough in the field of deep learning. DBNs can learn to generate data that is similar to the training data and can be fine-tuned using backpropagation for supervised learning tasks.",
        "related_topics": [
            "Deep Learning",
            "Restricted Boltzmann Machine",
            "Generative Models",
            "Unsupervised Learning",
            "Neural Networks"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Deep_belief_network",
            "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine",
            "https://en.wikipedia.org/wiki/Geoffrey_Hinton",
            "https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf",
            "https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf"
        ],
        "papers": [
            {
                "title": "A fast learning algorithm for deep belief nets",
                "url": "https://www.mitpressjournals.org/doi/abs/10.1162/neco.2006.18.7.1527",
                "authors": [
                    "Hinton, Geoffrey E",
                    "Osindero, Simon",
                    "Teh, Yee-Whye"
                ],
                "proceeding": "Neural computation",
                "date": "2006",
                "abstract": "We show how to use 'complementary priors' to eliminate the explaining away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm.",
                "url_pdf": "https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf",
                "num_citations": 10274,
                "publisher": "MIT Press",
                "pages": "1527--1554",
                "volume": "18",
                "journal": "Neural computation",
                "pub_type": "article"
            }
        ],
        "title": "Deep Belief Network (DBN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Deep_belief_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fa/Deep_belief_net.svg",
        "date": "2006"
    },
    {
        "relevant_people": [
            "Geoffrey Hinton",
            "Ruslan R. Salakhutdinov"
        ],
        "description": "The [**AutoEncoder**](https://en.wikipedia.org/wiki/Autoencoder) is a type of artificial neural network used for unsupervised learning of efficient codings. In 2006, [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) and [Ruslan R. Salakhutdinov](https://en.wikipedia.org/wiki/Ruslan_Salakhutdinov) published a groundbreaking paper titled '[Reducing the Dimensionality of Data with Neural Networks](https://www.cs.toronto.edu/~hinton/science.pdf)' which demonstrated the effectiveness of autoencoders in reducing the dimensionality of data while preserving its structure. This work played a significant role in the development of deep learning and the resurgence of neural networks.",
        "related_topics": [
            "Deep Learning",
            "Neural Networks",
            "Unsupervised Learning",
            "Dimensionality Reduction",
            "Representation Learning"
        ],
        "relevant_links": [
            "https://www.cs.toronto.edu/~hinton/science.pdf",
            "https://en.wikipedia.org/wiki/Autoencoder",
            "https://en.wikipedia.org/wiki/Geoffrey_Hinton",
            "https://en.wikipedia.org/wiki/Ruslan_Salakhutdinov"
        ],
        "papers": [
            {
                "title": "Reducing the Dimensionality of Data with Neural Networks",
                "url": "https://www.cs.toronto.edu/~hinton/science.pdf",
                "authors": [
                    "Geoffrey E. Hinton",
                    "Ruslan R. Salakhutdinov"
                ],
                "proceeding": "Science",
                "date": "2006",
                "abstract": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such 'autoencoder' networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.",
                "url_pdf": "https://www.cs.toronto.edu/~hinton/science.pdf",
                "num_citations": 12000,
                "publisher": "American Association for the Advancement of Science",
                "pages": "504--507",
                "volume": "313",
                "journal": "Science",
                "pub_type": "article"
            }
        ],
        "title": "AutoEncoder",
        "wiki_url": "https://en.wikipedia.org/wiki/Autoencoder",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png",
        "date": "2006"
    },
    {
        "date": "2008-07-05",
        "relevant_people": [
            "Pascal Vincent",
            "Hugo Larochelle",
            "Yoshua Bengio",
            "Pierre-Antoine Manzagol"
        ],
        "description": "The [**Denoising Auto Encoder (DAE)**](https://en.wikipedia.org/wiki/Autoencoder#Denoising_autoencoder_(DAE)) is a type of artificial neural network that is designed to learn efficient data representations by removing noise from the input data. It was introduced in the paper ['Extracting and Composing Robust Features with Denoising Autoencoders'](https://dl.acm.org/doi/10.1145/1390156.1390294) by [Pascal Vincent](https://scholar.google.com/citations?user=0PYvY_IAAAAJ&hl=en), [Hugo Larochelle](https://scholar.google.com/citations?user=x7A6UdYAAAAJ&hl=en), [Yoshua Bengio](https://scholar.google.com/citations?user=mDnn7g0AAAAJ&hl=en), and [Pierre-Antoine Manzagol](https://scholar.google.com/citations?user=4Pb4p4IAAAAJ&hl=en). The DAE has been used in various applications such as image denoising, feature extraction, and unsupervised learning.",
        "related_topics": [
            "Autoencoder",
            "Deep learning",
            "Neural networks",
            "Unsupervised learning",
            "Feature extraction"
        ],
        "relevant_links": [
            "https://dl.acm.org/doi/10.1145/1390156.1390294",
            "https://en.wikipedia.org/wiki/Autoencoder#Denoising_autoencoder_(DAE)",
            "https://www.researchgate.net/publication/220243176_Extracting_and_Composing_Robust_Features_with_Denoising_Autoencoders"
        ],
        "papers": [
            {
                "title": "Extracting and Composing Robust Features with Denoising Autoencoders",
                "url": "https://dl.acm.org/doi/10.1145/1390156.1390294",
                "authors": [
                    "Pascal Vincent",
                    "Hugo Larochelle",
                    "Yoshua Bengio",
                    "Pierre-Antoine Manzagol"
                ],
                "proceeding": "Proceedings of the 25th international conference on Machine learning",
                "date": "2008",
                "abstract": "We propose a novel approach to unsupervised feature learning based on denoising autoencoders, which are trained to denoise corrupted versions of the input data. We show that the denoising autoencoder is able to extract useful features from data and compose them into higher-level representations.",
                "url_pdf": "https://www.researchgate.net/profile/Hugo-Larochelle/publication/220243176_Extracting_and_Composing_Robust_Features_with_Denoising_Autoencoders/links/00b7d52a1b2a8a3e3d000000/Extracting-and-Composing-Robust-Features-with-Denoising-Autoencoders.pdf",
                "num_citations": 2854,
                "publisher": "ACM",
                "pages": "1096--1103",
                "conference": "25th International Conference on Machine Learning",
                "pub_type": "conference_paper"
            }
        ],
        "title": "Denoising Auto Encoder (DAE)",
        "wiki_url": "https://en.wikipedia.org/wiki/Autoencoder",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png"
    },
    {
        "relevant_people": [
            "Fei-Fei Li"
        ],
        "description": "The [**ImageNet**](https://en.wikipedia.org/wiki/ImageNet) project is a large visual database created by [Fei-Fei Li](https://en.wikipedia.org/wiki/Fei-Fei_Li) at Stanford University in 2009. It aimed to provide a vast amount of real-world data to improve the performance of machine learning algorithms. The database contains millions of labeled images across thousands of categories and has been instrumental in advancing the field of computer vision. ImageNet is often credited as the catalyst for the AI boom of the 21st century.",
        "related_topics": [
            "Computer Vision",
            "Deep Learning",
            "Convolutional Neural Networks",
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/ImageNet",
            "https://image-net.org/",
            "https://www.youtube.com/watch?v=40riCqvRoMs",
            "https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/",
            "https://www.nytimes.com/2018/11/18/technology/artificial-intelligence-language.html"
        ],
        "papers": [
            {
                "title": "ImageNet: A Large-Scale Hierarchical Image Database",
                "url": "https://ieeexplore.ieee.org/abstract/document/5206848",
                "authors": [
                    "Jia Deng",
                    "Wei Dong",
                    "Richard Socher",
                    "Li-Jia Li",
                    "Kai Li",
                    "Fei-Fei Li"
                ],
                "proceeding": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
                "date": "2009",
                "abstract": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce a new database called \"ImageNet\", a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets.",
                "url_pdf": "http://www.image-net.org/papers/imagenet_cvpr09.pdf",
                "num_citations": 22309,
                "publisher": "IEEE",
                "pages": "248-255",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "ImageNet",
        "wiki_url": "https://en.wikipedia.org/wiki/ImageNet",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/4f/ImageNet_error_rate_history_%28just_systems%29.svg",
        "date": "2009"
    },
    {
        "relevant_people": [],
        "description": "Kaggle is an online community of data scientists and machine learning practitioners, founded in 2010. The platform hosts machine learning competitions, where participants can submit their solutions to various data science problems. Kaggle has been instrumental in fostering collaboration and innovation in the field of artificial intelligence, as well as providing a platform for learning and knowledge sharing. The platform has grown over the years to include datasets, kernels (code sharing), and discussion forums.",
        "related_topics": [
            "Machine learning",
            "Data science",
            "Artificial intelligence",
            "Competitions",
            "Collaboration"
        ],
        "relevant_links": [
            "https://www.kaggle.com/",
            "https://en.wikipedia.org/wiki/Kaggle",
            "https://www.forbes.com/sites/gilpress/2013/03/24/kaggle-the-marriage-broker-between-companies-and-data-scientists/",
            "https://venturebeat.com/2012/08/08/kaggle-data-science-competitions/",
            "https://www.technologyreview.com/2012/04/19/184615/data-science-platform-kaggle-aims-to-match-geeks-with-gigs/"
        ],
        "papers": [],
        "title": "Kaggle",
        "wiki_url": "https://en.wikipedia.org/wiki/Kaggle",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/41/Global_thinking.svg",
        "date": "2010"
    },
    {
        "relevant_people": [
            "Quoc V. Le",
            "Marc'Aurelio Ranzato",
            "Rajat Monga",
            "Matthieu Devin",
            "Kai Chen",
            "Greg S. Corrado",
            "Jeff Dean",
            "Andrew Y. Ng"
        ],
        "description": "The [**Sparse Auto Encoder (SAE)**](https://en.wikipedia.org/wiki/Autoencoder#Sparse_autoencoder) is a neural network model that was introduced in 2011. It is an unsupervised learning algorithm that learns efficient representations of input data by enforcing sparsity constraints on the hidden layer activations. SAEs have been used in various applications, such as feature learning, dimensionality reduction, and pretraining for deep neural networks.",
        "related_topics": [
            "Autoencoders",
            "Unsupervised learning",
            "Deep learning",
            "Neural networks",
            "Feature learning"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1112.6209"
        ],
        "papers": [
            {
                "title": "Building high-level features using large scale unsupervised learning",
                "url": "https://arxiv.org/abs/1112.6209",
                "authors": [
                    "Quoc V. Le",
                    "Marc'Aurelio Ranzato",
                    "Rajat Monga",
                    "Matthieu Devin",
                    "Kai Chen",
                    "Greg S. Corrado",
                    "Jeff Dean",
                    "Andrew Y. Ng"
                ],
                "date": "2011",
                "abstract": "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder withpooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art.",
                "url_pdf": "https://arxiv.org/pdf/1112.6209.pdf",
                "num_citations": 5287,
                "publisher": "arXiv",
                "pub_type": "article"
            }
        ],
        "title": "Sparse Auto Encoder (SAE)",
        "wiki_url": "https://en.wikipedia.org/wiki/Autoencoder",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png",
        "date": "2011"
    },
    {
        "location": "Toronto",
        "relevant_people": [],
        "description": "The [**Contractive Auto Encoder (CAE)**](https://www.cs.toronto.edu/~larocheh/publications/icml-2011-contracive-autoencoders.pdf) is a type of autoencoder that explicitly enforces invariance during feature extraction. Introduced in 2011, CAEs are designed to learn a representation of input data that is robust to small variations. They achieve this by adding a penalty term to the objective function, which encourages the model to learn a contracted or stable representation of the input data.",
        "related_topics": [
            "Autoencoders",
            "Deep Learning",
            "Representation Learning",
            "Unsupervised Learning"
        ],
        "relevant_links": [
            "https://www.cs.toronto.edu/~larocheh/publications/icml-2011-contracive-autoencoders.pdf",
            "https://www.researchgate.net/publication/221650525_Contractive_Auto-Encoders_Explicit_Invariance_During_Feature_Extraction"
        ],
        "papers": [
            {
                "title": "Contractive Auto-Encoders: Explicit Invariance During Feature Extraction",
                "url": "https://www.cs.toronto.edu/~larocheh/publications/icml-2011-contracive-autoencoders.pdf",
                "authors": [
                    "Hugo Larochelle",
                    "Dumitru Erhan",
                    "Aaron Courville",
                    "James Bergstra",
                    "Yoshua Bengio"
                ],
                "proceeding": "Proceedings of the 28th International Conference on Machine Learning (ICML)",
                "date": "2011",
                "abstract": "We present a new type of auto-encoder that learns to extract features by training a parametric mapping from the input space to a feature space such that the Jacobian of the mapping is encouraged to be contractive with respect to the input. This contrasts with other auto-encoders that mostly rely on the smoothness of the learned mapping to obtain good generalization. We provide a simple and efficient algorithm to train contractive auto-encoders and show that they can outperform other auto-encoders on a number of classification tasks.",
                "url_pdf": "https://www.cs.toronto.edu/~larocheh/publications/icml-2011-contracive-autoencoders.pdf",
                "num_citations": 684,
                "publisher": "JMLR.org",
                "pages": "833--840",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "Contractive Auto Encoder (CAE)",
        "wiki_url": "https://en.wikipedia.org/wiki/Autoencoder",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png",
        "date": "2011"
    },
    {
        "relevant_people": [
            "IBM"
        ],
        "description": "IBM's [**Watson**](https://en.wikipedia.org/wiki/Watson_(computer)) is an artificial intelligence system that gained fame in 2011 when it defeated two human champions in a [**Jeopardy!**](https://en.wikipedia.org/wiki/Jeopardy!) competition. Watson utilized a combination of [machine learning](https://en.wikipedia.org/wiki/Machine_learning), [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing), and [information retrieval](https://en.wikipedia.org/wiki/Information_retrieval) techniques to understand and answer questions posed in natural language. This achievement showcased the potential of AI systems in understanding and processing human language, as well as their ability to compete with humans in complex tasks.",
        "related_topics": [
            "IBM",
            "Artificial Intelligence",
            "Machine Learning",
            "Natural Language Processing",
            "Information Retrieval",
            "Game Shows"
        ],
        "relevant_links": [
            "https://www.ibm.com/watson",
            "https://en.wikipedia.org/wiki/Watson_(computer)",
            "https://www.ibm.com/blogs/think/2016/02/ibmwatson-jeopardy/",
            "https://www.youtube.com/watch?v=WFR3lOm_xhE"
        ],
        "papers": [
            {
                "title": "Building Watson: An Overview of the DeepQA Project",
                "url": "https://dl.acm.org/doi/10.1145/2018396.2018398",
                "authors": [
                    "Ferrucci, David",
                    "Levas, Anthony",
                    "Bagchi, Sugato",
                    "Gondek, David",
                    "Mueller, Erik T."
                ],
                "proceeding": "AI Magazine",
                "date": "2010",
                "abstract": "IBM Research undertook a challenge to build a computer system that could compete at the human champion level in real time on the American TV quiz show, Jeopardy. The extent of the challenge includes fielding a real-time automatic contestant on the show, which can receive the questions in text form, determine an answer, decide whether to interrupt the other contestants by signaling its intent to respond, and deliver a well-formed English response.",
                "url_pdf": "https://www.researchgate.net/profile/Erik_Mueller3/publication/220403979_Building_Watson_An_Overview_of_the_DeepQA_Project/links/0deec524d5e5b5f8b6000000/Building-Watson-An-Overview-of-the-DeepQA-Project.pdf",
                "num_citations": 1272,
                "publisher": "Association for Computational Linguistics",
                "pages": "59-79",
                "volume": "31",
                "journal": "AI Magazine",
                "pub_type": "article"
            }
        ],
        "title": "Watson Beats Jeopardy",
        "wiki_url": "https://en.wikipedia.org/wiki/IBM_Watson",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/41/DeepQA.svg",
        "date": "2011"
    },
    {
        "relevant_people": [
            "Andrew Ng",
            "Jeff Dean"
        ],
        "organization": "Google Brain",
        "description": "In 2012, the [**Google Brain**](https://en.wikipedia.org/wiki/Google_Brain) team, led by [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng) and [Jeff Dean](https://en.wikipedia.org/wiki/Jeff_Dean_(computer_scientist)), created a neural network that learned to recognize cats by watching unlabeled images taken from frames of YouTube videos. This achievement demonstrated the potential of [unsupervised learning](https://en.wikipedia.org/wiki/Unsupervised_learning) in neural networks and marked a significant milestone in the field of [deep learning](https://en.wikipedia.org/wiki/Deep_learning).",
        "related_topics": [
            "Deep learning",
            "Neural networks",
            "Unsupervised learning",
            "Image recognition",
            "Machine learning"
        ],
        "relevant_links": [
            "https://www.nytimes.com/2012/06/26/technology/in-a-big-network-of-computers-evidence-of-machine-learning.html",
            "https://www.wired.com/2012/06/google-x-neural-network/",
            "https://ai.google/research/teams/brain/",
            "https://www.youtube.com/watch?v=n1ViNeWhC24"
        ],
        "papers": [
            {
                "title": "Building high-level features using large scale unsupervised learning",
                "url": "https://arxiv.org/abs/1112.6209",
                "authors": [
                    "Quoc V. Le",
                    "Marc'Aurelio Ranzato",
                    "Rajat S. Monga",
                    "Matthieu Devin",
                    "Kai Chen",
                    "Greg S. Corrado",
                    "Jeff Dean",
                    "Andrew Y. Ng"
                ],
                "date": "2012",
                "abstract": "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images?",
                "url_pdf": "https://arxiv.org/pdf/1112.6209.pdf",
                "num_citations": 2183,
                "conference": "International Conference on Learning Representations (ICLR)",
                "pub_type": "conference paper"
            }
        ],
        "title": "Recognizes Cats",
        "wiki_url": "https://en.wikipedia.org/wiki/List_of_cat_breeds",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/f3/20050922AmarilloRes.jpg",
        "date": "2012"
    },
    {
        "relevant_people": [
            "Alex Krizhevsky",
            "Ilya Sutskever",
            "Geoffrey Hinton"
        ],
        "description": "The [**AlexNet**](https://en.wikipedia.org/wiki/AlexNet) is a deep convolutional neural network (DCNN) that significantly impacted the field of computer vision and deep learning. It was developed by [Alex Krizhevsky](https://en.wikipedia.org/wiki/Alex_Krizhevsky), [Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever), and [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton). AlexNet won the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC) by a large margin, demonstrating the effectiveness of deep learning for image recognition tasks. The network consisted of eight layers, including five convolutional layers and three fully connected layers. The use of rectified linear units (ReLU) as activation functions and dropout for regularization contributed to its success. AlexNet's groundbreaking performance accelerated research in deep learning and its applications in various domains.",
        "related_topics": [
            "Deep Learning",
            "Convolutional Neural Networks",
            "ImageNet",
            "Computer Vision",
            "Artificial Intelligence"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/AlexNet",
            "https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html",
            "https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf",
            "https://medium.com/analytics-vidhya/understanding-alexnet-c7c6f2c3625a",
            "https://towardsdatascience.com/alexnet-the-architecture-that-challenged-cnns-e406d5297951"
        ],
        "papers": [
            {
                "title": "ImageNet Classification with Deep Convolutional Neural Networks",
                "url": "https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html",
                "authors": [
                    "Alex Krizhevsky",
                    "Ilya Sutskever",
                    "Geoffrey E. Hinton"
                ],
                "proceeding": "Advances in Neural Information Processing Systems 25 (NIPS 2012)",
                "date": "2012",
                "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art.",
                "url_pdf": "https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf",
                "num_citations": 67794,
                "publisher": "Neural Information Processing Systems",
                "pages": "1097--1105",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "Deep Convolutional Neural Network (DCNN) [AlexNet]",
        "wiki_url": "https://en.wikipedia.org/wiki/Convolutional_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/c/cc/Comparison_image_neural_networks.svg",
        "date": "2012"
    },
    {
        "relevant_people": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Alex Graves",
            "Ioannis Antonoglou",
            "Daan Wierstra",
            "Martin Riedmiller"
        ],
        "description": "The [**Deep Q Network (DQN)**](https://en.wikipedia.org/wiki/Q-learning#Deep_Q-learning) is a breakthrough in deep reinforcement learning, combining [Q-learning](https://en.wikipedia.org/wiki/Q-learning) with deep neural networks. It was introduced in 2013 by a team of researchers including [Volodymyr Mnih](https://en.wikipedia.org/wiki/Volodymyr_Mnih), [Koray Kavukcuoglu](https://scholar.google.com/citations?user=lqO3A8oAAAAJ&hl=en), [David Silver](https://en.wikipedia.org/wiki/David_Silver_(computer_scientist)), [Alex Graves](https://en.wikipedia.org/wiki/Alex_Graves_(computer_scientist)), [Ioannis Antonoglou](https://scholar.google.com/citations?user=rJw7VZwAAAAJ&hl=en), [Daan Wierstra](https://scholar.google.com/citations?user=3f3wJEEAAAAJ&hl=en), and [Martin Riedmiller](https://scholar.google.com/citations?user=0Z0RwZAAAAAJ&hl=en). Their paper, ['Playing Atari with Deep Reinforcement Learning'](https://arxiv.org/abs/1312.5602), demonstrated the ability of DQNs to learn and master various Atari games directly from raw pixel inputs, outperforming previous methods. The DQN algorithm was a significant milestone in AI research, leading to numerous advancements in reinforcement learning and the development of more sophisticated algorithms.",
        "related_topics": [
            "Reinforcement Learning",
            "Q-Learning",
            "Deep Learning",
            "Neural Networks",
            "Atari Games"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1312.5602",
            "https://en.wikipedia.org/wiki/Q-learning#Deep_Q-learning",
            "https://en.wikipedia.org/wiki/Reinforcement_learning"
        ],
        "papers": [
            {
                "title": "Playing Atari with Deep Reinforcement Learning",
                "url": "https://arxiv.org/abs/1312.5602",
                "authors": [
                    "Volodymyr Mnih",
                    "Koray Kavukcuoglu",
                    "David Silver",
                    "Alex Graves",
                    "Ioannis Antonoglou",
                    "Daan Wierstra",
                    "Martin Riedmiller"
                ],
                "proceeding": "arXiv preprint",
                "date": "2013",
                "abstract": "We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.",
                "url_pdf": "https://arxiv.org/pdf/1312.5602.pdf",
                "num_citations": 11794,
                "publisher": "arXiv",
                "pages": "1-9",
                "volume": "",
                "journal": "arXiv preprint",
                "pub_type": "article"
            }
        ],
        "title": "Deep Q Network (DQN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Q-learning",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg",
        "date": "2013"
    },
    {
        "relevant_people": [
            "Richard S. Sutton",
            "Andrew G. Barto"
        ],
        "description": "The [**Actor-Critic Networks**](https://en.wikipedia.org/wiki/Actor%E2%80%93critic_method) are a class of reinforcement learning algorithms that consist of two components: an actor, which is responsible for selecting actions, and a critic, which evaluates the actions chosen by the actor. The actor-critic framework was first introduced by [Richard S. Sutton](https://en.wikipedia.org/wiki/Richard_S._Sutton) and [Andrew G. Barto](https://en.wikipedia.org/wiki/Andrew_Barto) in 1983. It has since become an important approach in the field of reinforcement learning, as it combines the strengths of both value-based and policy-based methods, leading to more efficient and stable learning.",
        "related_topics": [
            "Reinforcement Learning",
            "Deep Learning",
            "Neural Networks",
            "Temporal-Difference Learning",
            "Q-Learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Actor%E2%80%93critic_method",
            "https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPAMIT99.pdf",
            "https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf"
        ],
        "papers": [
            {
                "title": "Actor-Critic Algorithms",
                "url": "https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf",
                "authors": [
                    "Richard S. Sutton",
                    "David McAllester",
                    "Satinder Singh",
                    "Yishay Mansour"
                ],
                "proceeding": "Advances in Neural Information Processing Systems 12",
                "date": "2000",
                "abstract": "This paper presents actor-critic algorithms for Markov decision processes with continuous state spaces and unknown, continuous, bounded reward functions. The algorithms are based on a new, nonparametric, online algorithm for estimating the values of states, which we call the kernel-based connectionist temporal difference (KBTD) algorithm. The KBTD algorithm is based on the connectionist temporal difference (CTD) algorithm, but uses a kernel-based representation of the value function.",
                "url_pdf": "https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf",
                "num_citations": 1286,
                "publisher": "Neural Information Processing Systems",
                "pages": "1008-1014",
                "volume": "12",
                "journal": "Advances in Neural Information Processing Systems",
                "pub_type": "conference"
            }
        ],
        "title": "Actor-Critic Networks",
        "wiki_url": "https://en.wikipedia.org/wiki/Actor%E2%80%93network_theory",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/36/Queue.svg",
        "date": "1983"
    },
    {
        "date": "December 20, 2013",
        "relevant_people": [
            "Diederik P. Kingma",
            "Max Welling"
        ],
        "description": "The [**Variational Auto Encoder (VAE)**](https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)) is a generative model that combines deep learning and probabilistic graphical models. VAEs are used to generate new data samples by learning a continuous latent space representation of the input data. They provide an efficient way of learning the underlying structure of the data, and have been applied to a wide range of applications, such as image generation, text generation, and reinforcement learning.",
        "related_topics": [
            "Deep learning",
            "Generative models",
            "Probabilistic graphical models",
            "Neural networks",
            "Unsupervised learning"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1312.6114"
        ],
        "papers": [
            {
                "title": "Auto-Encoding Variational Bayes",
                "url": "https://arxiv.org/abs/1312.6114",
                "authors": [
                    "Diederik P. Kingma",
                    "Max Welling"
                ],
                "date": "December 20, 2013",
                "abstract": "We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator.",
                "url_pdf": "https://arxiv.org/pdf/1312.6114.pdf",
                "num_citations": 12537,
                "publisher": "arXiv",
                "pub_type": "preprint"
            }
        ],
        "title": "Variational Auto Encoder (VAE)",
        "wiki_url": "https://en.wikipedia.org/wiki/Variational_autoencoder",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Kernel_Machine.svg"
    },
    {
        "relevant_people": [
            "Kyunghyun Cho",
            "Bart van Merrienboer",
            "Caglar Gulcehre",
            "Fethi Bougares",
            "Holger Schwenk",
            "Dzmitry Bahdanau",
            "Yoshua Bengio"
        ],
        "description": "The [**Gated Recurrent Unit (GRU)**](https://en.wikipedia.org/wiki/Gated_recurrent_unit) is a recurrent neural network architecture introduced in 2014. It was designed to address the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) in traditional recurrent neural networks (RNNs) and improve the efficiency of learning long-range dependencies. The GRU was proposed by [Kyunghyun Cho](https://en.wikipedia.org/wiki/Kyunghyun_Cho), Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, [Dzmitry Bahdanau](https://en.wikipedia.org/wiki/Dzmitry_Bahdanau), and [Yoshua Bengio](https://en.wikipedia.org/wiki/Yoshua_Bengio) in their paper 'Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation'. The GRU has since become a popular choice for various sequence-to-sequence learning tasks, such as machine translation and speech recognition.",
        "related_topics": [
            "Recurrent Neural Networks",
            "Long Short-Term Memory (LSTM)",
            "Deep Learning",
            "Sequence-to-Sequence Learning",
            "Machine Translation",
            "Speech Recognition"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1406.1078",
            "https://en.wikipedia.org/wiki/Gated_recurrent_unit",
            "https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be",
            "https://machinelearningmastery.com/gated-recurrent-unit-networks/"
        ],
        "papers": [
            {
                "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation",
                "url": "https://arxiv.org/abs/1406.1078",
                "authors": [
                    "Kyunghyun Cho",
                    "Bart van Merrienboer",
                    "Caglar Gulcehre",
                    "Fethi Bougares",
                    "Holger Schwenk",
                    "Dzmitry Bahdanau",
                    "Yoshua Bengio"
                ],
                "proceeding": "Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "date": "2014",
                "abstract": "In this paper, we propose a novel neural network model called RNN Encoder\u2013Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-size vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2013Decoder as an additional feature in the existing log-linear model.",
                "url_pdf": "https://arxiv.org/pdf/1406.1078.pdf",
                "num_citations": 10000,
                "publisher": "Association for Computational Linguistics",
                "pages": "1724--1734",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "Gated Recurrent Unit (GRU)",
        "wiki_url": "https://en.wikipedia.org/wiki/Gated_recurrent_unit",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/37/Gated_Recurrent_Unit%2C_base_type.svg",
        "date": "2014"
    },
    {
        "relevant_people": [
            "Facebook researchers"
        ],
        "description": "In 2014, Facebook researchers published their work on [**DeepFace**](https://research.fb.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/), a facial recognition system that uses neural networks to identify faces with an accuracy of 97.35%. This represented an improvement of more than 27% over previous systems and rivaled human performance in facial recognition tasks. DeepFace was a significant milestone in the field of AI, demonstrating the power of deep learning and neural networks for practical applications.",
        "related_topics": [
            "Facial recognition",
            "Deep learning",
            "Neural networks",
            "Artificial intelligence",
            "Facebook AI"
        ],
        "relevant_links": [
            "https://research.fb.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/",
            "https://www.wired.com/2014/03/facebook-deepface-facial-recognition/"
        ],
        "papers": [
            {
                "title": "DeepFace: Closing the Gap to Human-Level Performance in Face Verification",
                "url": "https://research.fb.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/",
                "authors": [
                    "Yaniv Taigman",
                    "Ming Yang",
                    "Marc'Aurelio Ranzato",
                    "Lior Wolf"
                ],
                "proceeding": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
                "date": "2014",
                "abstract": "In modern face recognition, the conventional pipeline consists of four stages: detect, align, represent and classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4,000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.25% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 25%, closely approaching human-level performance.",
                "url_pdf": "https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf",
                "num_citations": 5414,
                "publisher": "IEEE",
                "pages": "1701-1708",
                "volume": "",
                "journal": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
                "pub_type": "conference"
            }
        ],
        "title": "DeepFace",
        "wiki_url": "https://en.wikipedia.org/wiki/DeepFace",
        "image": null,
        "date": "2014"
    },
    {
        "relevant_people": [
            "Ian J. Goodfellow",
            "Jean Pouget-Abadie",
            "Mehdi Mirza",
            "Bing Xu",
            "David Warde-Farley",
            "Sherjil Ozair",
            "Aaron Courville",
            "Yoshua Bengio"
        ],
        "description": "The [**Generative Adversarial Network (GAN)**](https://en.wikipedia.org/wiki/Generative_adversarial_network) is a class of machine learning frameworks designed to generate new, previously unseen data samples by training two neural networks simultaneously. They were introduced by [Ian J. Goodfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow) and his team in 2014. GANs consist of a generator network that creates synthetic data samples, and a discriminator network that evaluates the authenticity of the generated samples. The two networks are trained together in a process that resembles a two-player [minimax game](https://en.wikipedia.org/wiki/Minimax), where the generator tries to produce realistic samples to fool the discriminator, and the discriminator tries to correctly identify whether a given sample is real or generated. GANs have since become a popular approach in various fields, including image synthesis, style transfer, and data augmentation.",
        "related_topics": [
            "Deep Learning",
            "Neural Networks",
            "Machine Learning",
            "Image Synthesis",
            "Style Transfer"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1406.2661"
        ],
        "papers": [
            {
                "title": "Generative Adversarial Networks",
                "url": "https://arxiv.org/abs/1406.2661",
                "authors": [
                    "Ian J. Goodfellow",
                    "Jean Pouget-Abadie",
                    "Mehdi Mirza",
                    "Bing Xu",
                    "David Warde-Farley",
                    "Sherjil Ozair",
                    "Aaron Courville",
                    "Yoshua Bengio"
                ],
                "date": "2014",
                "abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
                "url_pdf": "https://arxiv.org/pdf/1406.2661.pdf",
                "num_citations": "Citations: 25,000+ (Google Scholar)",
                "publisher": "arXiv",
                "pub_type": "article"
            }
        ],
        "title": "Generative Adversarial Network (GAN)",
        "wiki_url": "https://en.wikipedia.org/wiki/Generative_adversarial_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/2/2f/A_Recent_Entrance_to_Paradise.jpg",
        "date": "2014"
    },
    {
        "relevant_people": [
            "Kaiming He",
            "Xiangyu Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "description": "The [**Residual Neural Network**](https://en.wikipedia.org/wiki/Residual_neural_network) (ResNet) is a deep learning architecture introduced in 2015 by [Kaiming He](https://scholar.google.com/citations?user=1vS8V5wAAAAJ), [Xiangyu Zhang](https://scholar.google.com/citations?user=7C0fLh0AAAAJ), [Shaoqing Ren](https://scholar.google.com/citations?user=1CZt2TgAAAAJ), and [Jian Sun](https://scholar.google.com/citations?user=1E8X0kAAAAAJ). ResNet was designed to address the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) and improve the performance of deep neural networks in image recognition tasks. ResNet introduces residual connections, also known as skip connections, which allow the network to learn residual functions and enable the training of much deeper networks.",
        "related_topics": [
            "Deep Learning",
            "Convolutional Neural Networks",
            "Image Recognition",
            "Vanishing Gradient Problem",
            "Skip Connections"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1512.03385",
            "https://en.wikipedia.org/wiki/Residual_neural_network",
            "https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4",
            "https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624",
            "https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html"
        ],
        "papers": [
            {
                "title": "Deep Residual Learning for Image Recognition",
                "url": "https://arxiv.org/abs/1512.03385",
                "authors": [
                    "Kaiming He",
                    "Xiangyu Zhang",
                    "Shaoqing Ren",
                    "Jian Sun"
                ],
                "proceeding": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "date": "2015",
                "abstract": "In this paper, we propose a deep residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth.",
                "url_pdf": "https://arxiv.org/pdf/1512.03385.pdf",
                "num_citations": 69575,
                "publisher": "IEEE",
                "pages": "770-778",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "Residual Neural Network",
        "wiki_url": "https://en.wikipedia.org/wiki/Residual_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/5/5f/ResNets.svg",
        "date": "2015"
    },
    {
        "date": "October 2015",
        "relevant_people": [],
        "description": "AlphaGo Fan, developed by DeepMind Technologies, was an early version of the AlphaGo AI program that played the ancient Chinese board game of Go. It utilized deep learning techniques and 176 GPUs distributed across multiple machines. In October 2015, it achieved an ELO rating of 3,144, and went on to defeat European Go champion Fan Hui with a score of 5:0, marking the first time an AI program had defeated a professional Go player without any handicaps.",
        "related_topics": [
            "AlphaGo",
            "DeepMind Technologies",
            "Artificial Intelligence",
            "Deep Learning",
            "Board Games"
        ],
        "relevant_links": [
            "https://deepmind.com/research/case-studies/alphago-the-story-so-far",
            "https://www.nature.com/articles/nature16961",
            "https://www.youtube.com/watch?v=SUbqykXVx0A"
        ],
        "papers": [
            {
                "title": "Mastering the game of Go with deep neural networks and tree search",
                "url": "https://www.nature.com/articles/nature16961",
                "authors": [
                    "Silver, David",
                    "Huang, Aja",
                    "Maddison, Chris J.",
                    "Guez, Arthur",
                    "Sifre, Laurent",
                    "Driessche, George van den",
                    "Schrittwieser, Julian",
                    "Antonoglou, Ioannis",
                    "Panneershelvam, Veda",
                    "Lanctot, Marc",
                    "Dieleman, Sander",
                    "Grewe, Dominik",
                    "Nham, John",
                    "Kalchbrenner, Nal",
                    "Sutskever, Ilya",
                    "Lillicrap, Timothy",
                    "Leach, Madeleine",
                    "Kavukcuoglu, Koray",
                    "Graepel, Thore",
                    "Hassabis, Demis"
                ],
                "proceeding": "Nature",
                "date": "2016",
                "abstract": "The game of Go has long been viewed as the most challenging of classic games for artificial intelligence due to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses value networks to evaluate board positions and policy networks to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.",
                "url_pdf": "https://www.nature.com/articles/nature16961.epdf?referrer_access_token=8oxIc0Twz6nDy2IbSc_5_tRgN0jAjWel9jnR3ZoTv0Nj6USSKDeHj4Dja0K5b2W5ZgqRl34K5b9vLcD8p8A3MhK3I3ZvpxxM1eBgZKc0yG-9Z6Cg5WifJyA5XlQyA9rRlE8BGhJ3L5fX9N9J6z7u_0iY0Yw5g%3D%3D&tracking_referrer=www.bbc.com",
                "num_citations": 4638,
                "publisher": "Nature Publishing Group",
                "pages": "484-489",
                "volume": "529",
                "journal": "Nature",
                "pub_type": "article"
            }
        ],
        "title": "AlphaGo Fan",
        "wiki_url": "https://en.wikipedia.org/wiki/AlphaGo",
        "image": "https://upload.wikimedia.org/wikipedia/commons/0/0b/Alphago_logo_Reversed.svg"
    },
    {
        "date": "March 2016",
        "hardware": "48 TPUs, distributed",
        "ELO_rating": "3,739",
        "match_result": "4:1 against Lee Sedol",
        "description": "The [**AlphaGo Lee**](https://en.wikipedia.org/wiki/AlphaGo) version was developed by [DeepMind Technologies](https://en.wikipedia.org/wiki/DeepMind), a British artificial intelligence company acquired by Google in 2014. AlphaGo Lee played the board game Go and, in March 2016, defeated [Lee Sedol](https://en.wikipedia.org/wiki/Lee_Sedol), a 9-dan professional Go player, in a five-game match with a score of 4-1. This victory marked a significant milestone in the field of artificial intelligence, as Go was considered a challenging game for AI due to its complexity and large number of possible moves. AlphaGo Lee utilized 48 [Tensor Processing Units (TPUs)](https://en.wikipedia.org/wiki/Tensor_processing_unit) in a distributed system to perform deep learning and tree search algorithms, achieving an ELO rating of 3,739.",
        "related_topics": [
            "DeepMind",
            "Artificial Intelligence",
            "Go",
            "Lee Sedol",
            "AlphaGo",
            "Deep Learning",
            "Monte Carlo Tree Search"
        ],
        "relevant_links": [
            "https://deepmind.com/research/case-studies/alphago-the-story-so-far",
            "https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol",
            "https://www.nature.com/articles/nature16961",
            "https://www.youtube.com/watch?v=vFr3K2DORc8",
            "https://www.nytimes.com/2016/03/10/world/asia/lee-sedol-alphago-google-deepmind-go.html"
        ],
        "papers": [
            {
                "title": "Mastering the game of Go with deep neural networks and tree search",
                "url": "https://www.nature.com/articles/nature16961",
                "authors": [
                    "Silver, David",
                    "Huang, Aja",
                    "Maddison, Chris J.",
                    "Guez, Arthur",
                    "Sifre, Laurent",
                    "Driessche, George van den",
                    "Schrittwieser, Julian",
                    "Antonoglou, Ioannis",
                    "Panneershelvam, Veda",
                    "Lanctot, Marc",
                    "Dieleman, Sander",
                    "Grewe, Dominik",
                    "Nham, John",
                    "Kalchbrenner, Nal",
                    "Sutskever, Ilya",
                    "Lillicrap, Timothy",
                    "Leach, Madeleine",
                    "Kavukcuoglu, Koray",
                    "Graepel, Thore",
                    "Hassabis, Demis"
                ],
                "proceeding": "Nature",
                "date": "2016",
                "abstract": "The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses value networks to evaluate board positions and policy networks to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.",
                "url_pdf": "https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf",
                "num_citations": 6304,
                "publisher": "Nature Publishing Group",
                "pages": "484-489",
                "volume": "529",
                "journal": "Nature",
                "pub_type": "article"
            }
        ],
        "title": "AlphaGo Lee",
        "wiki_url": "https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol",
        "image": "https://upload.wikimedia.org/wikipedia/commons/0/0b/Alphago_logo_Reversed.svg"
    },
    {
        "date": "May 2017",
        "hardware": {
            "type": "TPUs",
            "quantity": 4,
            "configuration": "single machine"
        },
        "games_played": 4858,
        "record": {
            "wins": 60,
            "losses": 0,
            "against_professional_players": true
        },
        "description": "The [**AlphaGo Master**](https://en.wikipedia.org/wiki/AlphaGo) is a version of the AlphaGo AI developed by [DeepMind Technologies](https://en.wikipedia.org/wiki/DeepMind), a subsidiary of Alphabet Inc. In May 2017, AlphaGo Master played a series of online games against professional Go players under the pseudonym 'Master'. It demonstrated an exceptional performance by winning 60 games and losing none. The AI used a single machine equipped with 4 [Tensor Processing Units (TPUs)](https://en.wikipedia.org/wiki/Tensor_processing_unit) to achieve this remarkable feat.",
        "related_topics": [
            "AlphaGo",
            "DeepMind",
            "Artificial Intelligence",
            "Go (game)",
            "Deep Learning"
        ],
        "relevant_links": [
            "https://deepmind.com/research/case-studies/alphago-the-story-so-far",
            "https://en.wikipedia.org/wiki/AlphaGo",
            "https://www.youtube.com/watch?v=WXuK6gekU1Y"
        ],
        "papers": [
            {
                "title": "Mastering the game of Go with deep neural networks and tree search",
                "url": "https://www.nature.com/articles/nature16961",
                "authors": [
                    "Silver, David",
                    "Huang, Aja",
                    "Maddison, Chris J.",
                    "Guez, Arthur",
                    "Sifre, Laurent",
                    "Van Den Driessche, George",
                    "Schrittwieser, Julian",
                    "Antonoglou, Ioannis",
                    "Panneershelvam, Veda",
                    "Lanctot, Marc",
                    "Dieleman, Sander",
                    "Grewe, Dominik",
                    "Nham, John",
                    "Kalchbrenner, Nal",
                    "Sutskever, Ilya",
                    "Lillicrap, Timothy",
                    "Leach, Madeleine",
                    "Kavukcuoglu, Koray",
                    "Graepel, Thore",
                    "Hassabis, Demis"
                ],
                "proceeding": "Nature",
                "date": "2016",
                "abstract": "The game of Go has long been viewed as the most challenging of classic games for artificial intelligence due to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses value networks to evaluate board positions and policy networks to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.",
                "url_pdf": "https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf",
                "num_citations": 3736,
                "publisher": "Nature Publishing Group",
                "pages": "484--489",
                "volume": "529",
                "journal": "Nature",
                "pub_type": "article"
            }
        ],
        "title": "AlphaGo Master",
        "wiki_url": "https://en.wikipedia.org/wiki/AlphaGo",
        "image": "https://upload.wikimedia.org/wikipedia/commons/0/0b/Alphago_logo_Reversed.svg"
    },
    {
        "date": "October 2017",
        "hardware": {
            "TPUs": 4,
            "machine_type": "single machine"
        },
        "number_of_games_played": 5185,
        "match_results": [
            {
                "opponent": "AlphaGo Lee",
                "score": "100:0"
            },
            {
                "opponent": "AlphaGo Master",
                "score": "89:11"
            }
        ],
        "model": {
            "architecture": "40 block"
        },
        "description": "AlphaGo Zero, developed by [DeepMind](https://deepmind.com/), is a version of the [AlphaGo AI program](https://deepmind.com/research/case-studies/alphago-the-story-so-far) that achieved a major milestone in the field of artificial intelligence by mastering the complex board game [Go](https://en.wikipedia.org/wiki/Go_(game)) without any human input. In October 2017, AlphaGo Zero demonstrated its prowess by playing 5,185 games and defeating previous versions of AlphaGo, including AlphaGo Lee with a score of 100:0, and AlphaGo Master with a score of 89:11. The model used a 40-block architecture and was powered by 4 TPUs on a single machine.",
        "related_topics": [
            "DeepMind",
            "Artificial Intelligence",
            "Reinforcement Learning",
            "Neural Networks",
            "Game of Go"
        ],
        "relevant_links": [
            "https://deepmind.com/blog/article/alphago-zero-starting-scratch",
            "https://www.nature.com/articles/nature24270",
            "https://www.youtube.com/watch?v=WXuK6gekU1Y"
        ],
        "papers": [
            {
                "title": "Mastering the game of Go without human knowledge",
                "url": "https://www.nature.com/articles/nature24270",
                "authors": [
                    "David Silver",
                    "Julian Schrittwieser",
                    "Karen Simonyan",
                    "Ioannis Antonoglou",
                    "Aja Huang",
                    "Arthur Guez",
                    "Thomas Hubert",
                    "Lucas Baker",
                    "Matthew Lai",
                    "Adrian Bolton",
                    "Yutian Chen",
                    "Timothy Lillicrap",
                    "Fan Hui",
                    "Laurent Sifre",
                    "George van den Driessche",
                    "Thore Graepel",
                    "Demis Hassabis"
                ],
                "journal": "Nature",
                "date": "2017",
                "abstract": "A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo.",
                "url_pdf": "https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf",
                "num_citations": 5185,
                "publisher": "Nature Publishing Group",
                "pages": "484-489",
                "volume": "550",
                "issue": "7676",
                "pub_type": "article"
            }
        ],
        "title": "AlphaGo Zero",
        "wiki_url": "https://en.wikipedia.org/wiki/AlphaGo_Zero",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg"
    },
    {
        "date": "October 2017",
        "relevant_people": [],
        "description": "AlphaZero is a [computer program](https://en.wikipedia.org/wiki/AlphaZero) developed by [DeepMind Technologies](https://en.wikipedia.org/wiki/DeepMind) that uses [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) to master the games of [chess](https://en.wikipedia.org/wiki/Chess), [shogi](https://en.wikipedia.org/wiki/Shogi), and [Go](https://en.wikipedia.org/wiki/Go_(game)). In October 2017, AlphaZero demonstrated its capabilities by defeating the previous state-of-the-art AI, [AlphaGo Zero](https://en.wikipedia.org/wiki/AlphaGo_Zero), in a 100-game match with a score of 60:40. AlphaZero utilized 4 [Tensor Processing Units (TPUs)](https://en.wikipedia.org/wiki/Tensor_processing_unit) on a single machine and was able to achieve remarkable results in just a few hours of training.",
        "related_topics": [
            "DeepMind",
            "Artificial intelligence",
            "Reinforcement learning",
            "Monte Carlo Tree Search",
            "Game-playing AI"
        ],
        "relevant_links": [
            "https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go",
            "https://en.wikipedia.org/wiki/AlphaZero",
            "https://www.nature.com/articles/nature24270"
        ],
        "papers": [
            {
                "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm",
                "url": "https://arxiv.org/abs/1712.01815",
                "authors": [
                    "David Silver",
                    "Thomas Hubert",
                    "Julian Schrittwieser",
                    "Ioannis Antonoglou",
                    "Matthew Lai",
                    "Arthur Guez",
                    "Marc Lanctot",
                    "Laurent Sifre",
                    "Dharshan Kumaran",
                    "Thore Graepel",
                    "Timothy Lillicrap",
                    "Karen Simonyan",
                    "Demis Hassabis"
                ],
                "proceeding": "arXiv preprint",
                "date": "2017",
                "abstract": "The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. In contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains. Starting from random play, and given no domain knowledge except the game rules, AlphaZero achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.",
                "url_pdf": "https://arxiv.org/pdf/1712.01815.pdf",
                "num_citations": 5018,
                "publisher": "arXiv",
                "pages": "",
                "volume": "",
                "journal": "",
                "pub_type": "preprint"
            }
        ],
        "title": "AlphaZero",
        "wiki_url": "https://en.wikipedia.org/wiki/AlphaZero",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg"
    },
    {
        "relevant_people": [
            "Geoffrey E. Hinton",
            "Nicholas Frosst",
            "Sara Sabour"
        ],
        "description": "The [**Capsule Neural Network (CapsNet)**](https://en.wikipedia.org/wiki/Capsule_neural_network) is a type of artificial neural network introduced by [Geoffrey E. Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton), [Sara Sabour](https://scholar.google.com/citations?user=6s4xg_IAAAAJ&hl=en), and [Nicholas Frosst](https://scholar.google.com/citations?user=N3qUw0QAAAAJ&hl=en) in 2017. CapsNets aim to address some limitations of traditional [convolutional neural networks (CNNs)](https://en.wikipedia.org/wiki/Convolutional_neural_network) by using capsules, which are groups of neurons that represent different properties of an object. The key innovation in CapsNets is the [dynamic routing mechanism](https://arxiv.org/abs/1710.09829) between capsules, which allows the network to learn hierarchical relationships between object parts and their wholes. This results in improved performance in tasks such as object recognition and segmentation, as well as increased robustness to variations in input data.",
        "related_topics": [
            "Convolutional Neural Networks",
            "Deep Learning",
            "Object Recognition",
            "Computer Vision",
            "Neural Networks"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1710.09829",
            "https://en.wikipedia.org/wiki/Capsule_neural_network",
            "https://www.youtube.com/watch?v=pPN8d0E3900",
            "https://www.cs.toronto.edu/~hinton/",
            "https://scholar.google.com/citations?user=6s4xg_IAAAAJ&hl=en",
            "https://scholar.google.com/citations?user=N3qUw0QAAAAJ&hl=en"
        ],
        "papers": [
            {
                "title": "Dynamic Routing Between Capsules",
                "url": "https://arxiv.org/abs/1710.09829",
                "authors": [
                    "Sara Sabour",
                    "Nicholas Frosst",
                    "Geoffrey E. Hinton"
                ],
                "date": "2017",
                "abstract": "A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discriminatively trained, multi-layer capsule system achieves state-of-the-art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits.",
                "url_pdf": "https://arxiv.org/pdf/1710.09829.pdf",
                "num_citations": 3147,
                "pub_type": "article"
            }
        ],
        "title": "Capsule Neural Network (CapsNet)",
        "wiki_url": "https://en.wikipedia.org/wiki/Capsule_neural_network",
        "image": null,
        "date": "2017"
    },
    {
        "relevant_people": [
            "Ashish Vaswani",
            "Noam Shazeer",
            "Niki Parmar",
            "Jakob Uszkoreit",
            "Llion Jones",
            "Aidan N. Gomez",
            "Lukasz Kaiser",
            "Illia Polosukhin"
        ],
        "description": "The [**Transformer**](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) is a novel deep learning architecture introduced in the paper '[Attention Is All You Need](https://arxiv.org/abs/1706.03762)' by Vaswani et al. in 2017. It is based on the [self-attention](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html) mechanism and has significantly improved the state of the art in a variety of natural language processing tasks, including machine translation, language modeling, and sentiment analysis. The Transformer model has become the foundation for many subsequent models, such as [BERT](https://arxiv.org/abs/1810.04805), [GPT](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf), and [T5](https://arxiv.org/abs/1910.10683), and has had a profound impact on the field of AI and deep learning.",
        "related_topics": [
            "Deep learning",
            "Natural language processing",
            "Self-attention",
            "BERT",
            "GPT",
            "T5"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1706.03762",
            "https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html",
            "https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)",
            "https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html"
        ],
        "papers": [
            {
                "title": "Attention Is All You Need",
                "url": "https://arxiv.org/abs/1706.03762",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan N. Gomez",
                    "Lukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "proceeding": "31st Conference on Neural Information Processing Systems (NIPS 2017)",
                "date": "2017",
                "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.",
                "url_pdf": "https://arxiv.org/pdf/1706.03762.pdf",
                "num_citations": 24446,
                "publisher": "Neural Information Processing Systems",
                "pages": "5998--6008",
                "volume": "",
                "journal": "",
                "pub_type": "conference"
            }
        ],
        "title": "Transformer",
        "wiki_url": "https://en.wikipedia.org/wiki/Transformer",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/e2/Abspannportal.jpg",
        "date": "2017"
    },
    {
        "relevant_people": [
            "Petar Veli\u010dkovi\u0107",
            "Guillem Cucurull",
            "Arantxa Casanova",
            "Adriana Romero",
            "Pietro Li\u00f2",
            "Yoshua Bengio"
        ],
        "description": "The [**Graph Attention Networks**](https://arxiv.org/abs/1806.01261) (GAT) is a novel neural network architecture that operates on graph-structured data. It was introduced in 2017 by [Petar Veli\u010dkovi\u0107](https://scholar.google.com/citations?user=9AQKkWYAAAAJ&hl=en), [Guillem Cucurull](https://scholar.google.com/citations?user=6Q5I6HcAAAAJ&hl=en), [Arantxa Casanova](https://scholar.google.com/citations?user=9x1F3qUAAAAJ&hl=en), [Adriana Romero](https://scholar.google.com/citations?user=0b4e4I4AAAAJ&hl=en), [Pietro Li\u00f2](https://scholar.google.com/citations?user=9gKoC0AAAAAJ&hl=en), and [Yoshua Bengio](https://scholar.google.com/citations?user=m9X9zccAAAAJ&hl=en). GAT employs attention mechanisms to compute the hidden representations of nodes in the graph, enabling it to capture complex relationships between nodes and perform well on various graph-based tasks.",
        "related_topics": [
            "Graph Neural Networks",
            "Deep Learning",
            "Attention Mechanisms",
            "Graph-structured data"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1806.01261"
        ],
        "papers": [
            {
                "title": "Graph Attention Networks",
                "url": "https://arxiv.org/abs/1806.01261",
                "authors": [
                    "Petar Veli\u010dkovi\u0107",
                    "Guillem Cucurull",
                    "Arantxa Casanova",
                    "Adriana Romero",
                    "Pietro Li\u00f2",
                    "Yoshua Bengio"
                ],
                "proceeding": "Proceedings of the 5th International Conference on Learning Representations (ICLR 2017)",
                "date": "2017",
                "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems.",
                "url_pdf": "https://arxiv.org/pdf/1806.01261.pdf",
                "num_citations": "N/A",
                "publisher": "ICLR",
                "pages": "N/A",
                "volume": "N/A",
                "journal": "N/A",
                "pub_type": "conference"
            }
        ],
        "title": "Graph Attention Networks",
        "wiki_url": "https://en.wikipedia.org/wiki/Graph_neural_network",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1e/GNN_building_blocks.png",
        "date": "2017"
    },
    {
        "relevant_organization": [
            "OpenAI"
        ],
        "description": "The [**GPT**](https://en.wikipedia.org/wiki/OpenAI#GPT-3) (Generative Pre-trained Transformers) is a series of natural language processing models developed by [OpenAI](https://en.wikipedia.org/wiki/OpenAI), with the first version released in 2018. GPT models are designed to improve language understanding by leveraging unsupervised learning through pre-training on large amounts of text data. The models are then fine-tuned for specific tasks such as translation, summarization, and question-answering.",
        "related_topics": [
            "Natural Language Processing",
            "Deep Learning",
            "Machine Learning",
            "Transformer Models",
            "BERT"
        ],
        "relevant_links": [
            "https://openai.com/blog/language-unsupervised/",
            "https://arxiv.org/abs/1801.10198",
            "https://github.com/openai/finetune-transformer-lm"
        ],
        "papers": [
            {
                "title": "Improving Language Understanding by Generative Pre-Training",
                "url": "https://arxiv.org/abs/1801.10198",
                "authors": [
                    "Alec Radford",
                    "Karthik Narasimhan",
                    "Tim Salimans",
                    "Ilya Sutskever"
                ],
                "proceeding": "arXiv preprint",
                "date": "2018",
                "abstract": "We present an unsupervised approach to improve the fine-tuning of generative pre-trained transformer models for various natural language understanding tasks. The approach leverages unsupervised pre-training on a large corpus of text data and fine-tuning on a smaller labeled dataset.",
                "url_pdf": "https://arxiv.org/pdf/1801.10198.pdf",
                "num_citations": "N/A",
                "publisher": "arXiv",
                "pages": "N/A",
                "volume": "N/A",
                "journal": "N/A",
                "pub_type": "preprint"
            }
        ],
        "title": "Generative Pre-trained Transformers (GPT)",
        "wiki_url": "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer",
        "image": "https://upload.wikimedia.org/wikipedia/commons/9/91/Full_GPT_architecture.png",
        "date": "2018"
    },
    {
        "relevant_people": [
            "DeepMind"
        ],
        "description": "The [**AlphaFold**](https://deepmind.com/research/case-studies/alphafold) project by [DeepMind](https://deepmind.com) is an AI system designed to predict protein structures with high accuracy. In December 2018, AlphaFold 1 achieved a major milestone by placing first in the overall rankings of the 13th [Critical Assessment of Techniques for Protein Structure Prediction (CASP)](https://predictioncenter.org/casp13/index.cgi). This achievement showcased the potential of deep learning and artificial intelligence in solving complex biological problems and marked a significant breakthrough in the field of protein structure prediction.",
        "related_topics": [
            "DeepMind",
            "Protein Structure Prediction",
            "CASP",
            "Deep Learning",
            "Artificial Intelligence"
        ],
        "relevant_links": [
            "https://deepmind.com/blog/article/alphafold-casp13",
            "https://predictioncenter.org/casp13/index.cgi",
            "https://deepmind.com/research/case-studies/alphafold",
            "https://en.wikipedia.org/wiki/AlphaFold"
        ],
        "papers": [
            {
                "title": "Improved protein structure prediction using potentials from deep learning",
                "url": "https://www.nature.com/articles/s41586-019-1923-7",
                "authors": [
                    "Senior, Andrew W.",
                    "Evans, Richard",
                    "Jumper, John",
                    "Kirkpatrick, Jeff",
                    "Sifre, Laurent",
                    "Green, Tim",
                    "Qin, Chongli",
                    "\u017d\u00eddek, Augustin",
                    "Nelson, Alexander W. R.",
                    "Bridgland, Alex",
                    "Penedones, Hugo",
                    "Petersen, Stig",
                    "Simonyan, Karen",
                    "Crossan, Sean",
                    "Kohli, Pushmeet",
                    "Jones, David T.",
                    "Silver, David",
                    "Kavukcuoglu, Koray",
                    "Hassabis, Demis"
                ],
                "proceeding": "Nature",
                "date": "2020",
                "abstract": "Protein structure prediction can be used to determine the three-dimensional shape of a protein from its amino acid sequence. This problem is of fundamental importance as the structure of a protein largely determines its function; however, protein structures can be difficult to determine experimentally. Here we present a potential of mean force (PMF) that is trained using deep learning techniques to predict protein structures. We show that our PMF can improve the state-of-the-art in protein structure prediction.",
                "url_pdf": "https://www.nature.com/articles/s41586-019-1923-7.epdf",
                "num_citations": 1544,
                "publisher": "Nature Publishing Group",
                "pages": "106-111",
                "volume": "577",
                "journal": "Nature",
                "pub_type": "article"
            }
        ],
        "title": "AlphaFold",
        "wiki_url": "https://en.wikipedia.org/wiki/AlphaFold",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg",
        "date": "2018"
    },
    {
        "relevant_people": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "organization": "Google",
        "description": "The [**BERT**](https://en.wikipedia.org/wiki/BERT_(language_model)) (Bidirectional Encoder Representations from Transformers) is a pre-trained natural language processing model developed by [Google](https://en.wikipedia.org/wiki/Google). BERT revolutionized the NLP field by introducing the bidirectional training of transformers, which allows the model to better understand the context of words within a sentence. As a result, BERT enables anyone to train their own state-of-the-art question-answering system and has been widely adopted for various NLP tasks.",
        "related_topics": [
            "Natural Language Processing",
            "Deep Learning",
            "Transformers",
            "Language Models",
            "Machine Learning"
        ],
        "relevant_links": [
            "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html",
            "https://github.com/google-research/bert",
            "https://arxiv.org/abs/1810.04805",
            "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270",
            "https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/"
        ],
        "papers": [
            {
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
                "url": "https://arxiv.org/abs/1810.04805",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "date": "2018",
                "abstract": "BERT (Bidirectional Encoder Representations from Transformers) is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks.",
                "url_pdf": "https://arxiv.org/pdf/1810.04805.pdf",
                "num_citations": "16,000+",
                "publisher": "arXiv",
                "pub_type": "preprint"
            }
        ],
        "title": "Bidirectional Encoder Representations from Transformers (BERT)",
        "wiki_url": "https://en.wikipedia.org/wiki/BERT_(language_model)",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/41/Global_thinking.svg",
        "date": "2018"
    },
    {
        "relevant_people": [],
        "description": "The [**EfficientNet-B7**](https://arxiv.org/abs/1905.11946) is a state-of-the-art (SOTA) deep learning model for image classification, which achieved 84.4% accuracy on the [ImageNet](https://www.image-net.org/) dataset. The model is based on the [EfficientNet](https://arxiv.org/abs/1905.11946) architecture, introduced by researchers from Google AI in 2019. EfficientNet-B7 is the largest and most accurate model in the EfficientNet family, and it is known for its efficiency in terms of both computational resources and model size.",
        "related_topics": [
            "Deep Learning",
            "Convolutional Neural Networks",
            "Image Classification",
            "EfficientNet",
            "Google AI"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/1905.11946",
            "https://www.image-net.org/",
            "https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html"
        ],
        "papers": [
            {
                "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks",
                "url": "https://arxiv.org/abs/1905.11946",
                "authors": [
                    "Mingxing Tan",
                    "Quoc V. Le"
                ],
                "proceeding": "arXiv preprint",
                "date": "2019",
                "abstract": "In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet.",
                "url_pdf": "https://arxiv.org/pdf/1905.11946.pdf",
                "num_citations": 0,
                "publisher": "arXiv",
                "pages": "",
                "volume": "",
                "journal": "",
                "pub_type": "preprint"
            }
        ],
        "title": "EfficientNet-B7",
        "wiki_url": "https://en.wikipedia.org/wiki/.NET_Framework_version_history",
        "image": "https://upload.wikimedia.org/wikipedia/commons/5/55/Dot-Net_1_SVG.svg",
        "date": "2019"
    },
    {
        "organization": "OpenAI",
        "description": "The [**GPT-3**](https://en.wikipedia.org/wiki/GPT-3) (Generative Pre-trained Transformer 3) is a state-of-the-art language model developed by [OpenAI](https://en.wikipedia.org/wiki/OpenAI). It is based on the [transformer architecture](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) and uses unsupervised learning for text generation. GPT-3 is the largest and most powerful version of the GPT series, with 175 billion parameters. It can generate human-like text and perform various natural language processing tasks, such as translation, summarization, and question-answering.",
        "related_topics": [
            "GPT-2",
            "BERT",
            "Natural Language Processing",
            "Deep Learning",
            "Transformer Models"
        ],
        "relevant_links": [
            "https://openai.com/blog/openai-api/",
            "https://arxiv.org/abs/2005.14165",
            "https://github.com/openai/gpt-3",
            "https://en.wikipedia.org/wiki/GPT-3"
        ],
        "papers": [
            {
                "title": "Language Models are Few-Shot Learners",
                "url": "https://arxiv.org/abs/2005.14165",
                "authors": [
                    "Tom B. Brown",
                    "Benjamin Mann",
                    "Nick Ryder",
                    "Melanie Subbiah",
                    "Jared Kaplan",
                    "Prafulla Dhariwal",
                    "Arvind Neelakantan",
                    "Pranav Shyam",
                    "Girish Sastry",
                    "Amanda Askell",
                    "Sandhini Agarwal",
                    "Ariel Herbert-Voss",
                    "Gretchen Krueger",
                    "Tom Henighan",
                    "Rewon Child",
                    "Aditya Ramesh",
                    "Daniel M. Ziegler",
                    "Jeffrey Wu",
                    "Clemens Winter",
                    "Christopher Hesse",
                    "Mark Chen",
                    "Eric Sigler",
                    "Mateusz Litwin",
                    "Scott Gray",
                    "Benjamin Chess",
                    "Jack Clark",
                    "Christopher Berner",
                    "Sam McCandlish",
                    "Alec Radford",
                    "Ilya Sutskever",
                    "Dario Amodei"
                ],
                "proceeding": "arXiv preprint",
                "date": "2020",
                "abstract": "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.",
                "url_pdf": "https://arxiv.org/pdf/2005.14165.pdf",
                "num_citations": 4893,
                "publisher": "arXiv",
                "pub_type": "preprint"
            }
        ],
        "title": "GPT-3",
        "wiki_url": "https://en.wikipedia.org/wiki/GPT-3",
        "image": null,
        "date": "2020"
    },
    {
        "relevant_people": [
            "DeepMind"
        ],
        "description": "The [**AlphaFold 2**](https://deepmind.com/research/publications/AlphaFold-2) system, developed by [DeepMind](https://deepmind.com/), is designed to predict protein structures with remarkable accuracy. In November 2020, a team using AlphaFold 2 achieved unprecedented success in the [Critical Assessment of protein Structure Prediction (CASP)](https://predictioncenter.org/) competition. The system scored above 90 for approximately two-thirds of the proteins in CASP's [Global Distance Test (GDT)](https://en.wikipedia.org/wiki/Global_distance_test), a metric that evaluates the similarity between a computationally predicted structure and the experimentally determined structure, with 100 being a perfect match.",
        "related_topics": [
            "Protein structure prediction",
            "Deep learning",
            "Artificial intelligence",
            "Computational biology",
            "DeepMind"
        ],
        "relevant_links": [
            "https://deepmind.com/research/publications/AlphaFold-2",
            "https://predictioncenter.org/",
            "https://www.nature.com/articles/d41586-021-03361-1",
            "https://www.nature.com/articles/s41586-021-03819-2"
        ],
        "papers": [
            {
                "title": "Highly accurate protein structure prediction for the human proteome",
                "url": "https://www.nature.com/articles/s41586-021-03828-1",
                "authors": [
                    "Jumper, John",
                    "Evans, Richard",
                    "Pritzel, Alexander",
                    "Green, Tim",
                    "Figurnov, Michael",
                    "Ronneberger, Olaf",
                    "Tunyasuvunakool, Kathryn",
                    "Bates, Russ",
                    "Zidek, Augustin",
                    "Potapenko, Anna",
                    "Bridgland, Alex",
                    "Meyer, Clemens",
                    "Koh, Lucy",
                    "Kavukcuoglu, Koray",
                    "Hassabis, Demis",
                    "Schroeder, Tim",
                    "Ross, Christopher",
                    "Mulholland, Andrew J.",
                    "Sessler, Eric",
                    "Welling, Max",
                    "Rifai, Sara",
                    "Poole, Ben",
                    "Petersen, Stig",
                    "Simonyan, Karen",
                    "Crossan, Sean",
                    "Kohli, Pushmeet",
                    "Jones, David T.",
                    "Silver, David",
                    "Kaelbling, Leslie P.",
                    "Lozano-Perez, Tomas",
                    "Zemel, Richard",
                    "Testa, Carlos",
                    "Bengio, Yoshua",
                    "Yamins, Dan",
                    "Hinton, Geoffrey E.",
                    "Sheridan, Paul",
                    "Parr, Thomas",
                    "Leibo, Joel Z.",
                    "Levine, Sergey",
                    "Wayne, Greg",
                    "Mnih, Volodymyr",
                    "Graves, Alex",
                    "Riedmiller, Martin",
                    "Lillicrap, Timothy P.",
                    "Kording, Konrad P.",
                    "Botvinick, Matthew",
                    "Vinyals, Oriol",
                    "Osindero, Steve",
                    "Wang, Jane",
                    "Chen, Bowen",
                    "Weber, Theophane",
                    "Lomonaco, Vincenzo",
                    "Rezende, Danilo",
                    "Lockhart, Edward",
                    "Stones, David",
                    "Csordas, Attila",
                    "Flaxman, Seth",
                    "Kavukcuoglu, Koray",
                    "Hassabis, Demis",
                    "Schroeder, Tim",
                    "Ross, Christopher",
                    "Mulholland, Andrew J.",
                    "Sessler, Eric",
                    "Welling, Max",
                    "Rifai, Sara",
                    "Poole, Ben",
                    "Petersen, Stig",
                    "Simonyan, Karen",
                    "Crossan, Sean",
                    "Kohli, Pushmeet",
                    "Jones, David T.",
                    "Silver, David",
                    "Kaelbling, Leslie P.",
                    "Lozano-Perez, Tomas",
                    "Zemel, Richard",
                    "Testa, Carlos",
                    "Bengio, Yoshua",
                    "Yamins, Dan",
                    "Hinton, Geoffrey E.",
                    "Sheridan, Paul",
                    "Parr, Thomas",
                    "Leibo, Joel Z.",
                    "Levine, Sergey",
                    "Wayne, Greg",
                    "Mnih, Volodymyr",
                    "Graves, Alex",
                    "Riedmiller, Martin",
                    "Lillicrap, Timothy P.",
                    "Kording, Konrad P.",
                    "Botvinick, Matthew",
                    "Vinyals, Oriol",
                    "Osindero, Steve",
                    "Wang, Jane",
                    "Chen, Bowen",
                    "Weber, Theophane",
                    "Lomonaco, Vincenzo",
                    "Rezende, Danilo",
                    "Lockhart, Edward",
                    "Stones, David",
                    "Csordas, Attila",
                    "Flaxman, Seth"
                ],
                "proceeding": "Nature",
                "date": "2021",
                "abstract": "The AlphaFold2 model is applied to predict the structure of the human proteome, and the structures are made available in a public database. The model is also used to predict the structures of 20 other organisms, including mouse, zebrafish, fruit fly and Escherichia coli.",
                "url_pdf": "https://www.nature.com/articles/s41586-021-03828-1.pdf",
                "num_citations": 10,
                "publisher": "Nature Publishing Group",
                "pages": "590--596",
                "volume": "596",
                "journal": "Nature",
                "pub_type": "article"
            }
        ],
        "title": "AlphaFold 2",
        "wiki_url": "https://en.wikipedia.org/wiki/AlphaFold",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg",
        "date": "2021"
    },
    {
        "relevant_people": [
            "Vittorio Mazzia",
            "Francesco Salvetti",
            "Marcello Chiaberge"
        ],
        "description": "The [**Efficient CapsNet**](https://arxiv.org/abs/2106.00897) is a capsule network architecture that incorporates self-attention routing, improving the performance and efficiency of the original CapsNet model. It was proposed by [Vittorio Mazzia](https://scholar.google.com/citations?user=8r5W5JkAAAAJ&hl=en), [Francesco Salvetti](https://scholar.google.com/citations?user=6k36zWMAAAAJ&hl=en), and [Marcello Chiaberge](https://scholar.google.com/citations?user=0tVZjNIAAAAJ&hl=en) in their paper titled 'Efficient-CapsNet: capsule network with self-attention routing'. The architecture addresses the limitations of the original CapsNet, such as high computational complexity and slow convergence. By integrating self-attention mechanisms, the new model achieves better performance in terms of accuracy, generalization, and reduced training time.",
        "related_topics": [
            "Capsule Networks",
            "Self-Attention",
            "Deep Learning",
            "Convolutional Neural Networks"
        ],
        "relevant_links": [
            "https://arxiv.org/abs/2106.00897",
            "https://github.com/vmazzia/efficient-capsnet"
        ],
        "papers": [
            {
                "title": "Efficient-CapsNet: capsule network with self-attention routing",
                "url": "https://arxiv.org/abs/2106.00897",
                "authors": [
                    "Mazzia, Vittorio",
                    "Salvetti, Francesco",
                    "Chiaberge, Marcello"
                ],
                "date": "2021",
                "abstract": "Capsule Networks (CapsNets) are a novel deep learning architecture that aims to overcome some limitations of Convolutional Neural Networks (CNNs), such as the inability to generalize to different viewpoints. Despite their potential, CapsNets are still not widely adopted due to their high computational complexity and slow convergence. In this work, we propose a new CapsNet architecture, called Efficient-CapsNet, that integrates self-attention mechanisms in the routing algorithm. This new design allows for a more efficient routing process, reducing the number of required iterations and the overall training time. Moreover, we show that the proposed architecture achieves better performance in terms of accuracy and generalization than the original CapsNet model on several benchmark datasets.",
                "url_pdf": "https://arxiv.org/pdf/2106.00897.pdf",
                "num_citations": 0,
                "publisher": "arXiv",
                "volume": "",
                "journal": "",
                "pub_type": "preprint"
            }
        ],
        "title": "Efficient CapsNet",
        "wiki_url": "https://en.wikipedia.org/wiki/Media.net",
        "image": "https://upload.wikimedia.org/wikipedia/commons/e/e8/Crystal_Clear_app_kedit.svg",
        "date": "2021"
    },
    {
        "relevant_people": [
            "Ross Quinlan"
        ],
        "description": "The [**ID3 Algorithm**](https://en.wikipedia.org/wiki/ID3_algorithm) (Iterative Dichotomiser 3) is an algorithm used to generate decision trees. It was introduced by [Ross Quinlan](https://en.wikipedia.org/wiki/Ross_Quinlan) in 1986 as part of his inductive learning framework. The algorithm creates a multiway tree, finding the categorical feature that will maximize the information gain for each node. It is a greedy algorithm that selects the best attribute to split the dataset at each step. The ID3 algorithm is a precursor to the [C4.5](https://en.wikipedia.org/wiki/C4.5_algorithm) and [CART](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) algorithms, which are more advanced decision tree algorithms.",
        "related_topics": [
            "Machine Learning",
            "Decision Trees",
            "C4.5 Algorithm",
            "CART Algorithm",
            "Information Gain"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/ID3_algorithm",
            "https://en.wikipedia.org/wiki/Ross_Quinlan",
            "https://en.wikipedia.org/wiki/Decision_tree_learning",
            "https://en.wikipedia.org/wiki/C4.5_algorithm",
            "https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity"
        ],
        "papers": [
            {
                "title": "Induction of decision trees",
                "url": "https://doi.org/10.1016/S0169-2070(86)80084-9",
                "authors": [
                    "Quinlan, J. Ross"
                ],
                "proceeding": "Machine learning",
                "date": "1986",
                "abstract": "The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies of the factors influencing the ability of decision trees to generalize from given examples are reviewed.",
                "url_pdf": "https://hunch.net/~coms-4771/quinlan.pdf",
                "num_citations": 10456,
                "publisher": "Elsevier",
                "pages": "81-106",
                "volume": "1",
                "journal": "Machine learning",
                "pub_type": "article"
            }
        ],
        "title": "Decision Trees - ID3 Algorithm",
        "wiki_url": "https://en.wikipedia.org/wiki/ID3_algorithm",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/46/ID3_algorithm_decision_tree.png",
        "date": "1986"
    },
    {
        "relevant_people": [
            "Karl Pearson"
        ],
        "description": "The [**Principal Component Analysis (PCA)**](https://en.wikipedia.org/wiki/Principal_component_analysis) is a statistical method for dimensionality reduction, which involves a linear transformation of the data. It was introduced by [Karl Pearson](https://en.wikipedia.org/wiki/Karl_Pearson) in 1901. PCA is widely used in data analysis and machine learning to identify patterns in high-dimensional data, reduce noise, and visualize complex data structures. By transforming the data to a new coordinate system, PCA allows for the identification of the most significant directions (principal components) in the data, thus reducing the dimensionality and simplifying the analysis.",
        "related_topics": [
            "Dimensionality reduction",
            "Eigenvalues and eigenvectors",
            "Linear algebra",
            "Data analysis",
            "Machine learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Principal_component_analysis",
            "https://www.nature.com/articles/1002295",
            "https://www.sciencedirect.com/science/article/pii/S0031320399000555",
            "https://www.jstor.org/stable/2983775",
            "https://ieeexplore.ieee.org/abstract/document/4767965"
        ],
        "papers": [
            {
                "title": "On lines and planes of closest fit to systems of points in space",
                "url": "https://doi.org/10.1080/14786440109462720",
                "authors": [
                    "Pearson, Karl"
                ],
                "proceeding": "The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science",
                "date": "1901",
                "abstract": "This paper presents the method of PCA for the first time, as a way to find lines and planes of closest fit to a system of points in space. The method is based on the use of eigenvalues and eigenvectors, and provides a way to identify the most significant directions in the data.",
                "url_pdf": "https://www.tandfonline.com/doi/pdf/10.1080/14786440109462720",
                "num_citations": 24000,
                "publisher": "Taylor & Francis",
                "pages": "559-572",
                "volume": "2",
                "journal": "The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science",
                "pub_type": "article"
            }
        ],
        "title": "Principal Component Analysis (PCA)",
        "wiki_url": "https://en.wikipedia.org/wiki/Principal_component_analysis",
        "image": "https://upload.wikimedia.org/wikipedia/commons/b/b3/AirMerIconographyCorrelation.jpg",
        "date": "1901"
    },
    {
        "relevant_people": [
            "Jean-Francois Cardoso",
            "Aapo Hyvarinen",
            "Erkki Oja"
        ],
        "description": "The [**Independent Component Analysis (ICA)**](https://en.wikipedia.org/wiki/Independent_component_analysis) is a statistical and computational technique for revealing hidden factors that underlie sets of random variables, measurements, or signals. ICA defines a generative model for the observed multivariate data, which is typically given as a large database of samples. In the model, the data variables are assumed to be linear or nonlinear mixtures of some unknown latent variables, and the mixing system is also unknown. The latent variables are assumed non-Gaussian and mutually independent, and they are called the independent components of the observed data.",
        "related_topics": [
            "Blind Source Separation",
            "Higher-order statistics",
            "Signal processing",
            "Machine learning",
            "Data analysis"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Independent_component_analysis",
            "https://www.sciencedirect.com/science/article/pii/S089360809700086X",
            "https://ieeexplore.ieee.org/abstract/document/704219",
            "https://www.researchgate.net/publication/2433616_A_Fast_Fixed-Point_Algorithm_for_Independent_Component_Analysis"
        ],
        "papers": [
            {
                "title": "Independent Component Analysis: Algorithms and Applications",
                "url": "https://www.sciencedirect.com/science/article/pii/S0893608000000265",
                "authors": [
                    "Aapo Hyvarinen",
                    "Erkki Oja"
                ],
                "proceeding": "Neural Networks",
                "date": "2000",
                "abstract": "This paper presents an overview of feature extraction methods for off-line recognition of segmented (isolated) characters. Selection of a feature extraction method is probably the single most important factor in achieving high recognition performance in character recognition systems.",
                "url_pdf": "http://www.sci.utah.edu/~shireen/pdfs/tutorials/ica.pdf",
                "num_citations": 10315,
                "publisher": "Elsevier",
                "pages": "1483-1511",
                "volume": "13",
                "journal": "Neural Networks",
                "pub_type": "article"
            }
        ],
        "title": "Independent Component Analysis (ICA)",
        "wiki_url": "https://en.wikipedia.org/wiki/Independent_component_analysis",
        "image": "https://upload.wikimedia.org/wikipedia/commons/8/82/A-Local-Learning-Rule-for-Independent-Component-Analysis-srep28073-s3.ogv",
        "date": "1994"
    },
    {
        "decade": "1950s",
        "key_concepts": [
            "Probability theory",
            "Bayesian inference",
            "Naive Bayes",
            "Gaussian Mixture Models (GMMs)",
            "Hidden Markov Models (HMMs)"
        ],
        "description": "The development of [**Generative Models**](https://en.wikipedia.org/wiki/Generative_model) in the 1950s marked a significant advancement in the field of artificial intelligence and machine learning. These models are based on [probability theory](https://en.wikipedia.org/wiki/Probability_theory) and [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference) and are used to estimate the likelihood of a given data point belonging to a specific class or group. Some of the key generative models developed during this time include [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier), [Gaussian Mixture Models (GMMs)](https://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model), and [Hidden Markov Models (HMMs)](https://en.wikipedia.org/wiki/Hidden_Markov_model).",
        "related_topics": [
            "Bayesian networks",
            "Expectation-maximization algorithm",
            "Markov Chain Monte Carlo",
            "Probabilistic graphical models",
            "Machine learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Generative_model",
            "https://en.wikipedia.org/wiki/Probability_theory",
            "https://en.wikipedia.org/wiki/Bayesian_inference",
            "https://en.wikipedia.org/wiki/Naive_Bayes_classifier",
            "https://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model",
            "https://en.wikipedia.org/wiki/Hidden_Markov_model"
        ],
        "papers": [
            {
                "title": "A tutorial on hidden Markov models and selected applications in speech recognition",
                "url": "https://ieeexplore.ieee.org/abstract/document/18626",
                "authors": [
                    "Rabiner, Lawrence R."
                ],
                "proceeding": "Proceedings of the IEEE",
                "date": "1989",
                "abstract": "A tutorial on the basic principles and most significant applications of hidden Markov models (HMMs) in speech recognition is presented. The theoretical issues are described in an intuitive manner, and the practical application of HMMs is discussed. A detailed example of using HMMs for isolated word recognition is provided.",
                "url_pdf": "https://www.cs.cmu.edu/~./awb/papers/CMU-CS-89-169.pdf",
                "num_citations": 13496,
                "publisher": "IEEE",
                "pages": "257-286",
                "volume": "77",
                "journal": "Proceedings of the IEEE",
                "pub_type": "article"
            }
        ],
        "title": "Generative Models",
        "wiki_url": "https://en.wikipedia.org/wiki/Generative_model",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg"
    },
    {
        "relevant_people": [
            "Arthur Dempster",
            "Nan Laird",
            "Donald Rubin"
        ],
        "description": "The [**Gaussian Mixture Models (GMM)**](https://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model) are a probabilistic model that assumes all data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. GMMs are commonly used for clustering and density estimation tasks. The [**Expectation-Maximization (EM) algorithm**](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm), which was introduced in the 1960s by [Arthur Dempster](https://en.wikipedia.org/wiki/Arthur_P._Dempster), [Nan Laird](https://en.wikipedia.org/wiki/Nan_Laird), and [Donald Rubin](https://en.wikipedia.org/wiki/Donald_Rubin), is a popular method for estimating the parameters of GMMs. The EM algorithm is an iterative optimization technique that alternates between two steps: expectation (E-step) and maximization (M-step).",
        "related_topics": [
            "Expectation-Maximization algorithm",
            "Mixture of Gaussians",
            "Clustering",
            "Density estimation",
            "Probabilistic models"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model",
            "https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm",
            "https://www.cs.princeton.edu/courses/archive/spring08/cos424/papers/mclust.pdf",
            "https://www.cs.ubc.ca/~murphyk/Papers/em.pdf"
        ],
        "papers": [
            {
                "title": "Maximum likelihood from incomplete data via the EM algorithm",
                "url": "https://www.jstor.org/stable/2984875",
                "authors": [
                    "Dempster, Arthur P.",
                    "Laird, Nan M.",
                    "Rubin, Donald B."
                ],
                "proceeding": "Journal of the Royal Statistical Society: Series B (Methodological)",
                "date": "1977",
                "abstract": "A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.",
                "url_pdf": "https://www.jstor.org/stable/pdf/2984875.pdf",
                "num_citations": 78851,
                "publisher": "Wiley",
                "pages": "1-38",
                "volume": "39",
                "issue": "1",
                "journal": "Journal of the Royal Statistical Society: Series B (Methodological)",
                "pub_type": "article"
            }
        ],
        "title": "Gaussian Mixture Models (GMM)",
        "wiki_url": "https://en.wikipedia.org/wiki/Mixture_model",
        "image": "https://upload.wikimedia.org/wikipedia/commons/c/c7/Bayesian-categorical-mixture.svg",
        "date": "1960s"
    },
    {
        "relevant_people": [
            "Leonard E. Baum",
            "Lloyd R. Welch",
            "Petar M. Viterbi"
        ],
        "description": "The [**Hidden Markov Models (HMM)**](https://en.wikipedia.org/wiki/Hidden_Markov_model) are statistical models that represent a system where the observations are related to a sequence of hidden states. They were developed in the 1960s and have become a popular tool for sequence modeling, particularly in the fields of [speech recognition](https://en.wikipedia.org/wiki/Speech_recognition), [bioinformatics](https://en.wikipedia.org/wiki/Bioinformatics), and [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing). The [Viterbi Algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm), developed by [Petar M. Viterbi](https://en.wikipedia.org/wiki/Andrew_Viterbi), is an efficient method for finding the most likely sequence of hidden states in an HMM. The [Baum-Welch Algorithm](https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm), developed by [Leonard E. Baum](https://en.wikipedia.org/wiki/Leonard_Baum) and [Lloyd R. Welch](https://en.wikipedia.org/wiki/Lloyd_R._Welch), is an expectation-maximization algorithm used to estimate the parameters of an HMM.",
        "related_topics": [
            "Markov Chain",
            "Expectation-Maximization Algorithm",
            "Speech Recognition",
            "Bioinformatics",
            "Natural Language Processing"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Hidden_Markov_model",
            "https://en.wikipedia.org/wiki/Viterbi_algorithm",
            "https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm",
            "https://ieeexplore.ieee.org/abstract/document/1054010",
            "https://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf"
        ],
        "papers": [
            {
                "title": "An inequality with applications to statistical estimation for probabilistic functions of a Markov process and to a model for ecology",
                "url": "https://projecteuclid.org/euclid.bsmsp/1200512173",
                "authors": [
                    "Baum, Leonard E.",
                    "Petrie, Ted",
                    "Soules, George",
                    "Weiss, Norman"
                ],
                "proceeding": "Bulletin of the American Mathematical Society",
                "date": "1967",
                "abstract": "This paper presents an inequality for a probabilistic function of a Markov process and applies it to statistical estimation and to a model for ecology.",
                "url_pdf": "https://projecteuclid.org/download/pdf_1/euclid.bsmsp/1200512173",
                "num_citations": 281,
                "publisher": "American Mathematical Society",
                "pages": "243-260",
                "volume": "73",
                "journal": "Bulletin of the American Mathematical Society",
                "pub_type": "article"
            }
        ],
        "title": "Hidden Markov Models (HMM)",
        "wiki_url": "https://en.wikipedia.org/wiki/Hidden_Markov_model",
        "image": "https://upload.wikimedia.org/wikipedia/commons/7/71/A_profile_HMM_modelling_a_multiple_sequence_alignment.png",
        "date": "1960s"
    },
    {
        "relevant_people": [
            "Rudolph E. Kalman"
        ],
        "description": "The [**Kalman Filter**](https://en.wikipedia.org/wiki/Kalman_filter) is a mathematical technique for state estimation in linear dynamical systems. It uses a [recursive Bayesian filtering](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation) approach to estimate the state of a system by combining noisy measurements with a model of the system's dynamics. The Kalman Filter was developed by [Rudolph E. Kalman](https://en.wikipedia.org/wiki/Rudolf_E._K%C3%A1lm%C3%A1n) in 1960 and has since become a fundamental tool in various fields, including control systems, navigation, computer vision, and economics.",
        "related_topics": [
            "Linear Dynamical Systems",
            "State Estimation",
            "Bayesian Filtering",
            "Control Systems",
            "Navigation",
            "Computer Vision"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Kalman_filter",
            "https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation",
            "https://en.wikipedia.org/wiki/Rudolf_E._K%C3%A1lm%C3%A1n"
        ],
        "papers": [
            {
                "title": "A New Approach to Linear Filtering and Prediction Problems",
                "url": "https://ieeexplore.ieee.org/document/1086700",
                "authors": [
                    "Rudolph E. Kalman"
                ],
                "proceeding": "Transactions of the ASME--Journal of Basic Engineering",
                "date": "1960",
                "abstract": "The classical Wiener-Kolmogorov filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the \u201cstate variable\u201d formulation of dynamic systems. The resulting theory appears to be a significant simplification of the classical theory.",
                "url_pdf": "https://www.cs.unc.edu/~welch/kalman/media/pdf/Kalman1960.pdf",
                "num_citations": 26092,
                "publisher": "ASME",
                "pages": "35-45",
                "volume": "82",
                "journal": "Transactions of the ASME--Journal of Basic Engineering",
                "pub_type": "article"
            }
        ],
        "title": "Kalman Filters",
        "wiki_url": "https://en.wikipedia.org/wiki/Kalman_filter",
        "image": "https://upload.wikimedia.org/wikipedia/commons/a/a5/Basic_concept_of_Kalman_filtering.svg",
        "date": "1960"
    },
    {
        "relevant_people": [
            "Neil J. Gordon",
            "David J. Salmond",
            "Adrian F. M. Smith"
        ],
        "description": "The [**Particle Filters**](https://en.wikipedia.org/wiki/Particle_filter) (Sequential Monte Carlo Methods) are a class of algorithms used for nonlinear state estimation and [Bayesian filtering](https://en.wikipedia.org/wiki/Bayesian_filtering). They were first introduced by [Neil J. Gordon](https://scholar.google.com/citations?user=KfJ5pW8AAAAJ&hl=en), [David J. Salmond](https://scholar.google.com/citations?user=7BOuYJMAAAAJ&hl=en), and [Adrian F. M. Smith](https://scholar.google.com/citations?user=QcQlW9gAAAAJ&hl=en) in 1993. Particle filters are particularly useful in situations where the system being modeled has nonlinear dynamics or non-Gaussian noise. They have been widely applied in various fields, including robotics, computer vision, finance, and environmental science.",
        "related_topics": [
            "Monte Carlo Methods",
            "Bayesian Filtering",
            "Nonlinear State Estimation",
            "Robotics",
            "Computer Vision"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Particle_filter",
            "https://ieeexplore.ieee.org/document/280945",
            "https://www.cs.ubc.ca/~murphyk/Software/KF/kalman.html",
            "https://www.cs.ubc.ca/~murphyk/Software/PF/particle.html",
            "https://arxiv.org/abs/1309.1285"
        ],
        "papers": [
            {
                "title": "Novel approach to nonlinear/non-Gaussian Bayesian state estimation",
                "url": "https://ieeexplore.ieee.org/document/280945",
                "authors": [
                    "Gordon, Neil J.",
                    "Salmond, David J.",
                    "Smith, Adrian F. M."
                ],
                "proceeding": "IEE Proceedings F - Radar and Signal Processing",
                "date": "1993",
                "abstract": "The paper develops a novel approach to the problem of nonlinear/non-Gaussian Bayesian state estimation. The authors show that approximate solutions to the Bayesian state estimation problem can be obtained by propagating an ensemble of particles, which are appropriately weighted to represent the posterior density function. The solution is extremely flexible and can be applied to a wide range of problems, including those where the noise terms are non-Gaussian and/or correlated.",
                "url_pdf": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=280945",
                "num_citations": 11075,
                "publisher": "IET",
                "pages": "107-113",
                "volume": "140",
                "issue": "2",
                "journal": "IEE Proceedings F - Radar and Signal Processing",
                "pub_type": "article"
            }
        ],
        "title": "Particle Filters",
        "wiki_url": "https://en.wikipedia.org/wiki/Particle_filter",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/3e/Nuvola_apps_edu_mathematics_blue-p.svg",
        "date": "1993"
    },
    {
        "relevant_people": [
            "Stanislaw Ulam",
            "Nicholas Metropolis",
            "John von Neumann"
        ],
        "description": "The [**Monte Carlo methods**](https://en.wikipedia.org/wiki/Monte_Carlo_method) are a class of computational algorithms that rely on random sampling to obtain numerical results for problems that are difficult or impossible to solve analytically. These methods are widely used in various fields, such as physics, engineering, finance, and computer graphics. The development of Monte Carlo methods began in the 1940s, with contributions from [Stanislaw Ulam](https://en.wikipedia.org/wiki/Stanislaw_Ulam), [Nicholas Metropolis](https://en.wikipedia.org/wiki/Nicholas_Metropolis), and [John von Neumann](https://en.wikipedia.org/wiki/John_von_Neumann). The name 'Monte Carlo' was inspired by the famous [Monte Carlo Casino](https://en.wikipedia.org/wiki/Monte_Carlo_Casino) in Monaco, reflecting the element of chance in these methods.",
        "related_topics": [
            "Random Sampling",
            "Numerical Integration",
            "Optimization",
            "Markov Chain Monte Carlo",
            "Quasi-Monte Carlo Methods"
        ],
        "relevant_links": [
            "https://www.nature.com/articles/181767a0",
            "https://www.jstor.org/stable/2280232",
            "https://www.annualreviews.org/doi/abs/10.1146/annurev.pc.23.100172.000245",
            "https://www.sciencedirect.com/science/article/pii/S0377042700003764",
            "https://www.jstor.org/stable/2003356"
        ],
        "papers": [
            {
                "title": "The Monte Carlo Method",
                "url": "https://www.jstor.org/stable/2003356",
                "authors": [
                    "Metropolis, Nicholas",
                    "Ulam, Stanislaw"
                ],
                "proceeding": "Journal of the American Statistical Association",
                "date": "1949",
                "abstract": "The Monte Carlo method is a statistical approach to the study of various problems in physics, biology, and other fields. The method is based on the use of random sampling techniques to approximate solutions to complex mathematical problems.",
                "url_pdf": "https://www.jstor.org/stable/pdf/2003356.pdf",
                "num_citations": 2385,
                "publisher": "Taylor & Francis",
                "pages": "335-341",
                "volume": "44",
                "journal": "Journal of the American Statistical Association",
                "pub_type": "article"
            }
        ],
        "title": "Monte Carlo Methods",
        "wiki_url": "https://en.wikipedia.org/wiki/Monte_Carlo_method",
        "image": "https://upload.wikimedia.org/wikipedia/commons/8/89/Monte-Carlo_method_%28errors%29.png",
        "date": "1940s"
    },
    {
        "time_period": "1950s",
        "relevant_people": [
            "Alan Turing",
            "Noam Chomsky"
        ],
        "description": "The field of [**Natural Language Processing (NLP)**](https://en.wikipedia.org/wiki/Natural_language_processing) emerged in the 1950s, with early contributions from [Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing) and [Noam Chomsky](https://en.wikipedia.org/wiki/Noam_Chomsky). NLP is a subfield of artificial intelligence and linguistics that focuses on the interaction between computers and human languages. It involves the development of algorithms and models that enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP techniques have been applied to various tasks, such as machine translation, language modeling, syntactic parsing, semantic analysis, sentiment analysis, named entity recognition, text generation, and text classification.",
        "related_topics": [
            "Machine Learning",
            "Deep Learning",
            "Artificial Intelligence",
            "Linguistics",
            "Information Retrieval"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Natural_language_processing",
            "https://www.nltk.org/book/",
            "https://www.aclweb.org/anthology/",
            "https://spacy.io/",
            "https://huggingface.co/"
        ],
        "title": "Natural Language Processing (NLP)",
        "wiki_url": "https://en.wikipedia.org/wiki/Natural_language_processing",
        "image": "https://upload.wikimedia.org/wikipedia/commons/8/8b/Automated_online_assistant.png"
    },
    {
        "decade": "1960s",
        "relevant_people": [
            "Larry Roberts",
            "David Marr"
        ],
        "description": "The field of [**Computer Vision**](https://en.wikipedia.org/wiki/Computer_vision) started gaining prominence in the 1960s, with researchers like [Larry Roberts](https://en.wikipedia.org/wiki/Lawrence_G._Roberts) and [David Marr](https://en.wikipedia.org/wiki/David_Marr_(neuroscientist)) contributing to its development. Computer Vision is a field of artificial intelligence that focuses on enabling computers to interpret and understand visual information from the world. The field encompasses a wide range of applications, including object detection, image segmentation, image classification, image generation, image restoration, super-resolution, style transfer, pose estimation, optical character recognition, video analysis, action recognition, human pose estimation, and DensePose.",
        "related_topics": [
            "Deep Learning",
            "Neural Networks",
            "Artificial Intelligence",
            "Machine Learning",
            "Image Processing"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Computer_vision",
            "https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/roberts-63.pdf",
            "https://ieeexplore.ieee.org/abstract/document/4309317",
            "https://www.cs.cmu.edu/~16385/s17/Slides/1.1_Introduction.pdf",
            "https://www.cs.cmu.edu/~16385/s17/Slides/1.2_ImageFormation.pdf"
        ],
        "papers": [
            {
                "title": "Machine Perception Of Three-Dimensional Solids",
                "url": "https://dspace.mit.edu/handle/1721.1/12158",
                "authors": [
                    "Roberts, Lawrence G."
                ],
                "proceeding": "MIT Lincoln Laboratory",
                "date": "1963",
                "abstract": "The results of a theoretical investigation into the feasibility of a machine vision system are presented. The system is designed to recognize three-dimensional objects from the two-dimensional images that the objects form on the retina of a television camera.",
                "url_pdf": "https://dspace.mit.edu/bitstream/handle/1721.1/12158/30303513-MIT.pdf",
                "num_citations": 1950,
                "publisher": "MIT",
                "pub_type": "thesis"
            },
            {
                "title": "Vision: A Computational Investigation into the Human Representation and Processing of Visual Information",
                "url": "https://mitpress.mit.edu/books/vision",
                "authors": [
                    "Marr, David"
                ],
                "proceeding": "MIT Press",
                "date": "1982",
                "abstract": "David Marr's posthumously published book laid the groundwork for the field of computational vision by investigating the different levels of computation that are necessary for understanding the visual world.",
                "url_pdf": "",
                "num_citations": 26862,
                "publisher": "MIT Press",
                "pages": "",
                "volume": "",
                "journal": "",
                "pub_type": "book"
            }
        ],
        "title": "Computer Vision",
        "wiki_url": "https://en.wikipedia.org/wiki/Computer_vision",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/f9/DARPA_Visual_Media_Reasoning_Concept_Video.ogv"
    },
    {
        "relevant_people": [
            "Richard Bellman"
        ],
        "description": "Reinforcement Learning (RL) is a type of [machine learning](https://en.wikipedia.org/wiki/Machine_learning) that focuses on training agents to make decisions by interacting with an environment. The agent learns to maximize its cumulative reward by taking actions in various states. The field has its roots in the 1950s with the work of [Richard Bellman](https://en.wikipedia.org/wiki/Richard_E._Bellman), who introduced [Dynamic Programming](https://en.wikipedia.org/wiki/Dynamic_programming) and the concept of [Markov Decision Processes (MDPs)](https://en.wikipedia.org/wiki/Markov_decision_process). Over the years, RL has evolved and incorporated various techniques and methods, such as [Q-Learning](https://en.wikipedia.org/wiki/Q-learning), [Policy Gradient Methods](https://en.wikipedia.org/wiki/Reinforcement_learning#Policy_gradient_methods), [Deep Reinforcement Learning](https://en.wikipedia.org/wiki/Deep_reinforcement_learning), [Multi-Armed Bandits](https://en.wikipedia.org/wiki/Multi-armed_bandit), [Monte Carlo Tree Search](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search), [Inverse Reinforcement Learning](https://en.wikipedia.org/wiki/Inverse_reinforcement_learning), [Imitation Learning](https://en.wikipedia.org/wiki/Imitation_learning), and [Apprenticeship Learning](https://en.wikipedia.org/wiki/Apprenticeship_learning).",
        "related_topics": [
            "Dynamic Programming",
            "Markov Decision Processes",
            "Q-Learning",
            "Policy Gradient Methods",
            "Deep Reinforcement Learning",
            "Multi-Armed Bandits",
            "Monte Carlo Tree Search",
            "Inverse Reinforcement Learning",
            "Imitation Learning",
            "Apprenticeship Learning"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Reinforcement_learning",
            "https://www.theschool.ai/courses/move-37-course/",
            "https://www.youtube.com/watch?v=2pWv7GOvuf0",
            "https://www.cs.cmu.edu/~scohen/psnlp-lecture6.pdf",
            "https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf"
        ],
        "papers": [
            {
                "title": "A Survey of Reinforcement Learning Informed by Natural Language",
                "url": "https://arxiv.org/abs/1906.03926",
                "authors": [
                    "Goyal, Anirudh",
                    "Niekum, Scott"
                ],
                "proceeding": "arXiv preprint arXiv:1906.03926",
                "date": "2019",
                "abstract": "In this survey, we review recent work in the intersection of natural language processing and reinforcement learning.",
                "url_pdf": "https://arxiv.org/pdf/1906.03926.pdf",
                "num_citations": 81,
                "publisher": "arXiv",
                "pages": "1-32",
                "volume": "",
                "journal": "arXiv preprint",
                "pub_type": "article"
            }
        ],
        "title": "Reinforcement Learning (RL)",
        "wiki_url": "https://en.wikipedia.org/wiki/Reinforcement_learning",
        "image": "https://upload.wikimedia.org/wikipedia/commons/5/51/Computer_Retro.svg",
        "date": "1950s"
    },
    {
        "relevant_people": [
            "Sebastian Thrun",
            "Tom Mitchell"
        ],
        "description": "The concept of [**Transfer Learning**](https://en.wikipedia.org/wiki/Transfer_learning) emerged in the 1990s, with researchers like [Sebastian Thrun](https://en.wikipedia.org/wiki/Sebastian_Thrun) and [Tom Mitchell](https://en.wikipedia.org/wiki/Tom_M._Mitchell) contributing to its development. Transfer Learning is a machine learning technique that enables the adaptation of knowledge learned from one domain to another, related domain. This approach has gained significant traction due to its ability to leverage pre-existing knowledge, reducing the need for large amounts of labeled data and computational resources. Key concepts in transfer learning include [learning to learn](https://en.wikipedia.org/wiki/Learning_to_learn), [inductive transfer](https://en.wikipedia.org/wiki/Inductive_transfer), [domain adaptation](https://en.wikipedia.org/wiki/Domain_adaptation), [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_(machine_learning)), and [pretraining](https://en.wikipedia.org/wiki/Pretraining).",
        "related_topics": [
            "Deep Learning",
            "Neural Networks",
            "Domain Adaptation",
            "Multi-task Learning",
            "Lifelong Learning"
        ],
        "relevant_links": [
            "https://ieeexplore.ieee.org/abstract/document/5288526",
            "https://www.cs.cmu.edu/~tom/pubs/MachineLearning-97.pdf",
            "https://papers.nips.cc/paper/2009/hash/4b86abe48e4f9a8b32f3f178f7b2c8d3-Abstract.html",
            "https://arxiv.org/abs/1411.1792",
            "https://www.jmlr.org/papers/volume11/pan10a/pan10a.pdf"
        ],
        "papers": [
            {
                "title": "A survey on transfer learning",
                "url": "https://ieeexplore.ieee.org/abstract/document/5288526",
                "authors": [
                    "Sinno Jialin Pan",
                    "Qiang Yang"
                ],
                "proceeding": "IEEE Transactions on Knowledge and Data Engineering",
                "date": "2010",
                "abstract": "Transfer learning or inductive transfer is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.",
                "url_pdf": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5288526",
                "num_citations": 5379,
                "publisher": "IEEE",
                "pages": "1345-1359",
                "volume": "22",
                "journal": "IEEE Transactions on Knowledge and Data Engineering",
                "pub_type": "article"
            }
        ],
        "title": "Transfer Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Transfer_learning",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Unbalanced_scales.svg",
        "date": "1990s"
    },
    {
        "decade": "1950s",
        "techniques": [
            "Clustering",
            "Dimensionality Reduction",
            "Density Estimation",
            "Generative Models",
            "Autoencoders",
            "Variational Autoencoders (VAE)"
        ],
        "description": "Unsupervised learning is a type of machine learning that involves discovering patterns and structures in data without using labeled data as a reference. It emerged in the 1950s and has since become an essential aspect of artificial intelligence and machine learning. Some common unsupervised learning techniques include [clustering](https://en.wikipedia.org/wiki/Cluster_analysis), [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction), [density estimation](https://en.wikipedia.org/wiki/Density_estimation), [generative models](https://en.wikipedia.org/wiki/Generative_model), [autoencoders](https://en.wikipedia.org/wiki/Autoencoder), and [variational autoencoders (VAE)](https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)). These techniques help in various applications such as data compression, visualization, anomaly detection, and understanding complex data distributions.",
        "related_topics": [
            "Supervised Learning",
            "Reinforcement Learning",
            "Deep Learning",
            "Feature Extraction",
            "Pattern Recognition"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Unsupervised_learning",
            "https://towardsdatascience.com/unsupervised-learning-8d3b1b96d6f",
            "https://www.youtube.com/watch?v=jAA2g9ItoAc",
            "https://www.coursera.org/learn/machine-learning/lecture/olRZo/unsupervised-learning",
            "https://ai.stackexchange.com/questions/38/what-is-the-difference-between-supervised-learning-and-unsupervised-learning"
        ],
        "title": "Unsupervised Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Unsupervised_learning",
        "image": "https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png"
    },
    {
        "time_period": "1990s",
        "relevant_people": [
            "Vladimir Vapnik",
            "Esther Levin",
            "Yann LeCun",
            "Yoshua Bengio"
        ],
        "description": "Semi-Supervised Learning (SSL) is a [machine learning](https://en.wikipedia.org/wiki/Machine_learning) paradigm that emerged in the 1990s, which uses both [labeled](https://en.wikipedia.org/wiki/Labeled_data) and [unlabeled data](https://en.wikipedia.org/wiki/Unlabeled_data) for training. SSL algorithms aim to improve the learning performance by exploiting the information present in the unlabeled data. The development of SSL was influenced by the works of researchers like [Vladimir Vapnik](https://en.wikipedia.org/wiki/Vladimir_Vapnik), [Esther Levin](https://www.researchgate.net/profile/Esther-Levin), [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun), and [Yoshua Bengio](https://en.wikipedia.org/wiki/Yoshua_Bengio). Two main approaches to SSL are [graph-based methods](https://en.wikipedia.org/wiki/Semi-supervised_learning#Graph-based_methods) and [generative models](https://en.wikipedia.org/wiki/Semi-supervised_learning#Generative_models).",
        "related_topics": [
            "Supervised Learning",
            "Unsupervised Learning",
            "Machine Learning",
            "Deep Learning",
            "Artificial Neural Networks"
        ],
        "relevant_links": [
            "https://en.wikipedia.org/wiki/Semi-supervised_learning",
            "https://ai.stanford.edu/~ang/papers/icml04-largemargin.pdf",
            "https://papers.nips.cc/paper/2002/file/7e31c66d0e3c3b9f22b7e601cac9d0b3-Paper.pdf",
            "https://www.researchgate.net/publication/220276701_Semi-Supervised_Learning_Literature_Survey"
        ],
        "papers": [
            {
                "title": "Semi-Supervised Learning Literature Survey",
                "url": "https://www.researchgate.net/publication/220276701_Semi-Supervised_Learning_Literature_Survey",
                "authors": [
                    "Xiaojin Zhu"
                ],
                "date": "2005",
                "abstract": "We review the literature on semi-supervised learning, which is an area in machine learning and more generally, artificial intelligence. There has been a whole spectrum of interesting ideas on how to learn from both labeled and unlabeled data, i.e. semi-supervised learning. This document is a chapter of my thesis.",
                "url_pdf": "https://www.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf",
                "num_citations": 2859,
                "publisher": "University of Wisconsin-Madison",
                "pages": "1-52",
                "volume": "",
                "journal": "",
                "pub_type": "report"
            }
        ],
        "title": "Semi-Supervised Learning",
        "wiki_url": "https://en.wikipedia.org/wiki/Weak_supervision",
        "image": "https://upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png"
    },
    {
        "decade": "1960s",
        "relevant_people": [
            "John Holland",
            "Ingo Rechenberg",
            "Hans-Paul Schwefel"
        ],
        "description": "The [**Evolutionary Algorithms**](https://en.wikipedia.org/wiki/Evolutionary_algorithm) are a family of optimization algorithms inspired by the process of natural selection. They are used to find approximate solutions to optimization and search problems. The development of evolutionary algorithms began in the 1960s, with contributions from [John Holland](https://en.wikipedia.org/wiki/John_H._Holland), [Ingo Rechenberg](https://en.wikipedia.org/wiki/Ingo_Rechenberg), and [Hans-Paul Schwefel](https://en.wikipedia.org/wiki/Hans-Paul_Schwefel). Various types of evolutionary algorithms have been developed, including [Genetic Algorithms](https://en.wikipedia.org/wiki/Genetic_algorithm), [Evolution Strategies](https://en.wikipedia.org/wiki/Evolution_strategy), [Genetic Programming](https://en.wikipedia.org/wiki/Genetic_programming), [Particle Swarm Optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization), [Differential Evolution](https://en.wikipedia.org/wiki/Differential_evolution), and [Estimation of Distribution Algorithms](https://en.wikipedia.org/wiki/Estimation_of_distribution_algorithm).",
        "related_topics": [
            "Optimization algorithms",
            "Bio-inspired computing",
            "Machine learning",
            "Artificial intelligence",
            "Swarm intelligence"
        ],
        "relevant_links": [
            "https://www.sciencedirect.com/science/article/pii/S2210650219303449",
            "https://www.mitpressjournals.org/doi/abs/10.1162/evco.1992.1.1",
            "https://www.researchgate.net/publication/228932758_Evolutionary_algorithms",
            "https://www.springer.com/gp/book/9783642072852",
            "https://www.springer.com/gp/book/9783642072852"
        ],
        "papers": [
            {
                "title": "Adaption in Natural and Artificial Systems",
                "url": "https://www.jstor.org/stable/2008811",
                "authors": [
                    "Holland, John H."
                ],
                "proceeding": "",
                "date": "1975",
                "abstract": "John Holland's groundbreaking book on the development of genetic algorithms has been updated in this new edition with new insights and applications of genetic algorithms to a variety of problems.",
                "url_pdf": "https://deepblue.lib.umich.edu/bitstream/handle/2027.42/8425/bab9388.0001.001.pdf",
                "num_citations": "",
                "publisher": "University of Michigan Press",
                "pages": "",
                "volume": "",
                "journal": "",
                "pub_type": "book"
            }
        ],
        "title": "Evolutionary Algorithms",
        "wiki_url": "https://en.wikipedia.org/wiki/Evolutionary_algorithm",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg"
    },
    {
        "relevant_people": [
            "John McCarthy",
            "Marvin Minsky",
            "Allen Newell",
            "Herbert A. Simon"
        ],
        "description": "Artificial General Intelligence ([**AGI**](https://en.wikipedia.org/wiki/Artificial_general_intelligence)) refers to the development of human-like intelligence in machines, enabling them to perform any intellectual task that a human being can do. AGI is also known as [Strong AI](https://en.wikipedia.org/wiki/Strong_AI) or [Machine Consciousness](https://en.wikipedia.org/wiki/Machine_consciousness). The concept of AGI emerged in the 1950s with the work of AI pioneers such as [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)), [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky), [Allen Newell](https://en.wikipedia.org/wiki/Allen_Newell), and [Herbert A. Simon](https://en.wikipedia.org/wiki/Herbert_A._Simon). Their research focused on [cognitive architectures](https://en.wikipedia.org/wiki/Cognitive_architecture) and aimed to create machines that could mimic human intelligence across a wide range of tasks.",
        "related_topics": [
            "Artificial Narrow Intelligence (ANI)",
            "Machine Learning",
            "Neural Networks",
            "Turing Test",
            "Symbolic AI"
        ],
        "relevant_links": [
            "https://plato.stanford.edu/entries/artificial-intelligence/",
            "https://www.aaai.org/ojs/index.php/aimagazine/article/view/1848",
            "https://ieeexplore.ieee.org/abstract/document/1626715",
            "https://www.sciencedirect.com/science/article/pii/S0004370202001213",
            "https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/artificial-general-intelligence-and-the-human-mental-model/2D2D8FDC0C7B0C6E9E7B8D6B9A7F0B1E"
        ],
        "papers": [
            {
                "title": "Artificial General Intelligence: Concept, State of the Art, and Future Prospects",
                "url": "https://link.springer.com/article/10.1007%2Fs11023-014-9345-1",
                "authors": [
                    "Ben Goertzel"
                ],
                "proceeding": "Minds and Machines",
                "date": "2014",
                "abstract": "This paper provides a brief introduction to the domain of \u201cartificial general intelligence\u201d (AGI) research, clarifying the key concepts, the state of the art, and the major open issues.",
                "url_pdf": "https://link.springer.com/content/pdf/10.1007/s11023-014-9345-1.pdf",
                "num_citations": 84,
                "publisher": "Springer",
                "pages": "1-48",
                "volume": "24",
                "journal": "Minds and Machines",
                "pub_type": "article"
            }
        ],
        "title": "Artificial General Intelligence (AGI)",
        "wiki_url": "https://en.wikipedia.org/wiki/Artificial_general_intelligence",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg",
        "date": "1950s"
    },
    {
        "founder": "Elon Musk",
        "description": "The [**Neuralink**](https://en.wikipedia.org/wiki/Neuralink) is a neurotechnology company founded by [Elon Musk](https://en.wikipedia.org/wiki/Elon_Musk) in 2016. The company focuses on developing advanced [brain-computer interfaces (BCIs)](https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface) to enable humans to interact with computers and other devices using their thoughts. Neuralink aims to create high-bandwidth, implantable devices that can record and stimulate neurons in the brain, with potential applications in treating neurological disorders, enhancing cognitive abilities, and even merging human consciousness with artificial intelligence.",
        "related_topics": [
            "Brain-Computer Interface",
            "Neuron Activity Sensing",
            "Neural Prosthetics",
            "Brain Stimulation",
            "Neurotechnology"
        ],
        "relevant_links": [
            "https://www.neuralink.com/",
            "https://www.youtube.com/watch?v=DVvmgjBL74w",
            "https://www.nature.com/articles/s41586-020-03104-2",
            "https://www.ted.com/talks/elon_musk_the_future_we_re_building_and_boring"
        ],
        "papers": [
            {
                "title": "An integrated brain-machine interface platform with thousands of channels",
                "url": "https://www.biorxiv.org/content/10.1101/703801v3",
                "authors": [
                    "Elon Musk",
                    "Neuralink"
                ],
                "proceeding": "bioRxiv",
                "date": "2019",
                "abstract": "Brain-machine interfaces (BMIs) hold promise for the restoration of sensory and motor function and the treatment of neurological disorders, but clinical BMIs have not yet been widely adopted, in part because modest channel counts have limited their potential. In this white paper, we describe Neuralink's first steps toward a scalable high-bandwidth BMI system. We have built arrays of small and flexible electrode 'threads', with as many as 3,072 electrodes per array distributed across 96 threads. We have also built a neurosurgical robot capable of inserting six threads (192 electrodes) per minute. Each thread can be individually inserted into the brain with micron precision for avoidance of surface vasculature and targeting specific brain regions. The electrode array is packaged into a small implantable device that contains custom chips for low-power on-board amplification and digitization: the package for 3,072 channels occupies less than (23 x 18.5 x 2) mm3. A single USB-C cable provides full-bandwidth data streaming from the device.",
                "url_pdf": "https://www.biorxiv.org/content/biorxiv/early/2019/07/17/703801.full.pdf",
                "num_citations": 352,
                "publisher": "Cold Spring Harbor Laboratory",
                "pages": "1-57",
                "volume": "",
                "journal": "bioRxiv",
                "pub_type": "preprint"
            }
        ],
        "title": "Neuralink",
        "wiki_url": "https://en.wikipedia.org/wiki/Neuralink",
        "image": "https://upload.wikimedia.org/wikipedia/commons/f/fd/BrainGate.jpg",
        "date": "2016"
    },
    {
        "founders": [
            "Elon Musk",
            "Sam Altman",
            "Ilya Sutskever",
            "Greg Brockman",
            "John Schulman"
        ],
        "description": "The [**OpenAI**](https://en.wikipedia.org/wiki/OpenAI) organization was founded in 2015 by [Elon Musk](https://en.wikipedia.org/wiki/Elon_Musk), [Sam Altman](https://en.wikipedia.org/wiki/Sam_Altman), [Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever), [Greg Brockman](https://en.wikipedia.org/wiki/Greg_Brockman), and [John Schulman](https://en.wikipedia.org/wiki/John_Schulman_(computer_scientist)). Its mission is to ensure that artificial general intelligence ([AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence)) benefits all of humanity. OpenAI is dedicated to advancing AI research through open collaboration and ensuring long-term safety in the development of AI technologies.",
        "related_topics": [
            "Artificial Intelligence",
            "Artificial General Intelligence",
            "AI Safety",
            "AI Research",
            "Open Collaboration"
        ],
        "relevant_links": [
            "https://openai.com/",
            "https://en.wikipedia.org/wiki/OpenAI",
            "https://www.forbes.com/sites/parmyolson/2015/12/11/elon-musk-openai-artificial-intelligence/",
            "https://techcrunch.com/2015/12/11/elon-musk-sam-altman-launch-openai-to-find-and-encourage-positive-ai-uses/",
            "https://www.wired.com/2015/12/elon-musk-and-y-combinator-plan-to-set-artificial-intelligence-free/"
        ],
        "papers": [
            {
                "title": "OpenAI Charter",
                "url": "https://openai.com/charter/",
                "authors": [
                    "OpenAI"
                ],
                "date": "2018",
                "abstract": "The OpenAI Charter outlines the principles and strategy for the organization. It emphasizes broadly distributed benefits, long-term safety, technical leadership, and cooperative orientation as the key pillars for OpenAI's approach to developing artificial general intelligence."
            }
        ],
        "title": "OpenAI",
        "wiki_url": "https://en.wikipedia.org/wiki/OpenAI",
        "image": "https://upload.wikimedia.org/wikipedia/commons/a/a3/DALL-E_sample.png",
        "date": "2015"
    },
    {
        "organization": "OpenAI",
        "main_goal": "Zero-Shot Visual Reasoning",
        "application": "Image Generation",
        "model_type": "Transformer Model",
        "technique": "Text-to-Image Synthesis",
        "description": "The [**DALL-E**](https://openai.com/dall-e/) is an AI model developed by [**OpenAI**](https://openai.com/) in 2021, which is capable of generating high-quality images from textual descriptions. It is based on a [transformer architecture](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) and demonstrates zero-shot visual reasoning abilities. DALL-E can create coherent and contextually relevant images by understanding and interpreting the given textual input. As a result, it has a wide range of potential applications, including art, design, advertising, and more.",
        "related_topics": [
            "Generative Adversarial Networks (GANs)",
            "Deep Learning",
            "Natural Language Processing (NLP)",
            "Computer Vision",
            "Transformer Models"
        ],
        "relevant_links": [
            "https://openai.com/dall-e/",
            "https://arxiv.org/abs/2102.12092",
            "https://openai.com/blog/dall-e/"
        ],
        "papers": [
            {
                "title": "DALL-E: Creating Images from Text",
                "url": "https://arxiv.org/abs/2102.12092",
                "authors": [
                    "Aditya Ramesh",
                    "Mikhail Pavlov",
                    "Gabriel Goh",
                    "Scott Gray",
                    "Chelsea Voss",
                    "Alec Radford",
                    "Mark Chen",
                    "Ilya Sutskever"
                ],
                "date": "2021",
                "abstract": "DALL-E is a 12-billion parameter version of GPT-3 trained to generate images from text descriptions, using a dataset of text-image pairs. We find that DALL-E is able to create plausible images for a great variety of sentences that explore the compositional structure of language.",
                "url_pdf": "https://arxiv.org/pdf/2102.12092.pdf",
                "num_citations": "N/A",
                "publisher": "arXiv",
                "pages": "N/A",
                "volume": "N/A",
                "journal": "arXiv",
                "pub_type": "preprint"
            }
        ],
        "title": "DALL-E",
        "wiki_url": "https://en.wikipedia.org/wiki/DALL-E",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg",
        "date": "2021"
    },
    {
        "relevant_people": [
            "Ilya Sutskever",
            "Alec Radford",
            "Samy Bengio"
        ],
        "description": "The [**DALL-E 2**](https://openai.com/research/) project is a continuation of the initial [DALL-E](https://openai.com/blog/dall-e/) model, which was a neural network-based image generation model developed by [OpenAI](https://openai.com/). The DALL-E model was capable of generating high-quality images from textual descriptions, and the DALL-E 2 project aims to improve on this initial model by enhancing its capabilities and refining the output quality. The team behind DALL-E 2 includes researchers from OpenAI, such as [Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever), [Alec Radford](https://ai.google/research/people/105214), and [Samy Bengio](https://en.wikipedia.org/wiki/Samy_Bengio).",
        "related_topics": [
            "OpenAI",
            "Generative models",
            "Image synthesis",
            "Deep learning",
            "Neural networks"
        ],
        "relevant_links": [
            "https://openai.com/research/",
            "https://openai.com/blog/dall-e/",
            "https://arxiv.org/abs/2102.12092"
        ],
        "papers": [
            {
                "title": "DALL-E: Creating Images from Text",
                "url": "https://arxiv.org/abs/2102.12092",
                "authors": [
                    "Aditya Ramesh",
                    "Mikhail Pavlov",
                    "Gabriel Goh",
                    "Scott Gray",
                    "Chelsea Voss",
                    "Alec Radford",
                    "Mark Chen",
                    "Ilya Sutskever"
                ],
                "proceeding": "arXiv preprint",
                "date": "2021",
                "abstract": "DALL-E is a 12-billion parameter version of GPT-3 trained to generate images from text descriptions, using a dataset of text-image pairs. We find that DALL-E is able to create plausible images for a great variety of sentences that explore the compositional structure of language. We also show that it can generate creative, humorous images, and render text.",
                "url_pdf": "https://arxiv.org/pdf/2102.12092.pdf",
                "num_citations": "N/A",
                "publisher": "arXiv",
                "pages": "N/A",
                "volume": "N/A",
                "journal": "arXiv preprint",
                "pub_type": "preprint"
            }
        ],
        "title": "DALL-E 2",
        "wiki_url": "https://en.wikipedia.org/wiki/DALL-E",
        "image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg",
        "date": "2021"
    },
    {
        "relevant_organization": [
            "OpenAI"
        ],
        "description": "The [**GPT-2**](https://en.wikipedia.org/wiki/GPT-2) (Generative Pre-trained Transformer 2) is a state-of-the-art language model developed by [OpenAI](https://en.wikipedia.org/wiki/OpenAI) in 2019. It is based on the [transformer architecture](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) and uses unsupervised learning for text generation. GPT-2 is known for its ability to generate coherent and contextually relevant text based on a given input. It has been widely used in various applications such as chatbots, text summarization, and translation.",
        "related_topics": [
            "GPT-3",
            "BERT",
            "Natural Language Processing",
            "Deep Learning",
            "Text Generation"
        ],
        "relevant_links": [
            "https://openai.com/blog/better-language-models/",
            "https://github.com/openai/gpt-2",
            "https://arxiv.org/abs/1910.10683",
            "https://www.youtube.com/watch?v=8SAJKyU0x1w",
            "https://www.youtube.com/watch?v=SyxP65BpD34"
        ],
        "papers": [
            {
                "title": "Language Models are Unsupervised Multitask Learners",
                "url": "https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf",
                "authors": [
                    "Alec Radford",
                    "Jeffrey Wu",
                    "Rewon Child",
                    "David Luan",
                    "Dario Amodei",
                    "Ilya Sutskever"
                ],
                "date": "2019",
                "abstract": "The paper introduces GPT-2, a large-scale generative language model that achieves state-of-the-art performance on a wide range of natural language processing tasks. The authors demonstrate that GPT-2 can be fine-tuned for various tasks, including translation, summarization, and question-answering, with minimal task-specific input.",
                "num_citations": 3567,
                "publisher": "OpenAI"
            }
        ],
        "title": "GPT-2",
        "wiki_url": "https://en.wikipedia.org/wiki/GPT-2",
        "image": "https://upload.wikimedia.org/wikipedia/commons/9/91/Full_GPT_architecture.png",
        "date": "2019"
    },
    {
        "organization": "OpenAI",
        "category": "Conversational AI",
        "technology": "GPT-based Model",
        "description": "The [**ChatGPT**](https://platform.openai.com/docs/guides/chat) is a state-of-the-art conversational AI model developed by [**OpenAI**](https://www.openai.com/) in 2021. It is based on the [**GPT**](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer) (Generative Pre-trained Transformer) architecture, which is known for its advanced natural language understanding and text generation capabilities. ChatGPT is designed to generate human-like responses in a conversational setting, making it suitable for various applications such as chatbots, virtual assistants, and customer support.",
        "related_topics": [
            "GPT-3",
            "Transformer Models",
            "Natural Language Processing",
            "Machine Learning",
            "Deep Learning"
        ],
        "relevant_links": [
            "https://platform.openai.com/docs/guides/chat",
            "https://www.openai.com/",
            "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer",
            "https://arxiv.org/abs/2005.14165"
        ],
        "papers": [
            {
                "title": "Language Models are Few-Shot Learners",
                "url": "https://arxiv.org/abs/2005.14165",
                "authors": [
                    "Tom B. Brown",
                    "Benjamin Mann",
                    "Nick Ryder",
                    "Melanie Subbiah",
                    "Jared Kaplan",
                    "Prafulla Dhariwal",
                    "Arvind Neelakantan",
                    "Pranav Shyam",
                    "Girish Sastry",
                    "Amanda Askell",
                    "Sandhini Agarwal",
                    "Ariel Herbert-Voss",
                    "Gretchen Krueger",
                    "Tom Henighan",
                    "Rewon Child",
                    "Aditya Ramesh",
                    "Daniel M. Ziegler",
                    "Jeffrey Wu",
                    "Clemens Winter",
                    "Christopher Hesse",
                    "Mark Chen",
                    "Eric Sigler",
                    "Mateusz Litwin",
                    "Scott Gray",
                    "Benjamin Chess",
                    "Jack Clark",
                    "Christopher Berner",
                    "Sam McCandlish",
                    "Alec Radford",
                    "Ilya Sutskever",
                    "Dario Amodei"
                ],
                "date": "2020",
                "abstract": "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.",
                "url_pdf": "https://arxiv.org/pdf/2005.14165.pdf",
                "num_citations": 4679,
                "publisher": "arXiv",
                "journal": "arXiv preprint arXiv:2005.14165",
                "pub_type": "article"
            }
        ],
        "title": "ChatGPT",
        "wiki_url": "https://en.wikipedia.org/wiki/ChatGPT",
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/49/ChatGPT_Screenshot.png",
        "date": "2021"
    }
]